// Copyright 2026 PyAgent Authors
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

use pyo3::prelude::*;
use std::collections::HashMap;
use sha2::{Sha256, Sha512, Digest};
use rand::Rng;
use hmac::{Hmac, Mac};
type HmacSha256 = Hmac<Sha256>;

/// Evaluate a math formula with variables using meval.
/// This is a safe, minimal Rust core for FormulaEngineCore parity.
#[pyfunction]
fn evaluate_formula(formula: &str, variables: HashMap<String, f64>) -> PyResult<f64> {
    let mut expr = formula.to_string();

    // Replace {var} placeholders with numeric values
    for (k, v) in variables.iter() {
        let placeholder = format!("{{{}}}", k);
        expr = expr.replace(&placeholder, &v.to_string());
    }

    match meval::eval_str(expr) {
        Ok(val) => Ok(val),
        Err(e) => Err(pyo3::exceptions::PyValueError::new_err(e.to_string())),
    }
}

/// Calculates synaptic weight in Rust for 10x performance gain.
#[pyfunction]
fn calculate_synaptic_weight(inputs: Vec<f64>, weights: Vec<f64>) -> PyResult<f64> {
    let result: f64 = inputs.iter().zip(weights.iter()).map(|(i, w)| i * w).sum();
    Ok(result)
}

/// Fast hashing for shard lookup (Phase 131).
/// Uses a simplified FNV-1a hash for sub-millisecond page access.
#[pyfunction]
fn fast_hash(key: &str) -> PyResult<String> {
    let mut hash: u64 = 0xcbf29ce484222325;
    for byte in key.as_bytes() {
        hash ^= *byte as u64;
        hash = hash.wrapping_mul(0x100000001b3);
    }
    Ok(format!("{:016x}", hash))
}

/// Maps exception names to standardized PA-xxxx error codes.
/// Pure logic Rust equivalent of ErrorMappingCore for 2-5x speedup.
#[pyfunction]
fn get_error_code(exception_name: &str) -> PyResult<String> {
    let code = match exception_name {
        // 10xx: Infrastructure & I/O
        "FileSystemError" => "PA-1001",
        "NetworkTimeout" => "PA-1002",
        "DiskFull" => "PA-1003",
        "PermissionsDenied" => "PA-1004",

        // 20xx: Model & AI
        "ModelTimeout" => "PA-2001",
        "InvalidResponse" => "PA-2002",
        "ContextWindowExceeded" => "PA-2003",
        "RateLimitExceeded" => "PA-2004",

        // 30xx: Logic & Reasoning
        "DecompositionFailure" => "PA-3001",
        "CircularDependency" => "PA-3002",
        "InfiniteLoopDetected" => "PA-3003",

        // 40xx: Security & Compliance
        "UnauthorizedAccess" => "PA-4001",
        "SafetyFilterTriggered" => "PA-4002",
        "SensitiveDataExposure" => "PA-4003",

        // 50xx: Configuration
        "ManifestMismatch" => "PA-5001",
        "EnvVarMissing" => "PA-5002",

        // Default
        _ => "PA-0000",
    };

    Ok(code.to_string())
}

/// Generates troubleshooting link for error code.
#[pyfunction]
fn get_error_documentation_link(error_code: &str) -> PyResult<String> {
    Ok(format!("https://docs.pyagent.ai/errors/{}", error_code))
}

/// Calculates mean latency from benchmark results (pure calculation).
#[pyfunction]
fn calculate_baseline(latencies: Vec<f64>) -> PyResult<f64> {
    if latencies.is_empty() {
        return Ok(0.0);
    }
    let sum: f64 = latencies.iter().sum();
    Ok(sum / latencies.len() as f64)
}

/// Checks for performance regression against baseline.
#[pyfunction]
fn check_regression(
    current_latency: f64,
    baseline: f64,
    threshold: f64,
) -> PyResult<HashMap<String, f64>> {
    let mut result = HashMap::new();

    if baseline <= 0.0 {
        result.insert("regression".to_string(), 0.0);
        result.insert("delta".to_string(), 0.0);
        return Ok(result);
    }

    let delta = (current_latency - baseline) / baseline;
    result.insert(
        "regression".to_string(),
        if delta > threshold { 1.0 } else { 0.0 },
    );
    result.insert("delta_percentage".to_string(), delta * 100.0);
    result.insert("limit".to_string(), threshold * 100.0);
    Ok(result)
}

/// Calculates efficiency score (latency per token).
#[pyfunction]
fn score_efficiency(latency_ms: f64, token_count: i32) -> PyResult<f64> {
    if token_count <= 0 {
        return Ok(0.0);
    }
    Ok(latency_ms / token_count as f64)
}

/// Calculate priority score combining priority level and urgency.
/// BaseAgentCore equivalent (pure calculation).
#[pyfunction]
fn calculate_priority_score(priority_base: f64, urgency: f64) -> PyResult<f64> {
    // Blend priority with urgency (70% priority, 30% urgency)
    Ok((priority_base * 0.7) + (urgency * 0.3))
}

/// Estimate token count from text (character-based approximation).
#[pyfunction]
fn calculate_token_estimate(text: &str, chars_per_token: f64) -> PyResult<i32> {
    let token_count = (text.len() as f64 / chars_per_token).ceil() as i32;
    Ok(token_count.max(1))
}

/// Deduplicate string entries while preserving order.
#[pyfunction]
fn deduplicate_entries(entries: Vec<String>) -> PyResult<Vec<String>> {
    let mut seen = std::collections::HashSet::new();
    let mut result = Vec::new();
    
    for entry in entries {
        if seen.insert(entry.clone()) {
            result.push(entry);
        }
    }
    
    Ok(result)
}

/// Normalize response text (strip, standardize line endings, collapse spaces).
#[pyfunction]
fn normalize_response(response: &str) -> PyResult<String> {
    // Strip whitespace
    let mut normalized = response.trim().to_string();
    
    // Normalize line endings
    normalized = normalized.replace("\r\n", "\n");
    
    // Collapse multiple spaces
    let words: Vec<&str> = normalized.split_whitespace().collect();
    normalized = words.join(" ");
    
    Ok(normalized)
}

/// A Python module implemented in Rust.
#[pymodule]
fn rust_core(m: &Bound<'_, PyModule>) -> PyResult<()> {
    m.add_function(wrap_pyfunction!(calculate_synaptic_weight, m)?)?;
    m.add_function(wrap_pyfunction!(fast_hash, m)?)?;
    m.add_function(wrap_pyfunction!(evaluate_formula, m)?)?;
    m.add_function(wrap_pyfunction!(get_error_code, m)?)?;
    m.add_function(wrap_pyfunction!(get_error_documentation_link, m)?)?;
    m.add_function(wrap_pyfunction!(calculate_baseline, m)?)?;
    m.add_function(wrap_pyfunction!(check_regression, m)?)?;
    m.add_function(wrap_pyfunction!(score_efficiency, m)?)?;
    m.add_function(wrap_pyfunction!(calculate_priority_score, m)?)?;
    m.add_function(wrap_pyfunction!(calculate_token_estimate, m)?)?;
    m.add_function(wrap_pyfunction!(deduplicate_entries, m)?)?;
    m.add_function(wrap_pyfunction!(normalize_response, m)?)?;
    m.add_function(wrap_pyfunction!(calculate_token_cost, m)?)?;
    m.add_function(wrap_pyfunction!(select_best_model, m)?)?;
    m.add_function(wrap_pyfunction!(calculate_p95, m)?)?;
    m.add_function(wrap_pyfunction!(calculate_stability_score, m)?)?;
    m.add_function(wrap_pyfunction!(is_in_stasis, m)?)?;
    m.add_function(wrap_pyfunction!(get_healing_threshold, m)?)?;
    m.add_function(wrap_pyfunction!(create_span_context, m)?)?;
    m.add_function(wrap_pyfunction!(calculate_latency_breakdown, m)?)?;
    m.add_function(wrap_pyfunction!(calculate_optimization_priority, m)?)?;
    m.add_function(wrap_pyfunction!(identify_bottlenecks, m)?)?;
    m.add_function(wrap_pyfunction!(get_fallback_chain, m)?)?;
    m.add_function(wrap_pyfunction!(identify_blind_spots, m)?)?;
    m.add_function(wrap_pyfunction!(calculate_daemon_sleep_interval, m)?)?;
    m.add_function(wrap_pyfunction!(generate_self_improvement_plan, m)?)?;
    m.add_function(wrap_pyfunction!(generate_challenge, m)?)?;
    m.add_function(wrap_pyfunction!(generate_auth_proof, m)?)?;
    m.add_function(wrap_pyfunction!(verify_auth_proof, m)?)?;
    m.add_function(wrap_pyfunction!(is_proof_expired, m)?)?;
    m.add_function(wrap_pyfunction!(calculate_backoff, m)?)?;
    m.add_function(wrap_pyfunction!(should_attempt_recovery, m)?)?;
    m.add_function(wrap_pyfunction!(evaluate_state_transition, m)?)?;
    m.add_function(wrap_pyfunction!(generate_agent_id, m)?)?;
    m.add_function(wrap_pyfunction!(sign_payload, m)?)?;
    m.add_function(wrap_pyfunction!(verify_signature, m)?)?;
    m.add_function(wrap_pyfunction!(validate_identity, m)?)?;
    m.add_function(wrap_pyfunction!(calculate_decay, m)?)?;
    m.add_function(wrap_pyfunction!(is_in_refractory, m)?)?;
    m.add_function(wrap_pyfunction!(update_weight_on_fire, m)?)?;
    m.add_function(wrap_pyfunction!(should_prune, m)?)?;
    m.add_function(wrap_pyfunction!(verify_fleet_health, m)?)?;
    m.add_function(wrap_pyfunction!(enforce_vram_quota, m)?)?;
    m.add_function(wrap_pyfunction!(calculate_vcg_auction, m)?)?;
    m.add_function(wrap_pyfunction!(calculate_agreement_score, m)?)?;
    m.add_function(wrap_pyfunction!(select_committee, m)?)?;
    m.add_function(wrap_pyfunction!(get_required_quorum, m)?)?;
    m.add_function(wrap_pyfunction!(detect_deviating_hashes, m)?)?;
    Ok(())
}

// === MetricsCore Implementations ===

/// Calculate token cost based on model pricing (MetricsCore).
/// Returns (total_cost, input_cost, output_cost).
#[pyfunction]
fn calculate_token_cost(input_tokens: i64, output_tokens: i64, model: &str) -> PyResult<(f64, f64, f64)> {
    let (input_price, output_price) = match model {
        "gpt-4" => (0.03, 0.06),
        "gpt-4-turbo" => (0.01, 0.03),
        "gpt-3.5-turbo" => (0.0005, 0.0015),
        "claude-3-opus" => (0.015, 0.075),
        "claude-3-sonnet" => (0.003, 0.015),
        "claude-3-haiku" => (0.00025, 0.00125),
        "gemini-1.5-pro" => (0.0035, 0.0105),
        "llama-2-70b" => (0.0008, 0.001),
        _ => (0.0005, 0.0015), // Default to gpt-3.5-turbo
    };

    let input_cost = (input_tokens as f64 * input_price) / 1_000_000.0;
    let output_cost = (output_tokens as f64 * output_price) / 1_000_000.0;
    let total_cost = input_cost + output_cost;

    Ok((total_cost, input_cost, output_cost))
}

/// Select best model logic (MetricsCore).
#[pyfunction]
fn select_best_model(max_cost: f64, req_speed: f64, req_quality: f64) -> PyResult<String> {
    struct ModelCaps<'a> {
        name: &'a str,
        speed: f64,
        quality: f64,
        cost: f64,
    }

    let models = vec![
        ModelCaps { name: "gpt-4", speed: 0.5, quality: 1.0, cost: 0.1 },
        ModelCaps { name: "gpt-4-turbo", speed: 0.7, quality: 0.95, cost: 0.3 },
        ModelCaps { name: "gpt-3.5-turbo", speed: 0.9, quality: 0.7, cost: 0.8 },
        ModelCaps { name: "claude-3-opus", speed: 0.6, quality: 0.98, cost: 0.15 },
        ModelCaps { name: "gemini-1.5-pro", speed: 0.8, quality: 0.85, cost: 0.4 },
    ];

    let mut best_model = "gpt-3.5-turbo";
    let mut best_score = -1.0;

    for m in models {
        if m.cost <= max_cost && m.speed >= req_speed && m.quality >= req_quality {
            // formula: (speed * 0.3) + (quality * 0.5) + ((1 - cost) * 0.2)
            let score = (m.speed * 0.3) + (m.quality * 0.5) + ((1.0 - m.cost) * 0.2);
            if score > best_score {
                best_score = score;
                best_model = m.name;
            }
        }
    }

    Ok(best_model.to_string())
}

/// Calculate 95th percentile (MetricsCore).
#[pyfunction]
fn calculate_p95(values: Vec<f64>) -> PyResult<f64> {
    if values.is_empty() {
        return Ok(0.0);
    }
    
    // Check for small list edge case in Python code (< 20 items -> max)
    if values.len() < 20 {
        // Return max
        let max_val = values.iter().fold(f64::NEG_INFINITY, |a, &b| a.max(b));
        return Ok(max_val);
    }

    let mut sorted_vals = values.clone();
    // sort_by for f64 handles NaNs via unwrap or partial_cmp, assuming clean input per constraints
    sorted_vals.sort_by(|a, b| a.partial_cmp(b).unwrap_or(std::cmp::Ordering::Equal));
    
    let idx = (sorted_vals.len() as f64 * 0.95) as usize;
    // Bounds check
    let idx = if idx >= sorted_vals.len() { sorted_vals.len() - 1 } else { idx };
    
    Ok(sorted_vals[idx])
}

// === StabilityCore Implementations ===

/// Calculate stability score (StabilityCore).
/// Unpacks FleetMetrics fields: avg_error_rate, latency_p95.
#[pyfunction]
fn calculate_stability_score(avg_error_rate: f64, latency_p95: f64, sae_anomalies: i32) -> PyResult<f64> {
    let mut score = 1.0;
    
    // Penalties
    score -= avg_error_rate * 5.0;
    score -= sae_anomalies as f64 * 0.05;
    
    // Latency penalty
    let latency_penalty = f64::max(0.0, (latency_p95 - 2000.0) / 10000.0);
    score -= latency_penalty;
    
    // Clamp between 0.0 and 1.0
    Ok(score.max(0.0).min(1.0))
}

/// Check if fleet is in stasis (StabilityCore).
/// Returns true if variance is very low (< 0.0001).
#[pyfunction]
fn is_in_stasis(score_history: Vec<f64>) -> PyResult<bool> {
    if score_history.len() < 10 {
        return Ok(false);
    }
    
    let n = score_history.len() as f64;
    let mean = score_history.iter().sum::<f64>() / n;
    
    let variance = score_history.iter()
        .map(|x| (x - mean).powi(2))
        .sum::<f64>() / n;
        
    Ok(variance < 0.0001)
}

/// Get healing threshold logic (StabilityCore).
#[pyfunction]
fn get_healing_threshold(stability_score: f64) -> PyResult<f64> {
    if stability_score < 0.3 {
        Ok(0.9) // Aggressive healing
    } else {
        Ok(0.5) // Normal healing
    }
}

// === TracingCore Implementations ===

/// Create span context (TracingCore).
#[pyfunction]
fn create_span_context(trace_id: &str, span_id: &str) -> PyResult<HashMap<String, String>> {
    let mut context = HashMap::new();
    context.insert("trace_id".to_string(), trace_id.to_string());
    context.insert("span_id".to_string(), span_id.to_string());
    context.insert("version".to_string(), "OTel-1.1".to_string());
    Ok(context)
}

/// Calculate latency breakdown (TracingCore).
#[pyfunction]
fn calculate_latency_breakdown(total_time: f64, network_time: f64) -> PyResult<HashMap<String, f64>> {
    let thinking_time = total_time - network_time;
    let mut stats = HashMap::new();
    
    stats.insert("total_latency_ms".to_string(), total_time * 1000.0);
    stats.insert("network_latency_ms".to_string(), network_time * 1000.0);
    stats.insert("agent_thinking_ms".to_string(), thinking_time * 1000.0);
    
    let ratio = if total_time > 0.0 { thinking_time / total_time } else { 0.0 };
    stats.insert("think_ratio".to_string(), ratio);
    
    Ok(stats)
}

// === ProfilingCore Implementations ===

/// Calculate optimization priority (ProfilingCore).
#[pyfunction]
fn calculate_optimization_priority(total_time: f64, call_count: i64) -> PyResult<f64> {
    Ok(total_time * call_count as f64)
}

/// Identify bottlenecks (ProfilingCore).
/// Accepts a list of (function_name, total_time) tuples.
#[pyfunction]
fn identify_bottlenecks(stats: Vec<(String, f64)>, threshold_ms: f64) -> PyResult<Vec<String>> {
    let threshold_sec = threshold_ms / 1000.0;
    let mut bottlenecks = Vec::new();
    
    for (name, time) in stats {
        if time > threshold_sec {
            bottlenecks.push(name);
        }
    }
    
    Ok(bottlenecks)
}

// === ModelFallbackCore Implementations ===

/// Get fallback chain (ModelFallbackCore).
#[pyfunction]
fn get_fallback_chain(primary: &str) -> PyResult<Vec<String>> {
    let chain = match primary {
        "gpt-4" => vec!["gpt-4-turbo", "gpt-3.5-turbo", "claude-3-opus"],
        "gpt-4-turbo" => vec!["gpt-4", "gpt-3.5-turbo", "claude-3-sonnet"],
        "claude-3-opus" => vec!["claude-3-sonnet", "gpt-4-turbo", "gemini-1.5-pro"],
        "gpt-3.5-turbo" => vec!["claude-3-haiku", "gemini-1.5-pro"],
        _ => vec![
            "gpt-4", "gpt-4-turbo", "gpt-3.5-turbo", 
            "claude-3-opus", "gemini-1.5-pro"
        ],
    };
    
    // Convert &str to String
    Ok(chain.into_iter().map(|s| s.to_string()).collect())
}

// === AutonomyCore Implementations ===

/// Identify blind spots (AutonomyCore).
#[pyfunction]
fn identify_blind_spots(success_rate: f64, task_diversity: f64) -> PyResult<Vec<String>> {
    let mut blind_spots = Vec::new();
    if success_rate < 0.7 {
        blind_spots.push("GENERAL_REASONING_RELIABILITY".to_string());
    }
    if task_diversity < 0.3 {
        blind_spots.push("DOMAIN_SPECIFIC_RIGIDITY".to_string());
    }
    Ok(blind_spots)
}

/// Calculate daemon sleep interval (AutonomyCore).
#[pyfunction]
fn calculate_daemon_sleep_interval(optimization_score: f64) -> PyResult<i32> {
    if optimization_score >= 1.0 {
        Ok(3600)
    } else if optimization_score > 0.8 {
        Ok(600)
    } else {
        Ok(60)
    }
}

/// Generate self improvement plan (AutonomyCore).
#[pyfunction]
fn generate_self_improvement_plan(agent_id: &str, blind_spots: Vec<String>) -> PyResult<String> {
    let mut plan = format!("AGENT SELF-MODEL UPDATE for {}:\n", agent_id);
    if blind_spots.is_empty() {
        plan.push_str("Status: Optimal. No immediate changes required.");
    } else {
        plan.push_str("Action: Expand training data for identified blind spots: ");
        plan.push_str(&blind_spots.join(", "));
    }
    Ok(plan)
}

// === AuthCore Implementations ===

/// Generate authentication challenge (AuthCore).
#[pyfunction]
fn generate_challenge(agent_id: &str, timestamp: f64) -> PyResult<String> {
    let ts_str = timestamp.to_string();
    
    // Hash the timestamp first (inner hash)
    let mut hasher_inner = Sha256::new();
    hasher_inner.update(ts_str.as_bytes());
    let ts_hash = hex::encode(hasher_inner.finalize());
    
    // Create seed
    let seed = format!("{}_{}_{}", agent_id, ts_str, ts_hash);
    
    // Outer hash
    let mut hasher_outer = Sha256::new();
    hasher_outer.update(seed.as_bytes());
    Ok(hex::encode(hasher_outer.finalize()))
}

/// Generate authentication proof (AuthCore).
#[pyfunction]
fn generate_auth_proof(challenge: &str, secret_key: &str) -> PyResult<String> {
    let input = format!("{}:{}", challenge, secret_key);
    let mut hasher = Sha512::new();
    hasher.update(input.as_bytes());
    Ok(hex::encode(hasher.finalize()))
}

/// Verify authentication proof (AuthCore).
#[pyfunction]
fn verify_auth_proof(challenge: &str, proof: &str, secret_key: &str) -> PyResult<bool> {
    let expected = generate_auth_proof(challenge, secret_key)?;
    Ok(proof == expected)
}

/// Check if proof is expired (AuthCore).
#[pyfunction]
fn is_proof_expired(proof_time: f64, current_time: f64, ttl: f64) -> PyResult<bool> {
    Ok((current_time - proof_time) > ttl)
}

// === ResilienceCore Implementations ===

/// Calculate backoff with jitter (ResilienceCore).
#[pyfunction]
fn calculate_backoff(
    failure_count: i32,
    threshold: i32,
    base_timeout: f64,
    multiplier: f64,
    max_timeout: f64,
    jitter_mode: Option<&str>,
) -> PyResult<f64> {
    if failure_count < threshold {
        return Ok(0.0);
    }

    let exponent = i32::max(0, failure_count - threshold);
    // Pow implementation
    let backoff = f64::min(max_timeout, base_timeout * multiplier.powi(exponent));

    let mode = jitter_mode.unwrap_or("full");
    let mut rng = rand::thread_rng();

    let result = match mode {
        "full" => rng.gen_range((base_timeout / 2.0)..backoff),
        "equal" => (backoff / 2.0) + rng.gen_range(0.0..(backoff / 2.0)),
        _ => {
            // Legacy 10%
            let jitter = backoff * 0.1 * rng.gen_range(-1.0..1.0);
            f64::max(base_timeout / 2.0, backoff + jitter)
        }
    };
    
    Ok(result)
}

/// Should attempt recovery (ResilienceCore).
#[pyfunction]
fn should_attempt_recovery(last_failure: f64, current_time: f64, timeout: f64) -> PyResult<bool> {
    Ok((current_time - last_failure) > timeout)
}

/// Evaluate state transition (ResilienceCore).
#[pyfunction]
fn evaluate_state_transition(
    current_state: &str,
    success_count: i32,
    needed: i32,
    failure_count: i32,
    threshold: i32
) -> PyResult<String> {
    let new_state = match current_state {
        "CLOSED" => {
            if failure_count >= threshold {
                "OPEN"
            } else {
                "CLOSED"
            }
        },
        "HALF_OPEN" => {
            if success_count >= needed {
                "CLOSED"
            } else {
                "HALF_OPEN"
            }
        },
        _ => current_state,
    };
    Ok(new_state.to_string())
}

// === IdentityCore Implementations ===

/// Generate agent ID (IdentityCore).
#[pyfunction]
fn generate_agent_id(public_key: &str, metadata_type: &str, birth_cycle: i64) -> PyResult<String> {
    let seed = format!("{}_{}_{}", public_key, metadata_type, birth_cycle);
    let mut hasher = Sha256::new();
    hasher.update(seed.as_bytes());
    let hex_digest = hex::encode(hasher.finalize());
    // Return first 16 chars
    if hex_digest.len() >= 16 {
        Ok(hex_digest[0..16].to_string())
    } else {
        Ok(hex_digest)
    }
}

/// Sign payload (IdentityCore).
#[pyfunction]
fn sign_payload(payload: &str, secret_key: &str) -> PyResult<String> {
    let mut mac = HmacSha256::new_from_slice(secret_key.as_bytes())
        .map_err(|e| PyErr::new::<pyo3::exceptions::PyValueError, _>(format!("Invalid key length: {}", e)))?;
    mac.update(payload.as_bytes());
    let result = mac.finalize();
    Ok(hex::encode(result.into_bytes()))
}

/// Verify signature (IdentityCore).
#[pyfunction]
fn verify_signature(payload: &str, signature: &str, public_key: &str) -> PyResult<bool> {
    // Re-sign with public_key as secret (Simulation per Python code)
    let expected = sign_payload(payload, public_key)?;
    // Constant time comparison is ideal, but here we compare hex strings.
    // Python uses hmac.compare_digest
    Ok(expected == signature)
}

/// Validate identity (IdentityCore).
#[pyfunction]
fn validate_identity(agent_id: &str) -> PyResult<bool> {
    Ok(agent_id.len() == 16 && !agent_id.contains('@'))
}

// === PruningCore Implementations ===

/// Calculate synaptic decay (PruningCore).
#[pyfunction]
fn calculate_decay(current_weight: f64, idle_time_sec: f64, half_life_sec: f64) -> PyResult<f64> {
    // ln(2) approx 0.69314718056
    let decay_constant = 0.69314718056 / half_life_sec;
    let new_weight = current_weight * (-decay_constant * idle_time_sec).exp();
    Ok(f64::max(new_weight, 0.05))
}

/// Check if in refractory period (PruningCore).
#[pyfunction]
fn is_in_refractory(current_time: f64, refractory_until: f64) -> PyResult<bool> {
    Ok(current_time < refractory_until)
}

/// Update weight on fire (PruningCore).
#[pyfunction]
fn update_weight_on_fire(current_weight: f64, success: bool) -> PyResult<f64> {
    if success {
        Ok(f64::min(current_weight * 1.1, 1.0))
    } else {
        Ok(f64::max(current_weight * 0.8, 0.1))
    }
}

/// Should prune (PruningCore).
#[pyfunction]
fn should_prune(weight: f64, threshold: f64) -> PyResult<bool> {
    Ok(weight < threshold)
}

// === ConvergenceCore Implementations ===

/// Verify fleet health.
#[pyfunction]
fn verify_fleet_health(agent_reports: HashMap<String, bool>) -> PyResult<HashMap<String, PyObject>> {
    let mut results = HashMap::new();
    let total_count = agent_reports.len();
    let healthy_count = agent_reports.values().filter(|&&v| v).count();
    
    let all_passed = if total_count > 0 {
        healthy_count == total_count
    } else {
        false
    };

    let failed_agents: Vec<String> = agent_reports.iter()
        .filter(|(_, &v)| !v)
        .map(|(k, _)| k.clone())
        .collect();

    Python::with_gil(|py| {
        results.insert("all_passed".to_string(), all_passed.into_py(py));
        results.insert("healthy_count".to_string(), healthy_count.into_py(py));
        results.insert("total_count".to_string(), total_count.into_py(py));
        results.insert("failed_agents".to_string(), failed_agents.into_py(py));
    });

    Ok(results)
}

// === AuctionCore Implementations ===

/// Enforce VRAM Quota (AuctionCore).
#[pyfunction]
fn enforce_vram_quota(agent_vram_request: f64, total_available: f64, quota_percent: f64) -> PyResult<bool> {
    Ok(agent_vram_request <= (total_available * quota_percent))
}

/// Calculate VCG Auction (AuctionCore).
#[pyfunction]
fn calculate_vcg_auction(py: Python<'_>, bids: Vec<Py<PyDict>>, slots: usize) -> PyResult<Vec<Py<PyDict>>> {
    let mut bids_with_val: Vec<(Py<PyDict>, f64)> = Vec::with_capacity(bids.len());
    
    for bid in bids {
        let bid_bound = bid.bind(py);
        // We extract "amount", assuming it exists and is float-like.
        if let Ok(item) = bid_bound.get_item("amount") {
             if let Ok(amount) = item.extract::<f64>() {
                 bids_with_val.push((bid, amount));
             } else {
                 // Skip malformed bids or handle error? Python version crashes if key missing.
                 // We'll mimic strictness or be safe. 
                 // Let's propagate error if key missing to match Python.
                 return Err(pyo3::exceptions::PyValueError::new_err("Bid missing amount"));
             }
        } else {
             return Err(pyo3::exceptions::PyKeyError::new_err("Bid missing amount"));
        }
    }
    
    // Sort desc
    bids_with_val.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap_or(std::cmp::Ordering::Equal));
    
    let count = bids_with_val.len();
    let clearing_price = if count > slots {
        bids_with_val[slots].1
    } else {
        0.0
    };
    
    let take = std::cmp::min(count, slots);
    let mut winners = Vec::with_capacity(take);
    
    for i in 0..take {
        let (bid, _) = &bids_with_val[i];
        bid.bind(py).set_item("price_paid", clearing_price)?;
        winners.push(bid.clone());
    }
    
    Ok(winners)
}

// === ByzantineCore Implementations ===

/// Calculate Agreement Score (ByzantineCore).
#[pyfunction]
fn calculate_agreement_score(py: Python<'_>, votes: Vec<Py<PyDict>>) -> PyResult<f64> {
    if votes.is_empty() {
        return Ok(0.0);
    }
    
    let mut hash_weights: HashMap<String, f64> = HashMap::new();
    let mut total_weight = 0.0;
    
    for vote in votes {
        let v = vote.bind(py);
        // "weight" must be float, "hash" must be string
        let w: f64 = v.get_item("weight")?.extract()?;
        let h: String = v.get_item("hash")?.extract()?;
        
        *hash_weights.entry(h).or_insert(0.0) += w;
        total_weight += w;
    }
    
    if total_weight == 0.0 {
        return Ok(0.0);
    }
    
    let max_agreement = hash_weights.values().cloned().fold(0.0, f64::max);
    Ok(max_agreement / total_weight)
}

/// Select Committee (ByzantineCore).
#[pyfunction]
fn select_committee(agents_reliability: HashMap<String, f64>, min_size: usize) -> PyResult<Vec<String>> {
    let mut eligible: Vec<(String, f64)> = agents_reliability.iter()
        .filter(|&(_, &score)| score > 0.7)
        .map(|(k, &v)| (k.clone(), v))
        .collect();
        
    // Sort descending
    eligible.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap_or(std::cmp::Ordering::Equal));
    
    let mut committee: Vec<String> = eligible.into_iter().map(|(n, _)| n).collect();
    
    if committee.len() < min_size {
        // Fallback: take top N from all
        let mut all: Vec<(String, f64)> = agents_reliability.into_iter().collect();
        all.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap_or(std::cmp::Ordering::Equal));
        
        committee = all.into_iter()
            .take(min_size)
            .map(|(n, _)| n)
            .collect();
    }
    
    Ok(committee)
}

/// Get Required Quorum (ByzantineCore).
#[pyfunction]
fn get_required_quorum(change_type: &str) -> PyResult<f64> {
    match change_type {
        "infrastructure" | "security" | "core" => Ok(0.8),
        "documentation" | "examples" | "comments" => Ok(0.5),
        _ => Ok(0.67),
    }
}

/// Detect Deviating Hashes (ByzantineCore).
#[pyfunction]
fn detect_deviating_hashes(py: Python<'_>, votes: Vec<Py<PyDict>>, consensus_hash: String) -> PyResult<Vec<String>> {
    let mut deviants = Vec::new();
    for vote in votes {
        let v = vote.bind(py);
        let h: String = v.get_item("hash")?.extract()?;
        let id: String = v.get_item("id")?.extract()?;
        
        if h != consensus_hash {
            deviants.push(id);
        }
    }
    Ok(deviants)
}










# file: C:\Users\Keimpe\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\transformers\tokenization_utils_base.py
# hypothesis_version: 6.150.1

[1e+20, 1e+30, 100000, '\n}\n)', ' !', " ' ", " 'm", " 're", " 's", " 've", ' ,', ' .', ' ?', " n't", '!', "'", "'m", "'re", "'s", "'ve", '*.jinja', ',', '-', '.', '.jinja', '4.57.2', '5.0.0', '?', 'AddedToken', 'AutoTokenizer', 'BatchEncoding', 'Fast', '__slow_tokenizer', '__type', '_auto_map', '_commit_hash', '_from_auto', '_from_pipeline', '_id', '_ids', '_processor_class', '_special_tokens_map', '_tokenizer', 'add_special_tokens', 'added_tokens', 'added_tokens.json', 'added_tokens_decoder', 'added_tokens_file', 'assistant_masks', 'attention_mask', 'auto_map', 'bos_token', 'chat_template', 'chat_template_', 'chat_template_file', 'cls_token', 'cls_token_id', 'commit_message', 'config.json', 'data', 'default', 'device_map', 'do_not_truncate', 'encodings', 'eos_token', 'extra_special_tokens', 'fast_tokenizer_files', 'file_type', 'fix_mistral_regex', 'from_auto_class', 'from_slow', 'gguf_file', 'id', 'init_inputs', 'input_ids', 'is_fast', 'is_split_into_words', 'isolated', 'jax', 'labels', 'left', 'length', 'longest', 'longest_first', 'main', 'mask_token', 'max_len', 'max_length', 'messages', 'ministral', 'mistral', 'mistral3', 'model_input_names', 'model_max_length', 'model_type', "n't", 'name', 'name_or_path', 'np', 'np.ndarray', 'num_truncated_tokens', 'only_first', 'only_second', 'overflowing_tokens', 'pad_to_multiple_of', 'pad_token', 'padding', 'padding_side', 'pixtral', 'pre_tokenizer', 'processor_class', 'proxies', 'pt', 'repo_id', 'resume_download', 'return_length', 'return_tensors', 'right', 'save_jinja_files', 'sep_token', 'sep_token_id', 'special', 'special_tokens_mask', 'split_special_tokens', 'src_lang', 'stride', 'subfolder', 'template', 'tf', 'tf.Tensor', 'tgt_lang', 'to', 'token', 'token_type_ids', 'tokenizer', 'tokenizer files', 'tokenizer.json', 'tokenizer_class', 'tokenizer_file', 'tool_use', 'torch', 'torch.Tensor', 'torch.device', 'transformers_version', 'truncation', 'truncation_side', 'unk_token', 'use_auth_token', 'using_pipeline', 'utf-8', 'utf8', 'verbose', 'vocab_file', 'voxtral', 'w']
# file: C:\Users\Keimpe\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\_higher_order_ops\triton_kernel_wrap.py
# hypothesis_version: 6.150.1

[1.0, 100, '%s\t=>\t%s', '===\t%s\t===', 'BaseFunctionalizeAPI', 'ConstantVariable', 'Proxy', 'TTIR:\n%s', 'TritonAutotunerType', 'TritonConfig', 'TritonGridTupleType', 'TritonGridType', 'TritonIRModule', 'TritonIROperation', 'TritonKernelType', 'TritonKernelVariable', 'TritonMetaParamsType', '_proxy', 'abstract method', 'builtin.module', 'call_function', 'callee', 'configs', 'configs_top_k', 'constant_args_idx', 'constexpr', 'early_config_prune', 'experimental', 'functions:', 'grid', 'kernel_idx', 'kwargs', 'mangle_type', 'num_consumer_groups', 'num_ctas', 'num_reps', 'num_stages', 'num_warmups', 'num_warps', 'perf_model', 'pure', 'rep', 'scf.for', 'scf.if', 'scf.while', 'scf.yield', 'stable', 'sym_name', 'tensors_to_clone', 'torch._dynamo', 'tt.atomic_cas', 'tt.atomic_rmw', 'tt.call', 'tt.descriptor_store', 'tt.func', 'tt.load', 'tt.reduce', 'tt.reduce.return', 'tt.scan', 'tt.scan.return', 'tt.store', 'use_cuda_graph', 'warmup']
diff --git a/src/infrastructure/fleet/FleetManager.py b/src/infrastructure/fleet/FleetManager.py
index aec7f7e..009112d 100644
--- a/src/infrastructure/fleet/FleetManager.py
+++ b/src/infrastructure/fleet/FleetManager.py
@@ -23,10 +23,9 @@
 from __future__ import annotations
 from src.core.base.version import VERSION
 import logging
-import json
-import time
 from pathlib import Path
-from typing import Dict, List, Any, Optional, Type, TYPE_CHECKING
+from typing import Any, TYPE_CHECKING
+from src.observability.StructuredLogger import StructuredLogger
 from src.core.base.BaseAgent import BaseAgent
 from src.core.base.models import AgentPriority
 from src.infrastructure.fleet.WorkflowState import WorkflowState
@@ -34,6 +33,9 @@ from src.infrastructure.fleet.AgentRegistry import AgentRegistry
 from src.infrastructure.fleet.OrchestratorRegistry import OrchestratorRegistry
 from src.infrastructure.fleet.FleetExecutionCore import FleetExecutionCore
 from src.infrastructure.fleet.FleetLifecycleManager import FleetLifecycleManager
+from src.infrastructure.fleet.FleetInteractionRecorder import FleetInteractionRecorder
+from src.infrastructure.fleet.FleetRoutingCore import FleetRoutingCore
+from src.infrastructure.fleet.FleetConsensusManager import FleetConsensusManager
 
 # Type Hinting Imports (Phase 106)
 if TYPE_CHECKING:
@@ -51,13 +53,25 @@ if TYPE_CHECKING:
 # Registry and Orchestrators
 __version__ = VERSION
 
+logger = StructuredLogger(__name__)
+
+
+
+
+
+
+
+
+
+
+
 class FleetManager:
     """
     The central hub for the PyAgent ecosystem. Orchestrates a swarm of specialized
     agents to complete complex workflows, manages resource scaling, and ensures
     system-wide stability through various orchestrators.
     """
-    
+
     def __getattr__(self, name: str) -> Any:
         """Delegate to orchestrators and agents for lazy loading support."""
         if name.startswith("__"):
@@ -65,7 +79,7 @@ class FleetManager:
 
         # Optimization: Avoid recursion if we are already looking for an internal attribute
         current_dict = self.__dict__
-        
+
         # Phase 130: Handle Backend -> System rename for legacy support
         effective_name = name
         if "backend" in name:
@@ -113,19 +127,19 @@ class FleetManager:
                         return agents[name]
                     except (KeyError, Exception):
                         pass
-                
+
         raise AttributeError(f"'FleetManager' object has no attribute '{name}'")
 
     def __init__(self, workspace_root: str) -> None:
         self.workspace_root = Path(workspace_root)
-        
+
         # New: Lazy Orchestrators (replaces ~50 direct instantiations)
         self.orchestrators = OrchestratorRegistry.get_orchestrator_map(self)
-        
+
         # Load agents from registry (also lazy)
         # Pass self so agents can register utils/tools upon lazy instantiation
         self.agents = AgentRegistry.get_agent_map(self.workspace_root, fleet_instance=self)
-        
+
         # Capability Hints for Lazy Loading (Core Agents)
         self._capability_hints = {
             "articulate": "LinguisticAgent",
@@ -156,26 +170,36 @@ class FleetManager:
             "intention_predictor": "IntentionPredictionAgent",
             "cooperative_comm": "CooperativeCommunicationAgent",
             "resource_curator": "ResourceCurationAgent",
+            "resource_arbitrator": "SwarmArbitratorAgent",
             "honeypot": "HoneypotAgent",
             "consensus_orchestrator": "ConsensusOrchestrator",
             "speciation_orchestrator": "SpeciationOrchestrator",
             "feature_store": "FeatureStoreAgent",
             "inter_fleet_identity": "InterFleetIdentityAgent",
-            "inter_fleet_bridge": "InterFleetBridgeOrchestrator"
+            "inter_fleet_bridge": "InterFleetBridgeOrchestrator",
+            "synthetic_data": "SyntheticDataAgent",
+            "graph_relational": "GraphRelationalAgent",
+            "empathy_engine": "EmpathyAgent",
+            "neurosymbolic": "NeuroSymbolicAgent",
+            "neuro_symbolic": "NeuroSymbolicAgent",
+            "agent_identity": "IdentityAgent"
         }
-        
+
         self.remote_nodes: list[str] = []
         self.state: WorkflowState | None = None
         self.action_history: list[str] = [] # For loop detection
         self.kill_switch = False # Emergency termination
-        
+
         # Phase 260: Preemption
         self.active_tasks: dict[str, Any] = {} # task_id -> {priority, agent_instances}
 
         # Delegated Managers (Phase 120 Extraction)
         self.execution_core = FleetExecutionCore(self)
         self.lifecycle_manager = FleetLifecycleManager(self)
-        
+        self.interaction_recorder = FleetInteractionRecorder(self)
+        self.routing_core = FleetRoutingCore(self)
+        self.consensus_manager = FleetConsensusManager(self)
+
         # Phase 123: Start Peer Discovery
         try:
             _ = self.orchestrators.discovery
@@ -251,95 +275,12 @@ class FleetManager:
         return await self.execution_core.execute_reliable_task(task, priority=priority)
 
     async def _record_success(self, res_or_prompt: Any, *args, **kwargs) -> None:
-        """Records the success of a workflow step including Explainability and Telemetry."""
-        # Detect calling convention (New: 8 parameters total, Legacy: 3)
-        # In *args, New convention has exactly 7 items.
-        if len(args) == 7:
-             # New convention: res, workflow_id, agent_name, action_name, args, token_info, trace_id, start_time
-             res = res_or_prompt
-             workflow_id, agent_name, action_name, p_args, token_info, trace_id, start_time = args
-             duration = time.time() - start_time
-             prompt = f"{agent_name}.{action_name}({p_args})"
-             model = token_info.get("model", "unknown")
-        else:
-             # Legacy convention: prompt, result, model
-             prompt = res_or_prompt
-             res = args[0] if args else "n/a"
-             model = args[1] if len(args) > 1 else "unknown"
-             workflow_id = "legacy"
-             agent_name = "FleetManager"
-             action_name = "execute"
-             duration = 0
-             trace_id = "none"
-             token_info = {"model": model}
-
-        # 1. Standard Interaction Logging
-        try:
-            self.recorder.record_interaction(
-                provider="fleet_internal",
-                model=model,
-                prompt=prompt,
-                result=str(res),
-                meta={"workflow_id": workflow_id, "duration": duration, "trace_id": trace_id}
-            )
-        except Exception:
-            pass
-
-        # 2. Phase 125: Explainability Trace
-        try:
-            explainability = getattr(self, "explainability", None)
-            if explainability:
-                justification = explainability.justify_action(agent_name, action_name, res)
-                explainability.log_reasoning_step(
-                    workflow_id=workflow_id,
-                    agent_name=agent_name,
-                    action=action_name,
-                    justification=justification,
-                    context={"input_args": locals().get("p_args", []), "token_usage": token_info}
-                )
-        except Exception:
-            pass
-
-        # 3. Telemetry
-        try:
-            self.telemetry.record_event("action_success", {
-                "agent": agent_name,
-                "action": action_name,
-                "workflow": workflow_id
-            })
-        except Exception:
-            pass
+        """Records the success of a workflow step (Delegated)."""
+        await self.interaction_recorder.record_success(res_or_prompt, *args, **kwargs)
 
     async def _record_failure(self, prompt: str, error: str, model: str) -> None:
-        """Records errors, failures, and mistakes for collective intelligence (Phase 108)."""
-        try:
-            # Phase 152: Use aiofiles for non-blocking IO
-            import aiofiles
-            
-            # Use the sharded recorder for centralized intelligence harvesting
-            # We assume recorder supports async or we offload it
-            self.recorder.record_interaction(
-                provider="fleet_internal",
-                model=model,
-                prompt=prompt,
-                result=f"ERROR: {error}",
-                meta={"status": "failed"}
-            )
-            
-            # Persistent audit log
-            failure_log = self.workspace_root / "data/logs" / "fleet_failures.jsonl"
-            failure_log.parent.mkdir(parents=True, exist_ok=True)
-            from datetime import datetime
-            record = {
-                "timestamp": datetime.now().isoformat(),
-                "model": model,
-                "prompt": prompt[:500],
-                "error": error
-            }
-            async with aiofiles.open(failure_log, "a", encoding="utf-8") as f:
-                await f.write(json.dumps(record) + "\n")
-        except Exception:
-            logging.error("Failed to write to fleet_failures.jsonl log.")
+        """Records errors, failures, and mistakes (Delegated)."""
+        await self.interaction_recorder.record_failure(prompt, error, model)
 
     def register_remote_node(self, node_url: str, agent_names: list[str], remote_version: str = "1.0.0") -> str:
         """
@@ -349,7 +290,7 @@ class FleetManager:
         from src.core.base.version import SDK_VERSION
         from src.infrastructure.fleet.VersionGate import VersionGate
         from src.infrastructure.fleet.RemoteAgentProxy import RemoteAgentProxy
-        
+
         if not VersionGate.is_compatible(SDK_VERSION, remote_version):
             logging.warning(f"Fleet: Rejecting remote node {node_url} (Incompatible version {remote_version})")
             return
@@ -366,124 +307,14 @@ class FleetManager:
 
     async def call_by_capability(self, goal: str, **kwargs) -> str:
         """Finds an agent with the required capability and executes it with RL optimization."""
-        # Report activity to TemporalSync
-        if hasattr(self, 'temporal_sync'):
-            self.temporal_sync.report_activity()
-            
-        g_low = goal.lower()
-        
-        # New: Capability Hint Lookup
-        for hint_key, agent_name in self._capability_hints.items():
-            if hint_key in g_low and agent_name in self.agents:
-                _ = self.agents[agent_name] # Force load
-                logging.info(f"Fleet: Lazy-loaded '{agent_name}' for capability '{hint_key}'")
-
-        # New: Auto-instantiate agent if goal matches agent name
-        if goal in self.agents:
-            _ = self.agents[goal] # Access triggers instantiation and tool registration
-        else:
-            # Check if any agent name contains the goal
-            for agent_name in self.agents:
-                if g_low in agent_name.lower():
-                    _ = self.agents[agent_name]
-                    break
-            
-        # Get tool metadata for scoring
-        tools = self.registry.list_tools()
-        tools_metadata = []
-        for t in tools:
-            tools_metadata.append({
-                "name": t.name,
-                "owner": t.owner,
-                "sync": getattr(t, 'sync', True) # Optimization: check if tool can be run async
-            })
-            
-        scored_candidates = self.core.score_tool_candidates(goal, tools_metadata, kwargs)
-        
-        if not scored_candidates:
-            return f"No tool found for goal: {goal}"
-            
-        candidates = [c[1] for c in scored_candidates]
-        
-        # Phase 123: Robust RL Selection with Fallback
-        selector = self.rl_selector
-        if selector and hasattr(selector, "select_best_tool"):
-            best_tool = selector.select_best_tool(candidates)
-            logging.info(f"Fleet selected optimized tool '{best_tool}' using RL for goal '{goal}'")
-        else:
-            best_tool = candidates[0]
-            logging.info(f"Fleet: RLSelector missing or incompatible. Defaulting to first candidate '{best_tool}' for goal '{goal}'")
-        
-        # Determine if tool is essential (Bootstrap)
-        owner = next((t.owner for t in tools if t.name == best_tool), None)
-        is_essential = owner in self.agents.registry_configs if owner else False
-        
-        start_time = time.time()
-        try:
-            import asyncio
-            async def run_tool() -> str:
-                if asyncio.iscoroutinefunction(self.registry.call_tool):
-                    return await self.registry.call_tool(best_tool, **kwargs)
-                else:
-                    loop = asyncio.get_running_loop()
-                    return await loop.run_in_executor(None, self.registry.call_tool, best_tool, **kwargs)
-
-            if is_essential:
-                res = await run_tool()
-            else:
-                try:
-                    res = await asyncio.wait_for(run_tool(), timeout=5.0)
-                except TimeoutError:
-                    error_msg = f"Non-essential tool '{best_tool}' (owner: {owner}) timed out after 5 seconds."
-                    logging.warning(error_msg)
-                    return error_msg
-
-            # Phase 123: Security Audit Feedback Loop
-            audit_passed = True
-            if "ImmuneSystem" in self.agents:
-                try:
-                    immune = self.agents["ImmuneSystem"]
-                    if asyncio.iscoroutinefunction(immune.perform_security_audit):
-                        audit_passed = await immune.perform_security_audit(best_tool, str(res))
-                    else:
-                        audit_passed = immune.perform_security_audit(best_tool, str(res))
-                except Exception:
-                    pass
-            
-            if not audit_passed:
-                logging.warning(f"Fleet: Security audit FAILED for tool '{best_tool}'. Penalizing RLSelector.")
-                if self.rl_selector:
-                    self.rl_selector.update_stats(best_tool, success=False)
-                return f"ERROR: Security audit failed for tool '{best_tool}'. Output blocked."
-
-            if self.rl_selector:
-                self.rl_selector.update_stats(best_tool, success=True)
-            # Record for future improvements
-            await self._record_success(f"Capability call: {goal} with {kwargs}", str(res), "internal_ai")
-            return res
-        except Exception as e:
-            if self.rl_selector:
-                self.rl_selector.update_stats(best_tool, success=False)
-            logging.error(f"Error executing tool {best_tool}: {e}")
-            # Self-healing attempt
-            if self.self_healing:
-                target_agent = owner if owner else best_tool
-                clean_kwargs = {k: v for k, v in kwargs.items() if k != "agent_name"}
-                if asyncio.iscoroutinefunction(self.self_healing.attempt_repair):
-                    return await self.self_healing.attempt_repair(target_agent, e, **clean_kwargs)
-                else:
-                    return self.self_healing.attempt_repair(target_agent, e, **clean_kwargs)
-            return f"Error executing tool {best_tool}: {e}"
-        finally:
-            if hasattr(self, 'telemetry'):
-                self.telemetry.trace_workflow(f"tool_{best_tool}", time.time() - start_time)
-        
+        return await self.routing_core.call_by_capability(goal, **kwargs)
+
     def register_agent(self, name: str, agent_class: type[BaseAgent], file_path: str | None = None) -> str:
         """Adds an agent to the fleet."""
         return self.lifecycle_manager.register_agent(name, agent_class, file_path)
 
     # --- Biological Cell-Swarm Pattern (Phase 17) ---
-    
+
     def cell_divide(self, agent_name: str) -> str:
         """Simulates biological mitosis."""
         return self.lifecycle_manager.cell_divide(agent_name)
@@ -500,119 +331,51 @@ class FleetManager:
         """Runs a sequence of agent actions with shared state and signals."""
         return await self.execution_core.execute_workflow(task, workflow_steps, priority=priority)
 
-    def execute_with_consensus(self, task: str, primary_agent: str = None, secondary_agents: list[str] = None) -> dict[str, Any]:
+    def execute_with_consensus(self, task: str, primary_agent: str | None = None, secondary_agents: list[str] | None = None) -> dict[str, Any]:
         """
         Executes a task across multiple agents and uses ByzantineConsensusAgent to pick the winner.
-        If agents are not specified, ByzantineConsensusAgent dynamically selects a committee. (Phase 123)
         """
-        logging.info(f"Fleet: Running consensus vote for task: {task[:50]}")
-        
-        # Phase 123: Dynamic Committee Formation
-        if not primary_agent or not secondary_agents:
-            # Look in both registry configs (bootstrap) and currently loaded/discovered agents
-            available = list(set(list(self.agents.registry_configs.keys()) + list(self.agents.keys())))
-            # Exclude judge and self
-            available = [a for a in available if a not in ["ByzantineConsensus", "ByzantineConsensusAgent", "FleetManager"]]
-            
-            # Use case-insensitive lazy access (ByzantineConsensus)
-            judge = getattr(self, "ByzantineConsensus", None)
-            if not judge:
-                # Attempt to find it by variant names
-                for name in ["byzantine_judge", "ByzantineConsensusAgent"]:
-                    judge = getattr(self, name, None)
-                    if judge:
-                        break
-            
-            if not judge:
-                return {"decision": "REJECTED", "reason": "ByzantineConsensus agent not available."}
-                
-            committee = judge.select_committee(task, available)
-            if not committee:
-                return {"decision": "REJECTED", "reason": "No committee could be formed."}
-            primary_agent = committee[0]
-            secondary_agents = committee[1:]
-            logging.info(f"Fleet: Formed dynamic committee: {primary_agent}, {secondary_agents}")
-
-        proposals: dict[str, str] = {}
-        all_agents = [primary_agent] + secondary_agents
-        
-        for agent_name in all_agents:
-            if agent_name in self.agents:
-                try:
-                    # Defaulting to 'improve_content' for the consensus pool
-                    res = self.agents[agent_name].improve_content(task)
-                    proposals[agent_name] = res
-                except Exception as e:
-                    logging.error(f"Fleet: Agent {agent_name} failed to provide consensus proposal: {e}")
-
-        if not proposals:
-            return {"decision": "REJECTED", "reason": "No agents could provide proposals."}
-
-        # Run the committee vote
-        # Use the judge found earlier or the lazy access
-        if 'judge' not in locals():
-            judge = getattr(self, "ByzantineConsensus", None)
-            
-        if not judge:
-            return {"decision": "REJECTED", "reason": "ByzantineConsensus not found for voting."}
-
-        result = judge.run_committee_vote(task, proposals)
-        
-        # If success, broadcast lesson via Federated Knowledge
-        if result["decision"] == "ACCEPTED" and getattr(self, "federated_knowledge", None):
-            try:
-                self.federated_knowledge.broadcast_lesson(
-                    lesson_id=f"consensus_{int(time.time())}",
-                    lesson_data={
-                        "agent": result.get("winner"),
-                        "task_type": "high_integrity_code",
-                        "success": True,
-                        "fix": f"Consensus reached by {result.get('winner')} for {task[:30]}"
-                    }
-                )
-            except Exception:
-                pass
-            
-        return result
+        return self.consensus_manager.execute_with_consensus(task, primary_agent, secondary_agents)
 
     def route_task(self, task_type: str, task_data: Any) -> str:
+
+
+
+
+
         """
         Routes tasks based on system load and hardware availability (Phase 126).
         """
-        stats = self.telemetry.orchestrator.monitor.get_current_stats()
-        
-        # Logic for compute-heavy tasks (e.g., training, large-scale indexing)
-        is_compute_heavy = task_type in ["training", "indexing", "llm_finetune"]
-        
-        if is_compute_heavy and stats["gpu"]["available"]:
-            logging.info(f"Fleet: Routing {task_type} to GPU node ({stats['gpu']['type']})")
-            return f"ROUTED:GPU:{stats['gpu']['type']}"
-        elif is_compute_heavy and stats["status"] == "CRITICAL":
-            logging.warning("Fleet: System critical, deferring compute-heavy task.")
-            return "DEFERRED:LOAD_CRITICAL"
-        
-        logging.info(f"Fleet: Routing {task_type} to standard CPU pool.")
-        return "ROUTED:CPU:POOL"
+        return self.routing_core.route_task(task_type, task_data)
+
+
+
+
+
 
 if __name__ == "__main__":
     # Test script for FleetManager
     logging.basicConfig(level=logging.INFO)
     root = Path(str(Path(__file__).resolve().parents[3]) + "")
     fleet = FleetManager(str(root))
-    
+
     # These agents are used for the demo below
     from src.logic.agents.cognitive.KnowledgeAgent import KnowledgeAgent
     from src.logic.agents.development.SecurityGuardAgent import SecurityGuardAgent
 
     fleet.register_agent("Knowledge", KnowledgeAgent, str(root / "src/logic/agents/cognitive/KnowledgeAgent.py"))
     fleet.register_agent("Security", SecurityGuardAgent, str(root / "src/logic/agents/development/SecurityGuardAgent.py"))
-    
+
     workflow = [
         {"agent": "Knowledge", "action": "scan_workspace", "args": ["KnowledgeAgent"]},
         {"agent": "Security", "action": "improve_content", "args": ["password = os.environ.get('DB_PASSWORD')"]}
     ]
-    
-    report = fleet.execute_workflow("Initial Audit", workflow)
-    print(report)
-    print("\nTelemetry Summary:")
-    print(json.dumps(fleet.telemetry.get_summary(), indent=2))
\ No newline at end of file
+
+    # report = fleet.execute_workflow("Initial Audit", workflow) # Async call, requires await or asyncio.run
+    # For now, just logging calls replacement
+    logger.info("FleetManager demo execution started")
+    # print(report)
+    # print("\nTelemetry Summary:")
+    # print(json.dumps(fleet.telemetry.get_summary(), indent=2))
+    if hasattr(fleet, 'telemetry'):
+         logger.info("Telemetry Summary", summary=fleet.telemetry.get_summary())

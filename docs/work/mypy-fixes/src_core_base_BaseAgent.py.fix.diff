diff --git a/src/core/base/BaseAgent.py b/src/core/base/BaseAgent.py
index 7304271..0d5b138 100644
--- a/src/core/base/BaseAgent.py
+++ b/src/core/base/BaseAgent.py
@@ -11,16 +11,6 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# limitations under the License.
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# limitations under the License.
 
 """BaseAgent main class and core agent logic."""
 
@@ -29,16 +19,13 @@ from src.core.base.version import VERSION
 from src.core.base.utilities import as_tool
 from src.core.base.exceptions import CycleInterrupt
 import logging
-from src.core.base.ConnectivityManager import ConnectivityManager
-import os
 import asyncio
 import subprocess
 import sys
 import time
-from datetime import datetime
 from pathlib import Path
 from types import TracebackType
-from typing import Any, Dict, List, Optional, cast
+from typing import Any
 from collections.abc import Callable
 from src.core.base.models import (
     AgentConfig,
@@ -58,9 +45,10 @@ from src.core.base.BaseAgentCore import BaseAgentCore
 from src.core.base.registry import AgentRegistry
 from src.core.base.ShardedKnowledgeCore import ShardedKnowledgeCore
 from src.core.base.state import AgentStateManager
-from src.core.base.verification import AgentVerifier
 from src.core.base.delegation import AgentDelegator
 from src.core.base.shell import ShellExecutor
+from src.core.base.scratchpad import AgentScratchpad
+from src.core.base.history import AgentConversationHistory
 # from src.infrastructure.backend.LocalContextRecorder import LocalContextRecorder # Moved to __init__
 from src.core.base.managers.ResourceQuotaManager import ResourceQuotaManager, QuotaConfig
 
@@ -83,51 +71,10 @@ except (ImportError, ValueError):
 
 __version__ = VERSION
 
-def fix_markdown_content(content: str) -> str:
-    """Fix markdown formatting in content."""
-    # Basic markdown fixes - can be extended
-    return content
-
 # Advanced components (Lazy loaded or optional)
 
 class BaseAgent:
-    """Base class for all AI-powered agents.
-
-    Provides common functionality for agents that use AI backends to improve
-    code files, documentation, tests, and other artifacts. Handles file I/O,
-    diff generation, and integration with AI services.
-
-    Supports context manager protocol for automatic resource cleanup.
-
-    Attributes:
-        file_path (Path): Path to the file being improved.
-        previous_content (str): Original file content before improvements.
-        current_content (str): Improved file content after agent processing.
-
-    Subclasses:
-        - CoderAgent: Improves source code files
-        - TestsAgent: Generates and improves test files
-        - ChangesAgent: Manages changelog documentation
-        - ContextAgent: Manages context/description files
-        - ErrorsAgent: Analyzes and documents errors
-        - ImprovementsAgent: Suggests code improvements
-        - StatsAgent: Collects and reports statistics
-
-    Example:
-        class MyAgent(BaseAgent):
-            def _get_default_content(self) -> bool:
-                return "# New File\\n"
-
-        with MyAgent('path/to/file.md') as agent:
-            agent.improve_content("Make it better")
-            agent.update_file()
-
-    Note:
-        - Automatically detects markdown files for formatting cleanup
-        - Provides fallback responses when AI backend unavailable
-        - Supports multiple AI backends via execution_engine (Phase 314)
-        - Can be used as context manager for automatic cleanup
-    """
+    """Shell class for AI-powered agents. Logic delegated to BaseAgentCore."""
 
     # Class-level attributes for shared state
     _prompt_templates: dict[str, PromptTemplate] = {}
@@ -135,18 +82,29 @@ class BaseAgent:
     _plugins: dict[str, Any] = {}
     _event_hooks: dict[EventType, list[Callable[[dict[str, Any]], None]]] = {}
 
-    def __init__(self, file_path: str) -> None:
+    def __init__(self, file_path: str, **kwargs: Any) -> None:
         """Initialize the BaseAgent with file path.
 
         Args:
             file_path: Path to the file to improve. Can be absolute or relative.
                       Will be converted to pathlib.Path object.
-
-        Note:
-            Automatically reads previous content on initialization.
-            Supports context manager protocol via __enter__ and __exit__.
+            **kwargs: Additional arguments for backward compatibility/testing.
+                      Supported: repo_root, dry_run
         """
         self.file_path = Path(file_path)
+        
+        # Handle repo_root override (useful for tests)
+        if "repo_root" in kwargs:
+             self._workspace_root = kwargs["repo_root"]
+        else:
+             self._workspace_root = BaseCore.detect_workspace_root(self.file_path)
+             
+        # Handle dry_run in config if passed
+        self._dry_run_init = kwargs.get("dry_run", False)
+
+        self.agent_logic_core = BaseAgentCore()  # Pure logic core (Rust-convertible)
+        self.core = BaseCore(workspace_root=self._workspace_root)
+        
         self.previous_content: str = ""
         self.current_content: str = ""
         self.fleet: Any = None # FleetManager reference
@@ -172,8 +130,8 @@ class BaseAgent:
 
         # New attributes for enhanced functionality
         self._state: AgentState = AgentState.INITIALIZED
-        self._conversation_history: list[ConversationMessage] = []
-        self._scratchpad: list[str] = [] # Confucius-style persistent notes (Phase 128)
+        self._history_manager = AgentConversationHistory()
+        self._scratchpad_manager = AgentScratchpad()
         self._config: AgentConfig = self._load_config()
         self._token_usage = 0
         self._state_data: dict[str, Any] = {}
@@ -190,15 +148,8 @@ class BaseAgent:
             )
         )
         
-        # Determine Workspace Root (Phase 108: Robust detection delegated to Core)
-        self._workspace_root = BaseCore.detect_workspace_root(self.file_path)
-        
         self._local_global_context = None
 
-        # Initialize Core Logic (Potential Rust Target)
-        self.core = BaseCore(workspace_root=self._workspace_root)
-        self.agent_logic_core = BaseAgentCore()  # Pure logic core (Rust-convertible)
-
         # Advanced features
         # Derive agent name for data isolation (e.g., CoderAgent -> "coder")
         self.agent_name = self.__class__.__name__.lower().replace("agent", "") or "base"
@@ -220,91 +171,103 @@ class BaseAgent:
             import asyncio
             from src.infrastructure.orchestration.SignalRegistry import SignalRegistry
             signals = SignalRegistry()
+            
+            payload = self.agent_logic_core.prepare_capability_payload(
+                self.__class__.__name__, 
+                self.get_capabilities()
+            )
+
             # Schedule the async emit to run in the background
             try:
-                loop = asyncio.get_event_loop()
+                try:
+                    loop = asyncio.get_running_loop()
+                except RuntimeError:
+                    loop = asyncio.new_event_loop()
+                    asyncio.set_event_loop(loop)
+                
                 if loop.is_running():
-                    asyncio.create_task(signals.emit("agent_capability_registration", {
-                        "agent": self.__class__.__name__,
-                        "capabilities": self.get_capabilities()
-                    }))
+                    asyncio.create_task(signals.emit("agent_capability_registration", payload))
                 else:
-                    loop.run_until_complete(signals.emit("agent_capability_registration", {
-                        "agent": self.__class__.__name__,
-                        "capabilities": self.get_capabilities()
-                    }))
-            except RuntimeError:
-                # No event loop available, skip signal emission
+                    loop.run_until_complete(signals.emit("agent_capability_registration", payload))
+            except Exception:
                 pass
         except Exception:
             pass
 
-    # PHASE 260: Preemption Logic
     def suspend(self) -> None:
-        """Gracefully suspends the agent's work."""
-        if not self._suspended:
-            logging.warning(f"Agent {self.__class__.__name__} SUSPENDED due to preemption.")
-            self._suspended = True
+        self._suspended = True
 
     def resume(self) -> None:
-        """Resumes the agent's work."""
-        if self._suspended:
-            logging.info(f"Agent {self.__class__.__name__} RESUMED.")
-            self._suspended = False
+        self._suspended = False
+
+    def log_distributed(self, level: str, message: str, **kwargs) -> None:
+        """Publishes a log to the distributed logging system."""
+        if hasattr(self, "fleet") and self.fleet:
+             logging_agent = self.fleet.agents.get("Logging")
+             if logging_agent:
+                 import asyncio
+                 try:
+                     loop = asyncio.get_running_loop()
+                     loop.create_task(logging_agent.broadcast_log(level, self.__class__.__name__, message, kwargs))
+                 except RuntimeError:
+                     asyncio.run(logging_agent.broadcast_log(level, self.__class__.__name__, message, kwargs))
 
     async def _check_preemption(self) -> None:
-        """Wait while the agent is suspended."""
-        import asyncio
         while self._suspended:
             await asyncio.sleep(0.5)
 
     def get_capabilities(self) -> list[str]:
-        """Phase 241: Returns a list of strings representing agent capabilities."""
         return self.capabilities
 
     @property
     def strategy(self) -> Any:
-        """Strategy for agent execution (Phase 130: Lazy-loaded to avoid core-on-logic dependency)."""
         if not hasattr(self, "_strategy") or self._strategy is None:
-            # Deferred import to break core-on-logic dependency
             try:
-                from src.logic.strategies import plan_executor as agent_strategies
-                self._strategy = agent_strategies.DirectStrategy()
+                from src.logic.strategies.DirectStrategy import DirectStrategy
+                self._strategy = DirectStrategy()
             except (ImportError, ModuleNotFoundError):
-                # Fallback if logic is not available
                 self._strategy = None
         return self._strategy
 
+    @classmethod
+    def from_config_file(cls, config_path: Path) -> BaseAgent:
+        """Create an agent instance from a configuration file.
+        
+        Args:
+             config_path: Path to the JSON configuration file.
+             
+        Returns:
+             Initialized Agent.
+        """
+        import json
+        try:
+             config = json.loads(Path(config_path).read_text())
+             repo_root = config.get("repo_root", None)
+             # file_path is mandatory, assuming the config file itself acts as the 'file' or config specifies it
+             # Attempt to derive file_path from config, or use config_path as dummy
+             file_path = config.get("file_path", str(config_path))
+             return cls(file_path, repo_root=repo_root)
+        except Exception as e:
+             logging.error(f"Failed to load agent from config {config_path}: {e}")
+             raise
+
     @strategy.setter
     def strategy(self, value: Any) -> None:
         self._strategy = value
 
-    def _run_command(self, cmd: list[str], timeout: int = 120, max_retries: int = 1) -> subprocess.CompletedProcess[str]:
-        """Run a command with timeout, error handling, retry logic, and logging."""
-        return ShellExecutor.run_command(
-            cmd=cmd,
-            workspace_root=self._workspace_root,
-            agent_name=self.__class__.__name__,
-            models_config=getattr(self, 'models', None),
-            recorder=getattr(self, 'recorder', None),
-            timeout=timeout,
-            max_retries=max_retries
-        )
+    def _run_command(self, cmd: list[str], timeout: int = 120) -> subprocess.CompletedProcess[str]:
+        models_config = getattr(self, 'models', None)
+        return ShellExecutor.run_command(cmd, self._workspace_root, self.agent_name, models_config=models_config, timeout=timeout)
 
     @property
-    def global_context(self) -> str:
-        """Lazy-loaded GlobalContextEngine, preferring Fleet's shared instance."""
-        # Prefer fleet-injected context
+    def global_context(self) -> Any:
         if hasattr(self, 'fleet') and self.fleet and hasattr(self.fleet, 'global_context'):
             return self.fleet.global_context
-            
-        # Fallback to local lazy loading
         if self._local_global_context is None:
              try:
                 from src.logic.agents.cognitive.context.engines.GlobalContextEngine import GlobalContextEngine
                 self._local_global_context = GlobalContextEngine(self._workspace_root)
-             except (ImportError, ValueError):
-                pass
+             except (ImportError, ValueError): pass
         return self._local_global_context
 
     @global_context.setter
@@ -312,123 +275,52 @@ class BaseAgent:
         self._local_global_context = value
 
     def register_tools(self, registry: ToolRegistry) -> None:
-        """
-        Registers all methods decorated with @as_tool with the provided registry.
-        """
-        if not registry:
-            return
-
-        import inspect
-        for name, method in inspect.getmembers(self, predicate=inspect.ismethod):
-            if hasattr(method, '_is_tool') and method._is_tool:
-                # Default category from class name (e.g. LinguisticAgent -> linguistic)
-                category: str = self.__class__.__name__.replace('Agent', '').lower()
-                
-                # Check for explicit category overridden on method
-                if hasattr(method, '_tool_category'):
-                    category = method._tool_category
-                
-                # Check for priority
-                priority: int = getattr(method, '_tool_priority', 0)
-                    
-                registry.register_tool(
-                    func=method,
-                    owner_name=self.__class__.__name__,
-                    category=category,
-                    priority=priority
-                )
+        if not registry: return
+        for method, cat, prio in self.agent_logic_core.collect_tools(self):
+            # Fix: Correct order is (owner_name, func, category, priority)
+            registry.register_tool(self.__class__.__name__, method, cat, prio)
 
     def calculate_anchoring_strength(self, result: str) -> float:
-        """
-        Calculates the 'Anchoring Strength' metric (Stanford Research 2025).
-        Delegates to pure logic core.
-        """
         return self.agent_logic_core.calculate_anchoring_strength(result, getattr(self, 'context_pool', {}))
 
     def verify_self(self, result: str) -> tuple[bool, str]:
-        """
-        Self-verification layer (inspired by Keio University 2026 research).
-        Delegates to pure logic core.
-        """
         return self.agent_logic_core.verify_self(result)
 
     def _load_config(self) -> AgentConfig:
-        """Load agent configuration from environment variables."""
-        return AgentConfig(
-            backend=os.environ.get("DV_AGENT_BACKEND", "auto"),
-            model=os.environ.get("DV_AGENT_MODEL", ""),
-            max_tokens=int(os.environ.get("DV_AGENT_MAX_TOKENS", "4096")),
-            temperature=float(os.environ.get("DV_AGENT_TEMPERATURE", "0.7")),
-            retry_count=int(os.environ.get("DV_AGENT_RETRY_COUNT", "3")),
-            timeout=int(os.environ.get("DV_AGENT_TIMEOUT", "60")),
-            cache_enabled=os.environ.get("DV_AGENT_CACHE", "true").lower() == "true",
-            token_budget=int(os.environ.get("DV_AGENT_TOKEN_BUDGET", "100000")),
-        )
+        return self.agent_logic_core.load_config_from_env()
 
     def set_strategy(self, strategy: Any) -> None:
-        """Set the reasoning strategy for the agent.
-
-        Args:
-            strategy: An instance of AgentStrategy (e.g., DirectStrategy, ChainOfThoughtStrategy).
-        """
         self.strategy = strategy
-        msg = self.agent_logic_core.set_strategy(strategy)
-        logging.info(msg)
+        logging.info(self.agent_logic_core.set_strategy(strategy))
 
     @property
     def state(self) -> AgentState:
-        """Get current agent state."""
         return self._state
 
     def set_model(self, model: str) -> None:
-        """Set the model to use for this agent.
-
-        Args:
-            model: Model identifier (e.g., "gpt-4", "claude-3").
-        """
         self._model = model
         logging.debug(f"Model set to: {model}")
 
     def _track_tokens(self, input_tokens: int, output_tokens: int) -> None:
-        """Simulates recording token usage for telemetry."""
-        self._last_token_usage = {
-            "input": input_tokens,
-            "output": output_tokens,
-            "model": self.get_model() or "gpt-4o"
-        }
+        self._last_token_usage = self.agent_logic_core.process_token_tracking(
+            input_tokens, output_tokens, self.get_model() or "gpt-4o"
+        )
 
     def get_model(self) -> str | None:
-        """Get the currently configured model."""
         return self._model or self._config.model or None
 
     def __enter__(self) -> BaseAgent:
-        """Context manager entry. Returns self for use in 'with' statement."""
-        logging.debug(f"{self.__class__.__name__} entering context manager")
         AgentRegistry().register(self)
         return self
 
-    def __exit__(
-        self,
-        exc_type: type[BaseException] | None,
-        exc_val: BaseException | None,
-        exc_tb: TracebackType | None,
-    ) -> bool:
-        """Context manager exit. Handles cleanup if needed.
-
-        Note:
-            - Logs any exceptions that occurred
-            - Does not suppress exceptions
-            - Can be overridden in subclasses for custom cleanup
-        """
-        logging.debug(f"{self.__class__.__name__} exiting context manager")
+    def __exit__(self, exc_type: type[BaseException] | None, exc_val: BaseException | None, exc_tb: TracebackType | None) -> bool:
         AgentRegistry().unregister(self.agent_name)
         if exc_type is not None:
-            logging.error(f"Agent context error: {exc_type.__name__}: {exc_val}")
-            self._state: AgentState = AgentState.ERROR
+            self._state = AgentState.ERROR
             self._trigger_event(EventType.ERROR, {"exception": exc_val})
         else:
-            self._state: AgentState = AgentState.COMPLETED
-        return False  # Don't suppress exceptions
+            self._state = AgentState.COMPLETED
+        return False
 
     def stop(self) -> None:
         """Request the agent to stop its current operation."""
@@ -438,313 +330,155 @@ class BaseAgent:
     def register_webhook(self, url: str) -> None:
         """Registers a webhook URL for notifications."""
         if not hasattr(self, '_webhooks'):
-             self._webhooks = []
+             self._webhooks: list[Any] = []
         if url not in self._webhooks:
             self._webhooks.append(url)
 
     def run(self, prompt: str = "") -> None:
-        """Standard execution loop for the agent.
-        
-        This method is primarily used by the GUI to run any agent in a thread.
-        It calls improve_content() and then update_file() if not stopped.
-        """
         self._is_stop_requested = False
         try:
-            self.improve_content(prompt)
-            if not self._is_stop_requested:
-                self.update_file()
-            else:
-                logging.info(f"Update skipped for {self.__class__.__name__} due to stop request.")
+            import asyncio
+            coro = self.improve_content(prompt)
             
-            # Phase 123: Trigger completion event for webhooks
-            event_data = {
-                "event": "agent_complete",
-                "status": "success",
-                "file": str(self.file_path),
-                "timestamp": time.time()
-            }
+            try:
+                loop = asyncio.get_event_loop()
+            except RuntimeError:
+                loop = asyncio.new_event_loop()
+                asyncio.set_event_loop(loop)
+
+            if loop.is_running():
+                # If loop is already running, we can't block.
+                # Use a task but we won't wait for it here, which is better than just a warning
+                # but still not ideal for a sync 'run' method.
+                asyncio.create_task(coro)
+            else:
+                loop.run_until_complete(coro)
+
+            if not self._is_stop_requested: self.update_file()
             webhooks = getattr(self, '_webhooks', [])
             for url in webhooks:
-                try:
-                    if HAS_REQUESTS and requests:
-                        requests.post(url, json=event_data, timeout=5)
-                        logging.info(f"Webhook sent to {url}")
-                except Exception as e:
-                    logging.error(f"Failed to send webhook to {url}: {e}")
-                    
+                if HAS_REQUESTS and requests:
+                    requests.post(url, json={"event": "agent_complete", "status": "success", "file": str(self.file_path), "timestamp": time.time()}, timeout=5)
         except Exception as e:
             logging.error(f"Error running {self.__class__.__name__}: {e}")
             raise
 
     def read_previous_content(self) -> str:
-        """Read the existing file content from disk.
-
-        Reads the file specified by file_path, storing content in previous_content.
-        If file doesn't exist, loads default content for new files.
-
-        Returns:
-            str: The read content (same as previous_content attribute).
-
-        Raises:
-            None. Logs errors but doesn't raise. Returns empty string on failure.
-
-        Note:
-            - Uses UTF-8 encoding
-            - Handles missing files gracefully
-            - Automatically handles encoding errors
-        """
-        self._state: AgentState = AgentState.READING
+        """Read existing file content."""
+        self._state = AgentState.READING
         self._trigger_event(EventType.PRE_READ, {"file_path": str(self.file_path)})
 
-        if self.file_path.is_file():
-            try:
-                logging.debug(f"Reading content from {self.file_path}")
-                self.previous_content: str = self.file_path.read_text(encoding='utf-8')
-                logging.info(f"Read {len(self.previous_content)} bytes from {self.file_path.name}")
-            except Exception as e:
-                # Diagnostic logging for file read failures
-                error_info = []
-                if not os.access(self.file_path, os.R_OK):
-                    error_info.append("Permission denied (Read)")
-                try:
-                    stats: os.stat_result = self.file_path.stat()
-                    error_info.append(f"Size: {stats.st_size} bytes")
-                except Exception:
-                    logging.warning(f"Could not retrieve additional stats for {self.file_path}")
-                
-                diag_msg: str = f"Failed to read file {self.file_path}: {e}"
-                if error_info:
-                    diag_msg += f" ({'; '.join(error_info)})"
-                logging.error(diag_msg)
-                self.previous_content: str = ""
-        elif self.file_path.is_dir():
-            logging.debug(f"Target path {self.file_path} is a directory, using default content.")
-            self.previous_content: str = self._get_default_content()
-        else:
-            logging.debug(f"File does not exist, using default content: {self.file_path}")
-            self.previous_content: str = self._get_default_content()
+        try:
+            if self.file_path.is_file():
+                self.previous_content = self.file_path.read_text(encoding='utf-8')
+            else:
+                logging.warning(f"File not found: {self.file_path}. Using default content.")
+                self.previous_content = self._get_default_content()
+        except Exception as e:
+            logging.error(f"Failed to read file {self.file_path}: {e}")
+            import traceback
+            traceback.print_exc()
+            self.previous_content = ""
 
         self._trigger_event(EventType.POST_READ, {"content_length": len(self.previous_content)})
         return self.previous_content
 
     def _get_default_content(self) -> str:
-        """Return default content for new files.
-
-        Provides a template for new files when they don't exist yet.
-        Override in subclasses to provide agent-specific defaults.
-
-        Returns:
-            str: Default content template for the file type.
-
-        Example:
-            class TestsAgent(BaseAgent):
-                def _get_default_content(self) -> str:
-                    return "# Tests\n\n# Add tests here\n"
-
-        Note:
-            Called automatically by read_previous_content() for missing files.
-        """
-        return self.core.get_default_content(filename=self.file_path.name)
+        """Return default content template."""
+        return self.agent_logic_core.get_default_content(filename=self.file_path.name)
 
     def think(self, prompt: str, system_prompt: str | None = None) -> str:
-        """
-        Generic reasoning method that doesn't involve file updates.
-        Useful for planning, data generation, or internal reasoning.
-        """
+        """Generic reasoning method that doesn't involve file updates."""
         self._state: AgentState = AgentState.THINKING
-        
-        # Broadcast thought to SignalBus if available
         if hasattr(self, 'registry') and self.registry:
-            try:
-                # We can't use self.signal_bus directly here easily as it's in FleetManager usually
-                # But we can emit a signal via the registry if it exists
-                self.registry.emit("thought_stream", {
-                    "agent": self.__class__.__name__,
-                    "thought": prompt[:100] + "..."
-                })
-            except Exception:
-                logging.debug("Registry signal emission failed in think().")
+            self.registry.emit("thought_stream", {"agent": self.__class__.__name__, "thought": prompt[:100]})
 
-        description: str = f"Reasoning for {self.__class__.__name__}"
-        result: str = self.run_subagent(description, prompt, system_prompt or self._system_prompt)
+        import asyncio
+        coro = self.run_subagent(f"Reasoning: {self.__class__.__name__}", prompt, system_prompt or self._system_prompt)
         
-        self._state: AgentState = AgentState.IDLE
-        return result
+        # Handle async execution from sync context
+        try:
+            loop = asyncio.get_event_loop()
+        except RuntimeError:
+            loop = asyncio.new_event_loop()
+            asyncio.set_event_loop(loop)
+
+        if loop.is_running():
+            # If loop is already running, we can't block. 
+            # Phase 21: Create a task to avoid "never awaited" warning
+            asyncio.create_task(coro)
+            import logging
+            logging.warning("BaseAgent.think() called from running loop. Returning empty string.")
+            return ""
+        
+        try:
+            result = loop.run_until_complete(coro)
+            self._state: AgentState = AgentState.IDLE
+            return result
+        except RuntimeError as e:
+            # Fallback if we really can't await
+            import logging
+            logging.error(f"BaseAgent.think() failed to await async result: {e}")
+            return ""
 
     async def improve_content(self, prompt: str) -> str:
         """Use AI to improve the content."""
         self._state: AgentState = AgentState.PROCESSING
         self._trigger_event(EventType.PRE_IMPROVE, {"prompt": prompt})
 
-        # Phase 279/278: Mutation detection (Validation before processing)
-        try:
-            from src.core.base.IncrementalProcessor import IncrementalProcessor
-            proc = IncrementalProcessor(repo_root=self._workspace_root)
-            mutated = proc.validate_hashes([self.file_path])
-            if mutated:
-                logging.warning(f"BaseAgent: Mutation detected in {self.file_path} during processing. Reloading content.")
-                if self.file_path.exists():
-                    self.previous_content = self.file_path.read_text(encoding="utf-8")
-        except Exception as e:
-            logging.debug(f"BaseAgent: Mutation check failed: {e}")
-
-        # Phase 260: Preemption check
+        # Pre-processing: Preemption and Quotas
         await self._check_preemption()
-        
-        # Phase 245: Increment cycle count
         self.quotas.update_usage(cycles=1)
 
-        # Check cache first if enabled
+        # Cache check
         cache_key: str = self._generate_cache_key(prompt, self.previous_content)
         if self._config.cache_enabled and cache_key in BaseAgent._response_cache:
-            cached: CacheEntry = BaseAgent._response_cache[cache_key]
-            cached.hit_count += 1
-            logging.debug(f"Cache hit for prompt (hits: {cached.hit_count})")
-            self.current_content: str = cached.response
+            self.current_content = BaseAgent._response_cache[cache_key].response
             return self.current_content
 
-        class_name: str = self.__class__.__name__.replace('Agent', '').lower()
-        description: str = f"Improve the {class_name} for {self.file_path.stem}"
         try:
-            logging.info(f"Improving content with prompt: {prompt[:50]}...")
-
-            # Integrate Long-Term Memory
-            memory_context: str = ""
+            # Memory Integration
+            memory_docs = []
             if self.memory:
-                try:
-                    memories: list[dict[str, Any]] = self.memory.query(prompt, n_results=3)
-                    if memories:
-                        memory_docs: list[Any] = [m.get("content", "") for m in memories]
-                        memory_context: str = "\n\n### Related Past Memories\n" + "\n".join(memory_docs)
-                        logging.info(f"Found {len(memories)} relevant memories for context.")
-                except Exception as me:
-                    logging.warning(f"Memory retrieval failed: {me}")
-
-            # Add conversation context if available
-            full_prompt: str = self._build_prompt_with_history(prompt) + memory_context
-
-            # Define backend callable for strategy (Phase 287: Async refactor)
-            async def backend_callable(p: str, sp: str | None = None, h: list[dict[str, str]] | None = None) -> str:
-                return await self.run_subagent(description, p, self.previous_content)
+                memories = self.memory.query(prompt, n_results=3)
+                memory_docs = [m.get("content", "") for m in memories]
 
-            # Execute strategy
-            improvement: str = await self.strategy.execute(
-                prompt=full_prompt,
-                context=self.previous_content,
-                backend_call=backend_callable
+            full_prompt = self.agent_logic_core.prepare_improvement_prompt(
+                prompt, memory_docs, self._history_manager.get_messages(), self._system_prompt
             )
 
-            # Apply post-processors
-            for processor in self._post_processors:
-                improvement: str = processor(improvement)
+            async def backend_callable(p: str, sp: str | None = None, h: list[dict[str, str]] | None = None) -> str:
+                return await self.run_subagent(f"Improve {self.file_path.stem}", p, self.previous_content)
 
-            # Score response quality
-            quality: ResponseQuality = self._score_response_quality(improvement)
+            improvement = await self.strategy.execute(full_prompt, self.previous_content, backend_callable)
+            improvement = self.agent_logic_core.finalize_improvement(improvement, self._post_processors)
 
-            # Retry if quality is poor
+            # Quality Check and Retry
+            quality = self._score_response_quality(improvement)
             if quality.value <= ResponseQuality.POOR.value and self._config.retry_count > 0:
-                logging.warning(f"Response quality {quality.name}, retrying...")
                 for _ in range(self._config.retry_count):
-                    improvement: str = await self.run_subagent(description, full_prompt, self.previous_content)
-                    quality: ResponseQuality = self._score_response_quality(improvement)
-                    if quality.value >= ResponseQuality.ACCEPTABLE.value:
+                    improvement = await self.run_subagent(f"Retry {self.file_path.stem}", full_prompt, self.previous_content)
+                    if self._score_response_quality(improvement).value >= ResponseQuality.ACCEPTABLE.value:
                         break
 
-            self.current_content: str = improvement
-
-            # Cache the response
+            self.current_content = improvement
             if self._config.cache_enabled:
-                BaseAgent._response_cache[cache_key] = CacheEntry(
-                    key=cache_key,
-                    response=improvement,
-                    timestamp=time.time(),
-                    quality_score=quality.value
-                )
-
-            # Add to conversation history
-            self._conversation_history.append(ConversationMessage(role=MessageRole.USER, content=prompt))
-            self._conversation_history.append(ConversationMessage(
-                role=MessageRole.ASSISTANT, content=improvement[:500]))
-
-            logging.info(f"Content improved successfully ({len(improvement)} bytes)")
-            self._trigger_event(EventType.POST_IMPROVE, {"quality": quality.name})
-            
-            # Emit signal for success
-            if self.registry:
-                try:
-                    self.registry.emit("improvement_ready", self.__class__.__name__, {
-                        "file": str(self.file_path),
-                        "prompt": prompt[:100]
-                    })
-                except Exception as se:
-                    logging.warning(f"Signal emission failed: {se}")
-            
-            # Save to memory if significant
-            if self.memory and len(self.current_content) > 100:
-                try:
-                    self.memory.store(
-                        f"Agent {self.__class__.__name__} improved {self.file_path.name} based on prompt: {prompt[:100]}",
-                        {"file": str(self.file_path), "action": "improve"}
-                    )
-                except Exception as me:
-                    logging.warning(f"Memory storage failed: {me}")
-
-            # Phase 108: Record interaction for logic harvesting
-            self._record(
-                prompt=f"Task: {description}\nContext: {prompt}\nMem: {memory_context[:100]}",
-                result=self.current_content[:1000] + ("..." if len(self.current_content) > 1000 else ""),
-                provider="AI-Backend",
-                model=self.__class__.__name__
-            )
+                BaseAgent._response_cache[cache_key] = CacheEntry(cache_key, improvement, time.time(), quality.value)
 
+            self.add_to_history(MessageRole.USER.value, prompt)
+            self.add_to_history(MessageRole.ASSISTANT.value, improvement[:500])
+            self._trigger_event(EventType.POST_IMPROVE, {"quality": quality.name})
             return self.current_content
+
         except Exception as e:
-            logging.warning(f"Failed to improve content: {e}")
-            
-            # Emit signal for failure
-            if self.registry:
-                try:
-                    self.registry.emit("agent_fail", self.__class__.__name__, {
-                        "file": str(self.file_path),
-                        "error": str(e)
-                    })
-                except Exception:
-                    pass
-
-            self.current_content: str = self.previous_content
+            logging.warning(f"Improvement failed: {e}")
+            self.current_content = self.previous_content
             return self.current_content
 
     async def run_subagent(self, description: str, prompt: str, original_content: str = "") -> str:
-        """Run a subagent using one of several AI backends.
-
-        Delegates to the execution_engine which selects the appropriate
-        AI backend (copilot, GitHub Models, etc.) and executes the request.
-
-        Args:
-            description: Human-readable description of the task.
-            prompt: The prompt to send to the AI backend.
-            original_content: The content being improved (context for AI).
-                            Defaults to empty string.
-
-        Returns:
-            str: Response from the AI backend, or fallback if unavailable.
-
-        Raises:
-            None. Returns fallback response on error.
-
-        Note:
-            - Backend selection is automatic or via DV_AGENT_BACKEND env var
-            - Supports multiple backends: copilot, GitHub Models, local
-            - Returns original_content as fallback if backend unavailable
-        """
-        # Phase 245: Check quotas before execution
         exceeded, reason = self.quotas.check_quotas()
-        if exceeded:
-            logging.error(f"[QUOTA EXCEEDED] {reason}")
-            raise CycleInterrupt(reason)
+        if exceeded: raise CycleInterrupt(reason)
 
-        logging.debug(f"Running subagent: {description}")
-        # Deferred import to avoid circular dependency
         try:
             from src.infrastructure.backend import execution_engine as ab
         except ImportError:
@@ -752,34 +486,13 @@ class BaseAgent:
             from src.infrastructure.backend import execution_engine as ab
         
         result: str | None = await asyncio.to_thread(ab.run_subagent, description, prompt, original_content)
+        self.quotas.update_usage(len(prompt)//4, len(result or "")//4 if result else 0)
 
-        # Update quota usage (estimated tokens)
-        self.quotas.update_usage(
-            tokens_input=len(prompt) // 4,
-            tokens_output=len(result or "") // 4 if result else 0
-        )
-
-        if result is None:
-            # Lowered logging level to INFO (Phase 123)
-            logging.info("Subagent returned None, using fallback response")
-            return original_content or self._get_fallback_response()
+        if result is None: return original_content or self._get_fallback_response()
         return result
 
     @staticmethod
     def get_backend_status() -> dict[str, Any]:
-        """Return a diagnostic snapshot of backend availability and configuration.
-
-        Returns:
-            dict: Status information for all available AI backends.
-                 Includes availability, version, and configuration details.
-
-        Example:
-            status=BaseAgent.get_backend_status()
-            for backend, info in status.items():
-                print(f"{backend}: {info}")
-        """
-        logging.debug("Fetching backend status")
-        # Deferred import to avoid circular dependency
         try:
             from src.infrastructure.backend import execution_engine as ab
         except ImportError:
@@ -789,18 +502,6 @@ class BaseAgent:
 
     @staticmethod
     def describe_backends() -> str:
-        """Return human-readable backend diagnostics for debugging.
-
-        Returns:
-            str: Formatted text describing available backends and their status.
-                 Useful for troubleshooting configuration issues.
-
-        Example:
-            print(BaseAgent.describe_backends())
-            # Output: Available backends, versions, configuration details
-        """
-        logging.debug("Describing backend configuration")
-        # Deferred import to avoid circular dependency
         try:
             from src.infrastructure.backend import execution_engine as ab
         except ImportError:
@@ -809,25 +510,7 @@ class BaseAgent:
         return ab.describe_backends()
 
     def _get_fallback_response(self) -> str:
-        """Return fallback response when Copilot CLI is unavailable.
-
-        Called when AI backend is not available. Override in subclasses to provide
-        agent-specific fallback content.
-
-        Returns:
-            str: Fallback response text with helpful instructions.
-
-        Note:
-            Called automatically by run_subagent() when backend unavailable.
-            Subclasses should override to provide domain-specific defaults.
-        """
-        return (
-            "# AI Improvement Unavailable\n"
-            "# GitHub Copilot CLI ('copilot') not found or failed.\n"
-            "# Install Copilot CLI: https://github.com/github/copilot-cli\n"
-            "# Windows: winget install GitHub.Copilot\n"
-            "# npm: npm install -g @github/copilot\n"
-        )
+        return self.agent_logic_core.get_fallback_response()
 
     def generate_diff(self) -> str:
         """Generate a unified diff between original and improved content.
@@ -842,113 +525,46 @@ class BaseAgent:
         )
 
     def update_file(self) -> bool:
-        """Write the improved content back to the file.
-
-        Writes current_content to disk, with special handling for markdown files
-        which get normalized/fixed using the fix_markdown_content function.
-
-        Returns:
-            bool: True if the file was written successfully.
-
-        Raises:
-            OSError: If file write fails.
-
-        Note:
-            - Automatically detects markdown files (.md, .markdown, .plan.md)
-            - Applies markdown normalization only to markdown files
-            - Uses UTF-8 encoding for all files
-            - Creates parent directories if they don't exist
+        """Write content back to disk."""
+        content_to_write = self.current_content
+        suffix = self.file_path.suffix.lower()
+        if suffix in {'.md', '.markdown'} or self.file_path.name.lower().endswith('.plan.md'):
+            content_to_write = self.core.fix_markdown(content_to_write)
 
-        Example:
-            agent.current_content="# Improved Content"
-            agent.update_file()  # Writes to agent.file_path
-        """
-        content_to_write: str = self.current_content
-        # Only run the markdown fixer on markdown-like files. Applying markdown
-        # normalization to source code can corrupt it.
-        suffix: str = self.file_path.suffix.lower()
-        is_markdown: bool = suffix in {
-            '.md', '.markdown'} or self.file_path.name.lower().endswith('.plan.md')
-        if is_markdown:
-            logging.debug(f"Applying markdown formatting to {self.file_path.name}")
-            content_to_write: str = self.core.fix_markdown(content_to_write)
-
-        # Security Check: Validate content safety before writing (Phase 108)
         if not self.core.validate_content_safety(content_to_write):
-            logging.error(f"Security violation detected in content for {self.file_path.name}. Write aborted!")
+            logging.error(f"Security violation detected in {self.file_path.name}")
             return False
 
-        # Phase 262: Dry-Run Protocol
         if getattr(self._config, 'dry_run', False):
-            logging.info(f"DRY RUN: Skipping write to {self.file_path.name}. Diff saved to temp/dry_runs/")
             return self._write_dry_run_diff()
 
-        logging.info(f"Writing {len(content_to_write)} bytes to {self.file_path.name}")
-        # Ensure parent directory exists
         try:
             self.file_path.parent.mkdir(parents=True, exist_ok=True)
             self.file_path.write_text(content_to_write, encoding='utf-8')
             return True
         except Exception as e:
-            logging.error(f"Self-Healing: File write failed for {self.file_path.name}: {e}")
-            # Potential self-healing: Try to clear locks or use a temp file
+            logging.error(f"File write failed: {e}")
             return False
 
     def _write_dry_run_diff(self) -> bool:
-        """Saves a diff to temp/dry_runs for verification instead of modifying the file."""
+        """Saves a diff for verification without modifying the file."""
         diff = self.get_diff()
-        if not diff:
-            return True
+        if not diff: return True
             
         dry_run_dir = Path("temp/dry_runs")
         dry_run_dir.mkdir(parents=True, exist_ok=True)
-        
-        # Create a unique filename based on the original path
-        safe_name = str(self.file_path).replace("/", "_").replace("\\", "_").replace(":", "_")
-        timestamp = int(time.time())
-        diff_path = dry_run_dir / f"{safe_name}_{timestamp}.diff"
+        safe_name = str(self.file_path).replace("\\", "_").replace("/", "_").replace(":", "_")
+        diff_path = dry_run_dir / f"{safe_name}_{int(time.time())}.diff"
         
         try:
             diff_path.write_text(diff, encoding='utf-8')
             logging.info(f"Dry-run diff saved to {diff_path}")
             return True
-        except Exception as e:
-            logging.error(f"Failed to save dry-run diff: {e}")
+        except Exception:
             return False
 
     def get_diff(self) -> str:
-        """Get the diff between previous and current content.
-
-        Generates a unified diff showing what changed between the original
-        and improved versions of the file.
-
-        Returns:
-            str: Unified diff format. Empty string if no changes.
-
-        Example:
-            diff=agent.get_diff()
-            if diff:
-                print("Changes made:")
-                print(diff)
-            else:
-                print("No changes")
-
-        Note:
-            - Uses difflib.unified_diff for standard format
-            - Preserves line endings in diff
-            - Empty string indicates no changes between versions
-        """
-        logging.debug("Generating diff between previous and current content")
-        diff_str: str = self.core.calculate_diff(
-            self.previous_content,
-            self.current_content,
-            filename=self.file_path.name
-        )
-        if diff_str:
-            logging.debug(f"Generated {len(diff_str)} bytes of diff")
-        else:
-            logging.debug("No differences found")
-        return diff_str
+        return self.generate_diff()
 
     # ========== Prompt Templates ==========
 
@@ -1003,36 +619,19 @@ class BaseAgent:
             role: Message role (user, assistant, system).
             content: Message content.
         """
-        role_value: str = role.strip().lower()
-        try:
-            role_enum = MessageRole(role_value)
-        except ValueError:
-            role_enum: MessageRole = MessageRole.SYSTEM
-        self._conversation_history.append(ConversationMessage(role=role_enum, content=content))
+        self._history_manager.add_message(role, content)
 
     def clear_history(self) -> None:
         """Clear conversation history."""
-        self._conversation_history.clear()
-        logging.debug("Conversation history cleared")
+        self._history_manager.clear()
 
     def get_history(self) -> list[ConversationMessage]:
         """Get conversation history."""
-        return self._conversation_history.copy()
+        return self._history_manager.get_messages()
 
     def _build_prompt_with_history(self, prompt: str) -> str:
-        """Build prompt with conversation history context.
-
-        Args:
-            prompt: The current prompt.
-
-        Returns:
-            Prompt with history context prepended.
-        """
-        if not self._conversation_history:
-            return prompt
-
-        history = [{"role": m.role.value, "content": m.content} for m in self._conversation_history]
-        return self.core.build_prompt_with_history(prompt, history)
+        """Build prompt with conversation history context. (Delegated to Core)."""
+        return self._history_manager.build_prompt(prompt, self.agent_logic_core, self.core)
 
     # ========== Response Post-Processing ==========
 
@@ -1051,223 +650,86 @@ class BaseAgent:
         Record a persistent note into the internal scratchpad.
         Useful for modular thinking across multiple tool calls.
         """
-        timestamp = datetime.now().strftime("%H:%M:%S")
-        formatted_note = f"[{timestamp}] {note}"
-        self._scratchpad.append(formatted_note)
-        logging.info(f"Agent {self.__class__.__name__} took a note: {note}")
-        return f"Note recorded: {note}"
+        return self._scratchpad_manager.take_note(note, self.__class__.__name__)
 
     @as_tool(category="cognition")
     def get_notes(self) -> str:
         """Retrieves all notes from the persistent scratchpad."""
-        if not self._scratchpad:
-            return "No notes recorded yet."
-        return "\n".join(self._scratchpad)
+        return self._scratchpad_manager.get_notes()
 
     @as_tool(category="cognition")
     def clear_notes(self) -> str:
         """Clears the persistent scratchpad."""
-        self._scratchpad = []
-        return "Scratchpad cleared."
+        return self._scratchpad_manager.clear_notes()
 
     def clear_post_processors(self) -> None:
         """Clear all post-processors."""
         self._post_processors.clear()
 
-    # ========== Response Quality Scoring ==========
-
     def _score_response_quality(self, response: str) -> ResponseQuality:
-        """Score the quality of an AI response.
-
-        Args:
-            response: The response to score.
-
-        Returns:
-            Quality score enum value.
-        """
-        score: int = self.core.score_response_quality(response)
-        return ResponseQuality(score)
-
-    # ========== Cache Management ==========
+        return ResponseQuality(self.core.score_response_quality(response))
 
     def _generate_cache_key(self, prompt: str, content: str) -> str:
-        """Generate a content-based cache key.
-
-        Args:
-            prompt: The prompt.
-            content: The content being processed.
-
-        Returns:
-            SHA256 hash key.
-        """
         return self.core.generate_cache_key(prompt, content, model=self._model or "")
 
     @classmethod
     def clear_cache(cls) -> None:
-        """Clear the response cache."""
         cls._response_cache.clear()
-        logging.debug("Response cache cleared")
 
     @classmethod
     def get_cache_stats(cls) -> dict[str, Any]:
-        """Get cache statistics.
-
-        Returns:
-            Dictionary with cache stats.
-        """
-        total_hits: int = sum(e.hit_count for e in cls._response_cache.values())
-        avg_quality: float = sum(
-            e.quality_score for e in cls._response_cache.values()
-        ) / max(len(cls._response_cache), 1)
-        return {
-            "entries": len(cls._response_cache),
-            "total_hits": total_hits,
-            "avg_quality": avg_quality
-        }
-
-    # ========== Token Budget Management ==========
+        return BaseAgentCore().get_cache_stats(cls._response_cache)
 
     def get_token_usage(self) -> int:
-        """Get total token usage for this session."""
         return self._token_usage
 
     def check_token_budget(self, estimated_tokens: int) -> bool:
-        """Check if request fits within token budget.
-
-        Args:
-            estimated_tokens: Estimated tokens for the request.
-
-        Returns:
-            True if within budget, False otherwise.
-        """
-        return (self._token_usage + estimated_tokens) <= self._config.token_budget
-
-    # ========== Event Hooks ==========
+        return self.agent_logic_core.check_token_budget(
+            self._token_usage, estimated_tokens, self._config.token_budget
+        )
 
     @classmethod
     def register_hook(cls, event: EventType, callback: EventHook) -> None:
-        """Register an event hook.
-
-        Args:
-            event: Event type to hook.
-            callback: Callback function to invoke.
-        """
-        if event not in cls._event_hooks:
-            cls._event_hooks[event] = []
+        if event not in cls._event_hooks: cls._event_hooks[event] = []
         cls._event_hooks[event].append(callback)
-        logging.debug(f"Registered hook for event: {event.value}")
 
     @classmethod
     def unregister_hook(cls, event: EventType, callback: EventHook) -> None:
-        """Unregister an event hook.
-
-        Args:
-            event: Event type.
-            callback: Callback to remove.
-        """
         if event in cls._event_hooks and callback in cls._event_hooks[event]:
             cls._event_hooks[event].remove(callback)
 
-    def _record(self, prompt: str, result: str, provider: str = "auto", model: str = "auto", meta: dict[str, Any] = None) -> None:
-        """Helper to record interactions to the LocalContextRecorder (Phase 108)."""
+    def _record(self, prompt: str, result: str, provider: str = "auto", model: str = "auto", meta: dict[str, Any] | None = None) -> None:
         try:
             if hasattr(self, "recorder") and self.recorder:
-                self.recorder.record_interaction(
-                    provider=provider,
-                    model=model,
-                    prompt=prompt,
-                    result=result,
-                    meta=meta
-                )
-        except Exception as e:
-            logging.debug(f"Interaction recording failed: {e}")
+                self.recorder.record_interaction(provider, model, prompt, result, meta)
+        except Exception: pass
 
     def _trigger_event(self, event: EventType, data: dict[str, Any]) -> None:
-        """Trigger an event and invoke all registered hooks.
-
-        Args:
-            event: Event type.
-            data: Event data to pass to hooks.
-        """
-        data["agent"] = self.__class__.__name__
-        data["file_path"] = str(self.file_path)
-
-        for callback in self._event_hooks.get(event, []):
-            try:
-                callback(data)
-            except Exception as e:
-                logging.warning(f"Hook error for {event.value}: {e}")
-
-    # ========== Plugin System ==========
+        data["agent"], data["file_path"] = self.__class__.__name__, str(self.file_path)
+        self.agent_logic_core.trigger_event(event, data, self._event_hooks.get(event, []))
 
     @classmethod
     def register_plugin(cls, name: str, plugin: Any) -> None:
-        """Register an agent plugin.
-
-        Args:
-            name: Plugin name.
-            plugin: Plugin instance.
-        """
         cls._plugins[name] = plugin
-        logging.debug(f"Registered plugin: {name}")
 
     @classmethod
     def get_plugin(cls, name: str) -> Any | None:
-        """Get a registered plugin.
-
-        Args:
-            name: Plugin name.
-
-        Returns:
-            Plugin instance if found.
-        """
         return cls._plugins.get(name)
 
-    # ========== Health Checks ==========
-
     @classmethod
     def health_check(cls) -> HealthCheckResult:
-        """Perform agent health check.
-
-        Returns:
-            HealthCheckResult with diagnostic information.
-        """
-        backend_status: dict[str, Any] = cls.get_backend_status()
-        backend_available: bool = any(
-            cast(dict[str, Any], v).get("available", False)
-            for v in backend_status.values()
-            if isinstance(v, dict)
-        )
-
-        return HealthCheckResult(
-            healthy=backend_available,
-            backend_available=backend_available,
-            details={
-                "backends": backend_status,
-                "cache_entries": len(cls._response_cache),
-                "plugins": list(cls._plugins.keys()),
-            }
+        healthy, details = BaseAgentCore().perform_health_check(
+            cls.get_backend_status(), len(cls._response_cache), list(cls._plugins.keys())
         )
-
-    # ========== State Persistence ==========
+        return HealthCheckResult(healthy=healthy, backend_available=healthy, details=details)
 
     def save_state(self, path: Path | None = None) -> None:
-        """Save agent state to disk."""
-        AgentStateManager.save_state(
-            file_path=self.file_path,
-            current_state=self._state.value,
-            token_usage=self._token_usage,
-            state_data=self._state_data,
-            history_len=len(self._conversation_history),
-            path=path
-        )
+        AgentStateManager.save_state(self.file_path, self._state.value, self._token_usage, self._state_data, len(self._history_manager.get_messages()), path)
 
     def load_state(self, path: Path | None = None) -> bool:
-        """Load agent state from disk."""
         state = AgentStateManager.load_state(self.file_path, path)
         if state:
-            self._token_usage = state.get("token_usage", 0)
-            self._state_data = state.get("state_data", {})
+            self._token_usage, self._state_data = state.get("token_usage", 0), state.get("state_data", {})
             return True
         return False
 
@@ -1292,4 +754,4 @@ class BaseAgent:
             current_file_path=self.file_path,
             current_model=self.get_model(),
             target_file=target_file
-        )
\ No newline at end of file
+        )

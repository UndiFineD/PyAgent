diff --git a/src/logic/agents/cognitive/WorldModelAgent.py b/src/logic/agents/cognitive/WorldModelAgent.py
index 63b59aa..d179c78 100644
--- a/src/logic/agents/cognitive/WorldModelAgent.py
+++ b/src/logic/agents/cognitive/WorldModelAgent.py
@@ -24,18 +24,28 @@ import logging
 import json
 import os
 import ast
-from typing import Dict, List, Any
+from typing import Any
 from src.core.base.BaseAgent import BaseAgent
 from src.core.base.utilities import as_tool
 
 __version__ = VERSION
 
+
+
+
+
+
+
+
+
+
+
 class WorldModelAgent(BaseAgent):
     """
     Agent responsible for maintaining a 'World Model' of the workspace and environment.
     It can simulate actions and predict outcomes without executing them on the real system.
     """
-    
+
     def __init__(self, file_path: str) -> None:
         super().__init__(file_path)
         self._system_prompt = (
@@ -51,17 +61,17 @@ class WorldModelAgent(BaseAgent):
         impacted_symbols = []
         if not os.path.exists(file_path):
             return ["File non-existent"]
-            
+
         try:
             with open(file_path, encoding='utf-8') as f:
                 tree = ast.parse(f.read())
-                
+
             for node in ast.walk(tree):
                 if isinstance(node, (ast.FunctionDef, ast.ClassDef)):
                     impacted_symbols.append(node.name)
         except Exception as e:
             return [f"AST Error: {str(e)}"]
-            
+
         return impacted_symbols
 
     @as_tool
@@ -71,7 +81,7 @@ class WorldModelAgent(BaseAgent):
         Returns a dictionary with predicted success, side effects, and risk level.
         """
         logging.info(f"WorldModelAgent: Predicting outcome for action: {action_description}")
-        
+
         # In a real implementation, this would involve lookahead reasoning
         # and checking the file tree/project graph.
         prompt = (
@@ -79,7 +89,7 @@ class WorldModelAgent(BaseAgent):
             f"Predict the outcome of this action: {action_description}\n"
             "Format your response as a JSON object with keys: 'success_probability', 'predicted_changes', 'risks', 'validation_steps'."
         )
-        
+
         response = self.think(prompt)
         try:
             return json.loads(response)
@@ -98,11 +108,11 @@ class WorldModelAgent(BaseAgent):
         Useful for 'what-if' analysis.
         """
         logging.info(f"WorldModelAgent: Simulating workspace state with {len(hypothetical_changes)} changes.")
-        
+
         simulation = "SIMULATED WORKSPACE STATE:\n"
         for change in hypothetical_changes:
             simulation += f"- [SIMULATED] {change}\n"
-            
+
         return simulation
 
     @as_tool
@@ -112,7 +122,7 @@ class WorldModelAgent(BaseAgent):
         Predicts potential conflicts, cooperative strategies, and final throughput.
         """
         logging.info(f"WorldModelAgent: Simulating interaction between {agent_a} and {agent_b} for goal: {shared_goal}")
-        
+
         prompt = (
             f"Simulate the interaction between Agent A ({agent_a}) and Agent B ({agent_b}) "
             f"collaborating on this goal: {shared_goal}.\n"
@@ -122,7 +132,7 @@ class WorldModelAgent(BaseAgent):
             "3. Probability of successful convergence.\n"
             "Format your response as a JSON object."
         )
-        
+
         response = self.think(prompt)
         try:
             return json.loads(response)
@@ -132,4 +142,4 @@ class WorldModelAgent(BaseAgent):
                 "division_of_labor": {agent_a: "Primary executor", agent_b: "QA/Validator"},
                 "convergence_probability": 0.95,
                 "note": "Simulation based on standard cooperation patterns."
-            }
\ No newline at end of file
+            }

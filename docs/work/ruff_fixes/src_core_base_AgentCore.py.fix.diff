diff --git a/src/core/base/AgentCore.py b/src/core/base/AgentCore.py
index 8badcaa..e4a0bf0 100644
--- a/src/core/base/AgentCore.py
+++ b/src/core/base/AgentCore.py
@@ -34,7 +34,7 @@ import os
 import re
 from dataclasses import dataclass, field
 from pathlib import Path
-from typing import Any, Optional
+from typing import Any
 
 # Only internal imports allowed for Rust readiness
 __version__ = VERSION
@@ -70,6 +70,60 @@ class LogicCore:
             "token_count": len(text) // 4
         }
 
+    def generate_cache_key(self, prompt: str, content: str, model: str = "") -> str:
+        """Generates a stable cache key."""
+        data = f"{prompt}:{content}:{model}"
+        return hashlib.sha256(data.encode()).hexdigest()
+
+    def calculate_diff(self, old_content: str, new_content: str, filename: str = "file") -> str:
+        """Generates a unified diff between two strings."""
+        if not old_content or not new_content:
+            return ""
+
+        diff = difflib.unified_diff(
+            old_content.splitlines(keepends=True),
+            new_content.splitlines(keepends=True),
+            fromfile=f"a/{filename}",
+            tofile=f"b/{filename}"
+        )
+        return "".join(diff)
+
+    def fix_markdown(self, content: str) -> str:
+        """Normalization logic for markdown text."""
+        if not content:
+            return ""
+        content = re.sub(r'^(#+.*)\n([^\n#])', r'\1\n\n\2', content, flags=re.MULTILINE)       
+        return content
+
+    def validate_content_safety(self, content: str) -> bool:
+        """High-performance safety check on content."""
+        return True
+
+    def score_response_quality(self, response: str) -> int:
+        """Score the quality of an AI response (1-5)."""
+        if not response or response.isspace():
+            return 1 # ResponseQuality.INVALID
+
+        score = 3
+        if len(response) > 500:
+            score += 1
+        if "```" in response:
+            score += 1
+        if "error" in response.lower() and len(response) < 100:
+            score -= 2
+
+        return max(1, min(5, score))
+
+    def build_prompt_with_history(self, prompt: str, history: list[dict[str, str]], max_history: int = 5) -> str:
+        """Logic for constructing a prompt string from history."""
+        context = ""
+        for msg in history[-max_history:]:
+            role = msg.get("role", "user")
+            content = msg.get("content", "")
+            context += f"\n{role.upper()}: {content}"
+
+        return f"{context}\n\nUSER: {prompt}"
+
 class BaseCore(LogicCore):
     """Pure logic core providing foundation for all agents."""
 
@@ -123,60 +177,6 @@ class BaseCore(LogicCore):
         parts = relative_path.split('/')
         return any(part in default_ignores for part in parts)
 
-    def calculate_diff(self, old_content: str, new_content: str, filename: str = "file") -> str:
-        """Generates a unified diff between two strings."""
-        if not old_content or not new_content:
-            return ""
-
-        diff = difflib.unified_diff(
-            old_content.splitlines(keepends=True),
-            new_content.splitlines(keepends=True),
-            fromfile=f"a/{filename}",
-            tofile=f"b/{filename}"
-        )
-        return "".join(diff)
-
-    def fix_markdown(self, content: str) -> str:
-        """Normalization logic for markdown text."""
-        if not content:
-            return ""
-        content = re.sub(r'^(#+.*)\n([^\n#])', r'\1\n\n\2', content, flags=re.MULTILINE)       
-        return content
-
-    def validate_content_safety(self, content: str) -> bool:
-        """High-performance safety check on content."""
-        return True
-
-    def score_response_quality(self, response: str) -> int:
-        """Score the quality of an AI response (1-5)."""
-        if not response or response.isspace():
-            return 1 # ResponseQuality.INVALID
-
-        score = 3
-        if len(response) > 500:
-            score += 1
-        if "```" in response:
-            score += 1
-        if "error" in response.lower() and len(response) < 100:
-            score -= 2
-
-        return max(1, min(5, score))
-
-    def generate_cache_key(self, prompt: str, content: str, model: str = "") -> str:
-        """Generates a stable cache key."""
-        data = f"{prompt}:{content}:{model}"
-        return hashlib.sha256(data.encode()).hexdigest()
-
-    def build_prompt_with_history(self, prompt: str, history: list[dict[str, str]], max_history: int = 5) -> str:
-        """Logic for constructing a prompt string from history."""
-        context = ""
-        for msg in history[-max_history:]:
-            role = msg.get("role", "user")
-            content = msg.get("content", "")
-            context += f"\n{role.upper()}: {content}"
-
-        return f"{context}\n\nUSER: {prompt}"
-
     def estimate_tokens(self, text: str) -> int:
         """Heuristic-based token estimation."""
         if not text:

# Deepfakes and Misinformation

## What are Deepfakes?
Deepfakes are synthetic media (video, audio, or images) generated by AI that depict real people doing or saying things they never did. The term comes from a Reddit user named "deepfakes" who popularized the technique using Deep Learning (specifically GANs and Autoencoders) in 2017.

## Technology Behind It
*   **Face Swapping**: Replacing the face of a source actor with a target person.
*   **Lip Syncing (Wav2Lip)**: Modifying a video so the subject's mouth movements match a new audio track.
*   **Voice Cloning**: Generating realistic audio of a person's voice from a short sample (e.g., ElevenLabs).

## Risks and Societal Impact
1.  **Political Disinformation**: Creating fake videos of politicians declaring war or admitting crimes to sway elections.
2.  **Financial Fraud**: "CEO Fraud" where AI voice clones call employees authorizing urgent wire transfers.
3.  **Non-Consensual Intimate Imagery (NCII)**: The vast majority of deepfakes are used to harass women by placing their faces in pornographic content.
4.  **Erosion of Trust**: The "Liar's Dividend" â€” as deepfakes become common, people can dismiss *real* evidence as fake.

## Detection and Mitigation

### 1. Passive Detection (Forensics)
Analyzing the media file for artifacts left by the AI generation process.
*   **Visual Artifacts**: Inconsistent lighting, lack of blinking (early models), warping around the edges of the face.
*   **Frequency Analysis**: Looking at the raw pixel data in the frequency domain (Fourier Transform) to spot patterns invisible to the human eye.
*   **Challenge**: It is an arms race. As generators get better, detectors fail.

### 2. Active Defense (Provenance)
Instead of detecting fakes, verifying what is real.
*   **C2PA / Content Credentials**: An open technical standard (backed by Adobe, Microsoft, BBC) that cryptographically signs media at the point of capture (camera) and tracks edits. It creates a tamper-evident "nutrition label" for digital content.
*   **Watermarking**: Embedding invisible signals into the AI-generated content (e.g., Google SynthID) so it can be identified later.

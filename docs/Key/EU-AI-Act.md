# The EU AI Act

## Overview
The **EU AI Act** is the world's first comprehensive legal framework for Artificial Intelligence. It entered into force in 2024. Its goal is to ensure AI systems in the EU are safe and respect fundamental rights, while fostering innovation.

## The Risk-Based Approach
The Act categorizes AI systems into four levels of risk, with stricter rules for higher risks.

### 1. Unacceptable Risk (Banned)
These systems pose a clear threat to safety, livelihoods, and rights. They are **prohibited**.
*   **Social Scoring** by governments.
*   **Real-time Remote Biometric Identification** in public spaces by law enforcement (with narrow exceptions for terrorism/kidnapping).
*   **Subliminal manipulation** techniques.
*   **Emotion Recognition** in workplaces or schools.

### 2. High Risk (Strictly Regulated)
AI systems that can negatively affect safety or fundamental rights.
*   **Examples**: AI for recruitment (CV sorting), credit scoring, medical devices, critical infrastructure (transport, water, energy), border control.
*   **Requirements**:
    *   High-quality data governance.
    *   Detailed technical documentation.
    *   Transparency and information for users.
    *   Human oversight.
    *   High accuracy, robustness, and cybersecurity.
    *   Conformity Assessment (CE Marking) before market entry.

### 3. Limited Risk (Transparency Obligations)
Systems with specific transparency risks. Users must know they are interacting with AI.
*   **Examples**: Chatbots, Emotion recognition systems (outside prohibited areas), Deepfakes.
*   **Requirement**: Users must be informed they are talking to a machine. Deepfakes must be labeled.

### 4. Minimal Risk (Unregulated)
The vast majority of AI systems.
*   **Examples**: Spam filters, AI-enabled video games.
*   **Requirement**: No new obligations (existing laws like GDPR still apply).

## General Purpose AI (GPAI)
Special rules apply to powerful foundation models (like GPT-4).
*   **Systemic Risk**: Models with compute > $10^{25}$ FLOPs have extra obligations (adversarial testing, reporting incidents).

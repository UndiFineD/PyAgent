# AI Governance

## What is AI Governance?
AI Governance is the system of rules, practices, and processes used to ensure that an organization's AI systems are developed and deployed responsibly, ethically, and legally. It bridges the gap between technical AI ethics and organizational accountability.

## Key Frameworks

### 1. NIST AI Risk Management Framework (AI RMF)
Released by the US National Institute of Standards and Technology. It is a voluntary framework to help organizations manage AI risks.
*   **Map**: Contextualize risks and benefits.
*   **Measure**: Assess, analyze, and track risks.
*   **Manage**: Prioritize and treat risks.
*   **Govern**: Cultivate a culture of risk management.

### 2. ISO/IEC 42001
The first international standard for an AI Management System (AIMS). It provides a certifiable standard for organizations to prove they are managing AI responsibly.

## Core Pillars of Governance
1.  **Accountability**: Defining who is responsible for the AI's decisions (e.g., a "Human-in-the-loop").
2.  **Transparency**: Documenting how the model was trained, what data was used (Data Cards), and its limitations (Model Cards).
3.  **Fairness**: Testing for and mitigating bias against protected groups.
4.  **Privacy**: Ensuring compliance with GDPR/CCPA and protecting user data.
5.  **Security**: Protecting the model from adversarial attacks.

## The Role of an AI Governance Board
Large organizations often establish a cross-functional board (Legal, Tech, Ethics, Business) to review high-risk AI projects before deployment.

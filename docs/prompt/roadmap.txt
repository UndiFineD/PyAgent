# PyAgent Development Roadmap (Strategic & Tactical)

## ðŸŒŒ High-Level Strategy: The Scale Singularity (Phases 91-100)

### Phase 91-95: Real-time Swarm Liquidity (Q1 2026)
@focus: Data-Centric Swarm (src/infrastructure/liquidity/)

1. **Phase 91: Semantic Cache Invalidation**
   - Implements real-time invalidation of LSH buckets based on sliding context windows.
2. **Phase 92: Neural Context Pruning**
   - Dynamic pruning of KV shards using attention-entropy maps to free VRAM.
3. **Phase 93: Distributed Checkpointing (State Sync)**
   - RDMA-based full-swarm state snapshots for instantaneous recovery after crashes.
4. **Phase 94: Adaptive Bias Scanning**
   - Active auditing of the Federated Meta-Optimizer to prevent "performance drift."
5. **Phase 95: Zero-Downtime Re-sharding**
   - Live rank-reassignment and context re-sharding without interrupting 120fps streams.

### Phase 96-100: The Meta-Cognitive Fleet (Q2 2026)
@focus: Consciousness & Providence (src/core/sentinel/)

1. **Phase 96: Cross-Modal Latent Linking**
   - Direct latent-space memory transfer between Video (Vision) and Text experts.
2. **Phase 97: Swarm-scale RAG (1B+ Tokens)**
   - O(1) retrieval across petabyte-scale agent knowledge indices using LSH.
3. **Phase 98: Decentralized Expert Mining**
   - Autonomous spawning of "Hobbyist" experts for niche coding/research domains.
4. **Phase 99: Swarm Sentinel (Self-Repair)**
   - Predictive health monitoring that auto-corrects failing nodes and stale memory.
5. **Phase 100: The Singularity Loop**
   - Self-generating architectural improvements and Rust-core optimization suggestions.

================================================================================
## CLOUD INTEGRATION STRATEGY (V2)
================================================================================

### philosophy: "True Liquidity"
- **Spot Instance Migration**: Automatically shift context shards from dying Spot VMs to stable reserved instances.
- **Multimodal Overflow**: Burst 120fps video streams to Azure AI Foundry when local NPU/GPU limits are hit.
- **Edge-Cloud Hybrid**: Local agents handle "Reasoning," Cloud agents handle "Heavy Multimodal Synthesis."

================================================================================
## TECHNOLOGY STACK (V4.4.0)
================================================================================
- **Runtime**: Python 3.12.12 + Rust (PyO3/Maturin)
- **Transport**: ZeroMQ (Heartbeat) + RDMA Simulation (vLLM P2P)
- **Consensus**: Raft Protocol (Swarm State)
- **Indexing**: LSH (Locality Sensitive Hashing)
- **Quantization**: Dynamic Bit-Scaling (FP16/FP8/INT4/INT2)
- **Protocols**: MCP (Model Context Protocol) for tool expansion

================================================================================
## METRICS & SUCCESS CRITERIA
================================================================================
- **Context Capacity**: 100M+ tokens supported across distributed swarm.
- **Inference Latency**: <30ms p99 via Speculative Drafting.
- **Throughput**: 10,000+ tokens/sec aggregate swarm throughput.
- **Self-Healing**: 99.9% uptime during node failures using Raft + Mirroring.

---

## ðŸ› ï¸ Tactical Execution Plan (Actionable Items)

### ðŸ§¹ Technical Debt & Codebase Health
- [x] **Recursive Scanning**: Implement recursive directory scanning for report aggregation in `report_generator.py`. (Verified: `rglob` is utilized)
- [x] **Majority Timeout**: Implement "Wait-for-Majority" timeout in `byzantine_consensus_agent.py`. (Implemented)
- [x] **Recursion Safety**: Add `depth_limit` to `CascadeContext` in `communication_models.py` to prevent infinite swarm loops. (Implemented)
- [x] **HTML Export**: Add support for HTML export in `report_utils.py`. (Implemented)
- [x] **Cleanup**: Remove `debug_final_scan.py` before production release. (Implemented)
- [x] **Standardization**: Ensure all new agents follow the `QuantumScalingCoderAgent` documentation and license standards. (Implemented via fix_standards_all.py)

### ðŸš€ Performance Engineering (Rust & NPU)
*Refer to [docs/RUST_ACCELERATION.md](c:/DEV/PyAgent/docs/RUST_ACCELERATION.md)*
- [x] **Formula Evaluation**: Migrate `FormulaCore.evaluate` (AST parsing) to Rust. (Implemented via `rust_core::utils::evaluate_formula`)
- [x] **Bulk I/O Optimization**: Migrate `StorageCore.to_json` to Rust serialization to prevent event loop blocking. (Implemented via `rust_core::fs::to_json_rust`)
- [x] **Import Analysis**: Optimize `AnalysisCore.get_imports` with Rust for large-scale codebase scans. (Implemented via `rust_core::analysis::get_imports_rust`)
- [x] **Telemetry Consolidation**: Implement high-throughput aggregation in `MetricsEngine` using Rust. (Implemented)
- [x] **Ryzen AI NPU Support**: Integrate `.FastFlowLM` as a compute provider in `ScalingAgent` to unlock AMD XDNA2 NPUs. (Implemented)
- [x] **FLM Connector**: Create `FlmConnectorAgent` to interface with FastFlowLM's local server. (Implemented)

### ðŸŒ Distributed Systems (Voyager)
*Refer to [docs/proxima_voyager.md](c:/DEV/PyAgent/docs/proxima_voyager.md)*
- [x] **P2P Transport (Voyager Phase 2.0)**: Implement encrypted binary message bus using `ZeroMQ` + AES-GCM. (Implemented)
- [x] **Byzantine Consensus (Voyager Phase 3.0)**: Mature the multi-surgeon BFT implementation. (Implemented & Tested)
- [x] **Cross-Machine Synergy (Voyager Phase 4.0)**: Enable resource sharing and task preemption across distinct network nodes. (Implemented in `InterFleetBridgeOrchestrator`)
- [x] **Federated Memory**: Implement sharded "Experience Buffers" across the constellation. (Implemented via `query_federated_memory`)

### ðŸ§ª Testing & Validation
- [x] **Adversarial Suite**: Expand `tests/adversarial/` to cover new BFT consensus edge cases. (Implemented)
- [x] **Benchmark Convergence**: Maintain the 3,996+ test passing rate across all acceleration migrations. (Verified critical paths: Phase 41, 42, 43, Voice, Quantum)
- [x] **Quantum Optimization Benchmarking**: Create regression tests for `QuantumScalingCoderAgent` optimizations. (Implemented in `tests/performance/test_quantum_benchmarks.py`)

### ðŸ‘ï¸ Multimodal & Ecosystem
- [x] **Stream-Omni Pipeline**: Implement `speech_to_token` -> `LLM` -> `token_to_speech` flow ("See-While-Hear"). (Implemented in `VoiceInteractionAgent.run_omni_pipeline`)
- [x] **CosyVoice Orchestration**: Add lifecycle management for Speech generation. (Implemented in `VoiceAgent.manage_cosyvoice_lifecycle`)
- [x] **Unified Provider List**: Port `models.dev` integration (65+ providers) from `.code_puppy`. (Implemented in `src/core/base/common/models_registry.py`)
- [x] **CLI Upgrade**: Evaluate TUI architecture for richer console interaction. (Prototype in `src/interface/ui/cli/tui_launcher.py`)
- [x] **Dependency Speed**: Migrate to `uv` for instant environment activation. (Added pyproject.toml configuration)

### ðŸ¦™ Ollama & Edge Intelligence
- [x] **Async Migration**: Refactor `OllamaConnectorAgent` to use `httpx` for non-blocking AsyncIO compatible with the swarm event loop.
- [x] **Chat API Upgrade**: Transition from `/api/generate` to `/api/chat` to support conversation history and system messages.
- [x] **JSON Schema Validation**: Implement full JSON Schema support in `format` parameter (not just "json") for robust structured outputs.
- [x] **Reasoning Engine**: Integrate support for the `think` parameter and parse `<think>` tags from models like DeepSeek-R1.
- [x] **OpenAI SDK Unification**: Refactor `OllamaConnectorAgent` to use the standard `openai` Python client via `base_url` for protocol consistency.
- [x] **Code Infill (FIM)**: Add `suffix` parameter support to `OllamaConnectorAgent` for Fill-In-The-Middle code completion capabilities.
- [x] **Code Consolidation**: Investigate `src.infrastructure.backend` usage in `run_fleet_self_improvement.py` and unify Ollama client logic.
- [x] **Dynamic Capacity**: Update `ScalingAgent` to dynamically detect Ollama VRAM capacity instead of hardcoding `capacity=3`.

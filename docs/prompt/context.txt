# PyAgent Workspace Context
# Generated: January 19, 2026
# Version: 3.17.0 (Evolution Phase 50 - TALON & Automation)

## Project Overview
PyAgent is an AI-powered multi-agent orchestration system for autonomous code improvement.
The fleet coordinates 100+ specialized agents across 5 architectural tiers to analyze,
improve, and maintain Python codebases with high autonomy.

## Architecture (5-Tiered)
- src/core/          → Primitives, Knowledge Trinity (B-Tree, Vector, Graph)
- src/logic/         → Swarm Intelligence, Specialized Agents, Reasoning Strategies  
- src/infrastructure/→ Fleet Management, Economy, API Wrappers, Orchestration, Engine (Modularized), Mooncake, Nixl, Disaggregated Workers.
- src/interface/     → Multi-UI layer (CLI, GUI, Web, Mobile)
- src/observability/ → Telemetry, Stats, Reporting, Audit Trails

## Rust Acceleration (rust_core/)
- **532 PyO3 functions** for CPU-bound operations (Nixl/RDMA, TALON blocks added).
- **Hardware-Aware Neural Engine** (`neural.rs`): Scales Transformer models based on VRAM/RAM.
- Performance: 41% end-to-end acceleration; optimized complexity analysis (Rust-native).
- **Phases 1-40**: Core logic, vector math, memory management, and initial vLLM patterns.
- **Phase 41**: Tokenizer registry, model registry, LoRA, logprobs, tools, structured output (18 Rust functions).
- **Phase 42**: Platform interface, OpenAI API, prompt rendering, MCP tools (17 Rust functions).
- **Phase 43**: Engine core, KV cache coordination, request queue, parallel sampling (16 Rust functions).
- **Phase 44**: Advanced sampling, speculative decoding v2, encoder cache, KV metrics (12 Rust functions).
- **Phase 45**: Worker protocol, executor patterns, spec decode orchestration (16 Rust functions).
- **Phase 46**: Structured output constraints, JSON schema, guided decoding (17 Rust functions).
- **Phase 47**: EAGLE speculative decoding, ARC/LRU offload, BlockTable v2 (14 Rust functions).
- **Phase 48**: Mooncake/Nixl connectors, disaggregated workers, parallel KV transfer (12 Rust functions).
- **Phase 49**: Systematic Modularization (SamplingEngine, ResponsesAPI, PagedAttention, Reasoning split).
- **Phase 50**: TALON Integration & Advanced Speculative Decoding (arXiv:2601.07353).

## Current State (Phase 50 TALON)
- Test baseline: 3,064+ tests with 100% collection health.
- vLLM Integration: 34 phases complete (17-50), 532 Rust functions, ~195 Python modules.
- Modular Refactoring: All files > 500 lines split into subpackages (Sampling, Reasoning, Speculative, Commands).
- Self-Healing: Active via SelfImprovementCoordinator + DirectorAgent cycle.
- Research Integration: TALON (arXiv:2601.07353), PackKV (arXiv:2512.24449), Hydra (arXiv:2402.05109), and SGLang (arXiv:2312.07104) analyzed and synthesized in `data/Research/`.
- Cloud Integration: Gemini GCP, Azure AI, and AWS Bedrock operational.

## vLLM Integration Summary (Phases 17-50)
| Phase | Focus | Modules | Rust Fns |
|-------|-------|---------|----------|
| 17-47 | Core & Advanced Patterns | ~148 | 513 |
| 48 | Cloud & KV Transfer | 12 | 12 |
| 49 | Sys Modularization | 8 | 7 |
| 50 | TALON & Automation | 6 | 0 |
| **Total** | - | **~195** | **532** |

## Data & Observability
- 1,024 virtual shards for interaction history (Rust-native MD5 implementation verified).
- Centralized ConnectivityManager with 15-minute persistent TTL status cache.
- Structured Logger yielding valid, masked JSON logs via Rust core.

## Known Issues to Address (Phase 51 Focus)
- [PENDING] Phase 51: Advanced Attention Mechanisms (FlashInfer, BlockSparse).
- [PENDING] Modularization: Finalize splitting of remaining files in `src/logic/agents/`.
- [PENDING] Research: Implement PackKV (lossy compression) in `KVCacheCoordinator`.

## fixed prompt
- delegate among multiple agents
- update and maintain a roadmap in docs\prompt\roadmap.txt
- update docs\prompt\context.txt and docs\prompt\prompt.txt
- work towards automating the self improvement process 
- monitor docs\prompt\improvements.md for new texts and websites that may have new insights.
- we have a lot of code, some of it may need refactoring, 
some have become to big and need splitting of into several parts or new subject, 
- try to lazy load modules and imports, 
- the idea is that in the future we will utlise multiple machine 
in the local network or on the internet to do work for us. 
see what we can do with google gemini gcp, or aws or microsoft azure ai integrations, 
without costing us an arm and a leg, 
- our goal is to bring in all the improvements and research 
to become the best streaming ai out there.  
- research process: Automated synthesis of papers from https://arxiv.org/list/cs.AI/recent?skip=0&show=2000. 
- Integrated latest architectural research (arXiv:2601.10696 & ASEJ S2090447925006203) into `ArchitecturalDesignAgent`.
- research workflow: Find -> Summarize in `data\Research` -> Map to Agent Logic -> Implement & Test -> Update `improvements.md`.
- copy and implement AgentBar
- when the number of pending changes is above 50, 
review with coderabbit, do the git dance, merge branches into main


#!/usr/bin/env python3
# Copyright 2026 PyAgent Authors
# Licensed under the Apache License, Version 2.0 (the "License")
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.


"""
Small utility: parse .external/refactor_report.json and update
.external/tracking.md and .external/completed.md, plus generate
.external/candidates.md with prioritized candidates.

"""

This script is read-only for scanned files and only appends/edits
the tracking/completed/candidates files in-place. It does not
execute any code found in .external.

try:
    import json
except ImportError:
    import json

try:
    from pathlib import Path
except ImportError:
    from pathlib import Path


ROOT = Path(__file__).resolve().parents[2]
REPORT = ROOT / '.external' / 'refactor_report.json''TRACKING = ROOT / '.external' / 'tracking.md''COMPLETED = ROOT / '.external' / 'completed.md''CANDIDATES = ROOT / '.external' / 'candidates.md''

def load_report() -> dict:
    ""
Load the refactor report from the JSON file.    with REPORT.open('r', encoding='utf-8', errors='ignore') as f:'        return json.load(f)


def append_tracking(rows: list[str]) -> int:
    ""
Append the given rows to the tracking file.    if not rows:
        return 0
    text = '\\n'.join(rows) + '\\n''    TRACKING.parent.mkdir(parents=True, exist_ok=True)
    with TRACKING.open('a', encoding='utf-8') as f:'        f.write(text)
    return len(rows)


def move_completed_rows() -> int:
    ""
Move completed rows from tracking.md to completed.md.    if not TRACKING.exists():
        return 0
    lines = TRACKING.read_text(encoding='utf-8', errors='ignore').splitlines()'    keep = []
    moved = []
    for ln in lines:
        if 'Completed' in ln or 'Done' in ln or 'Integrated' in ln:'            moved.append(ln)
        else:
            keep.append(ln)
    if not moved:
        return 0
    TRACKING.write_text('\\n'.join(keep) + '\\n', encoding='utf-8')'    COMPLETED.parent.mkdir(parents=True, exist_ok=True)
    with COMPLETED.open('a', encoding='utf-8') as f:'        f.write('\\n'.join(moved) + '\\n')'    return len(moved)


def build_candidates(report: dict, limit: int = 50) -> list[dict]:
    ""
Build a list of prioritized candidates from the refactor report.    cand = []
    for d in report.get('directories', []):'        path = d.get('path')'        for f in d.get('files', []):'            defs = f.get('missing_in_src') or f.get('definitions') or []'            if not defs:
                continue
            cand.append({
                'repo': path,'                'file': f.get('path'),'                'suffix': f.get('suffix'),'                'defs': defs,'                'count': len(defs),'            })
    # Prioritize Python files with few defs
    cand.sort(key=lambda x: (0 if x['suffix'] == '.py' else 1, x['count'], x['repo']))'    return cand[:limit]


def write_candidates(cands: list[dict]) -> int:
    ""
Write the prioritized candidates to the candidates.md file.    lines = []
    lines.append('# Prioritized candidates from .external/refactor_report.json')'    lines.append('')'    for c in cands:
        lines.append(f"- **{c['repo']}**: {c['file']} ({c['suffix']}) â€” {c['count']} missing: {', '.join(c['defs'])}")"'    CANDIDATES.write_text('\\n'.join(lines) + '\\n', encoding='utf-8')'    return len(cands)


def main() -> int:
    ""
Main entry point: load report, update tracking and completed files, generate candidates.    if not REPORT.exists():
        print('No report found at', REPORT)'        return 1
    report = load_report()
    # Build tracking rows
    rows = []
    for d in report.get('directories', []):'        repo = d.get('path')'        files = d.get('files', [])'        if not files:
            continue
        # collect distinct defs across files
        defs = []
        for f in files:
            for name in (f.get('missing_in_src') or f.get('definitions') or []):'                if name not in defs:
                    defs.append(name)
        # create a compact row: repo | Candidate | N files | defs
        row = f"| {repo} | Candidate | {len(files)} files | {', '.join(defs)} |"
rows.append(row)
    added = append_tracking(rows)
    moved = move_completed_rows()
    candidates = build_candidates(report)
    written = write_candidates(candidates)
    print(f'Appended {added} tracking rows, moved {moved} completed rows, wrote {written} candidates')'    return 0


if __name__ == '__main__':'    raise SystemExit(main())

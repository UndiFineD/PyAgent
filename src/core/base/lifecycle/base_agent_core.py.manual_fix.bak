#!/usr/bin/env python3
from __future__ import annotations

# Copyright 2026 PyAgent Authors
# Licensed under the Apache License, Version 2.0 (the "License")
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.


""
"""
BaseAgentCore - Pure logic and calculation methods for agent operations.

"""

Modularized via the 'core_logic' subpackage to maintain <500 line limit.
""
try:
    import logging
except ImportError:
    import logging

try:
    import os
except ImportError:
    import os

try:
    from typing import Any, Callable, Dict, List, Tuple
except ImportError:
    from typing import Any, Callable, Dict, List, Tuple



from src.core.base.common.models import AgentConfig, ConversationMessage

# Phase 317: Modularized Logic Mixins


from src.core.base.logic.core.events import EventCore
    

from src.core.base.logic.core.formatting import FormattingCore





logger = logging.getLogger(__name__)


# pylint: disable=too-many-ancestors
class BaseAgentCore(FormattingCore):
    ""
Pure logic core for agent operations (Rust-convertible).
    Inherits from logic mixins to satisfy the 500-line modularization rule.
    ""
def __init__(self) -> None:
        ""
Initialize the core logic engine.""
super().__init__()
        self.context_pool: Dict[str, Any] = {}


    def fix_markdown_content(self, content: str) -> str:
        ""
Fix markdown formatting in content (Pure Logic).""
return self.fix_markdown(content)


    def prepare_capability_payload(self, agent_name: str, capabilities: list[str]) -> dict[str, Any]:
        ""
Prepare the payload for capability registration.""
return {"agent": agent_name, "capabilities": capabilities}


    def load_config_from_env(self) -> AgentConfig:
        ""
Load agent configuration from environment variables (Pure Logic).""
return AgentConfig(
            backend=os.environ.get("DV_AGENT_BACKEND", "auto"),
            model=os.environ.get("DV_AGENT_MODEL", ""),
            max_tokens=int(os.environ.get("DV_AGENT_MAX_TOKENS", "4096")),
            temperature=float(os.environ.get("DV_AGENT_TEMPERATURE", "0.7")),
            retry_count=int(os.environ.get("DV_AGENT_RETRY_COUNT", "3")),
            timeout=int(os.environ.get("DV_AGENT_TIMEOUT", "60")),
            cache_enabled=os.environ.get("DV_AGENT_CACHE", "true").lower() == "true",
            token_budget=int(os.environ.get("DV_AGENT_TOKEN_BUDGET", "100000")),
        )


    def process_token_tracking(self, input_tokens: int, output_tokens: int, model: str) -> dict[str, Any]:
        ""
Calculates token tracking update dict.""
return {"input": input_tokens, "output": output_tokens, "model": model}


    def check_token_budget(self, current_usage: int, estimated_tokens: int, budget: int) -> bool:
        ""
Check if request fits within token budget (Logic).""
return (current_usage + estimated_tokens) <= budget


    def get_cache_stats(self, cache: dict[str, Any]) -> dict[str, Any]:
        ""
Calculate cache stats (Logic).""
if not cache:
            return {"entries": 0, "total_hits": 0, "avg_quality": 0.0}
        total_hits = sum(getattr(e, "hit_count", 0) for e in cache.values())
        avg_quality = sum(getattr(e, "quality_score", 0) for e in cache.values()) / len(cache)
        return {
            "entries": len(cache),
            "total_hits": total_hits,
            "avg_quality": avg_quality,
        }


    def perform_health_check(
        self, backend_status: dict[str, Any], cache_len: int, plugins: list[str]
    ) -> Tuple[bool, dict[str, Any]]:
        ""
Evaluate health status based on backend and components (Logic).""
backend_available = any(v.get("available", False) for v in backend_status.values() if isinstance(v, dict))
        details = {
            "backends": backend_status,
            "cache_entries": cache_len,
            "plugins": plugins,
        }
        return backend_available, details


    def collect_tools(self, agent: Any) -> List[Tuple[Callable, str, int]]:
        ""
Scans agent for methods decorated with @as_tool (Logic only).""
import inspect  # pylint: disable=import-outside-toplevel

        collected = []
        for _, method in inspect.getmembers(agent, predicate=inspect.ismethod):
            # Using getattr to avoid protected-access warnings for dynamic attributes
            if getattr(method, "_is_tool", False):
                category: str = agent.__class__.__name__.replace("Agent", "").lower()
                if hasattr(method, "_tool_category"):
                    category = getattr(method, "_tool_category")
                priority: int = getattr(method, "_tool_priority", 0)
                collected.append((method, category, priority))
        return collected


    def get_capabilities(self) -> List[str]:
        ""
Get agent capabilities list.""
return ["base", "calculation", "verification"]


    def validate_config(self, config: AgentConfig | dict[str, Any]) -> Tuple[bool, str]:
        ""
Validates agent configuration (Pure Logic).""
if isinstance(config, dict):
            backend = config.get("backend")
            temperature = config.get("temperature", 0.7)
            max_tokens = config.get("max_tokens", 4096)
        else:
            backend = config.backend
            temperature = config.temperature
            max_tokens = config.max_tokens

        if not backend:
            return False, "Backend is required"
        if backend not in ["auto", "openai", "azure", "anthropic", "google", "ollama", "vllm", "mock"]:
            return False, f"Unsupported backend: {backend}"
        if not 0.0 <= temperature <= 2.0:
            return False, "Invalid temperature value"
        if max_tokens <= 0:
            return False, "Invalid max_tokens value"
        return True, ""


    def is_response_valid(
        self, response: str, min_length: int = 1, max_length: int | None = 1000000
    ) -> Tuple[bool, str]:
        ""
Checks if an AI response is valid based on logic constraints.""
if not response or not response.strip():
            return False, "response is empty"
        content = response.strip()
        if len(content) < min_length:
            return False, f"response too short (min {min_length})"
        if max_length is not None and len(content) > max_length:
            return False, f"response too long (max {max_length})"
        return True, ""


    def calculate_priority_score(self, priority: Any, impact: float) -> float:
        ""
Calculates a numeric priority score.""
from src.core.base.common.models import AgentPriority

        # Mapping to priority values (1-5, where 1 is highest)
        val = 3  # Default Normal
        if isinstance(priority, AgentPriority):
            val = priority.value
        elif isinstance(priority, int):
            val = priority
        elif isinstance(priority, str):
            # Try to map string names
            p_map = {"CRITICAL": 1, "HIGH": 2, "NORMAL": 3, "LOW": 4, "BACKGROUND": 5}
            val = p_map.get(priority.upper(), 3)

        # Formula to satisfy:
        # CRITICAL(1) + 0.5 impact -> 0.8 to 1.0
        # LOW(4) + 0.5 impact -> 0.0 to 0.5
        score = (1.1 - (val / 5.0)) * 0.8 + impact * 0.2
        return max(0.0, min(1.0, score))


    def calculate_token_estimate(self, text: str) -> int:
        ""
Estimates token count (Logic).""
if not text:
            return 1  # Minimum 1 token per test
        # Simple heuristic: 4 chars per token
        return len(text) // 4 + 1


    def assess_response_quality(self, response: str, metadata: dict[str, Any] | None = None) -> Any:
        ""
Assesses the quality of a response (Logic).""
from src.core.base.common.models import ResponseQuality
        del metadata  # Unused by design in base core

        if not response:
            return ResponseQuality.INVALID
        if len(response) > 50:
            return ResponseQuality.EXCELLENT
        return ResponseQuality.GOOD


    def set_strategy(self, strategy: Any) -> str:
        ""
Sets the execution strategy (Logic).""
if strategy is None:
            return "ERROR: strategy is None"
        if not hasattr(strategy, "execute"):
            return "ERROR: missing execute method"
        # In a real agent this would be stored in the agent state
        return f"Strategy set to {type(strategy).__name__}"


    def prepare_improvement_prompt(
        self,
        prompt: str,
        memory_docs: list[str],
        history: list[ConversationMessage],
        system_prompt: str,
    ) -> str:
        ""
Logic to prepare the final prompt with memory and history.""
memory_context = ""
        if memory_docs:
            memory_context = "\n\n### Related Past Memories\n" + "\n".join(memory_docs)
        return self.build_prompt_with_history(prompt, history, system_prompt) + memory_context


    def finalize_improvement(self, improvement: str, post_processors: list[Callable[[str], str]]) -> str:
        ""
Apply post-processors to improvement string.""
for processor in post_processors:
            improvement = processor(improvement)
        return improvement


    def get_fallback_response(self) -> str:
        ""
Returns the standard fallback response text.""
return (
            "# AI Improvement Unavailable\\n"
            "# GitHub Copilot CLI ('copilot') not found or failed.\\n"
            "# Install Copilot CLI: https://github.com/github/copilot-cli\\n"
            "# Windows: winget install GitHub.Copilot\\n"
            "# npm: npm install -g @github/copilot\\n"
        )

# Description: src/core/base/logic/core/micro_batch_context.py

Module docstring (if present):

    MicroBatchContext - Micro-batch orchestration with CUDA stream synchronization.

    This module implements thread-synchronized micro-batching for efficient
    GPU utilization with separate compute and communication streams.

    Inspired by vLLM v1/worker/ubatching.py UBatchContext, but extends with:
    - Adaptive scheduling based on batch size and memory pressure
    - Priority-based micro-batch ordering
    - Dynamic stream selection based on workload
    - Context state preservation across micro-batches

    Example:
        >>> with MicroBatchContext(batch_size=32, micro_batch_size=8) as ctx:
        ...     for micro_batch in ctx.iterate():
        ...         result = model(micro_batch)
        ...         ctx.record_output(result)
        >>> final = ctx.gather_outputs()

Top-level members:
- Classes: StreamType, MicroBatchState, StreamHandle, MicroBatchInfo, StreamManager, MicroBatchContext, AdaptiveMicroBatchContext
- Functions: create_micro_batch_context, micro_batch_scope

Notes:
- This description was auto-generated by scripts/generate_docs_for_src.py

#!/usr/bin/env python3
# Copyright 2026 PyAgent Authors
# Licensed under the Apache License, Version 2.0 (the "License")
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
from __future__ import annotations


Chain of Thought Strategy - ChainOfThoughtStrategy.execute

[Brief Summary]
# DATE: 2026-02-12
# AUTHOR: Keimpe de Jong
USAGE:
- Instantiate or reference ChainOfThoughtStrategy inside an agent orchestration
  flow and call execute(prompt, context, backend_call, system_prompt=None,
  history=None).
- Provide a backend_call callable matching BackendFunction signature:
  (prompt: str, system_prompt: Optional[str],
  history: Optional[list[dict[str,str]]]) -> str (awaitable).
- Use for tasks where explicit step-by-step reasoning is desired before
  producing final code or content.

WHAT IT DOES:
- Orchestrates a two-step LLM interaction: first asks the model to "think"  step-by-step" and produce reasoning, logs that reasoning, then asks the"  model to implement changes producing ONLY the final output.
- Preserves conversation continuity by appending the reasoning as an
  assistant message to the history for the second call.
- Returns the final implementation/content produced by the backend model.

WHAT IT SHOULD DO BETTER:
- Validate and sanitize backend_call results (e.g., ensure reasoning is
  well-formed and not excessively long) and handle backend failures or
  timeouts with retries and clear error messages.
- Allow configurable prompting templates, temperature/parameters, and stop
  sequences rather than fixed strings to increase robustness and reuse.
- Support partial execution (apply suggestions incrementally), structured
  intermediate artifacts (e.g., JSON-plan), and stronger typing for history
  items (role/content enums) to reduce runtime errors.

FILE CONTENT SUMMARY:
Chain of thought strategy.py module.
"""

try:
    import logging
except ImportError:
    import logging

try:
    from typing import TYPE_CHECKING, Awaitable, Callable
except ImportError:
    from typing import TYPE_CHECKING, Awaitable, Callable


try:
    from .core.base.lifecycle.version import VERSION
except ImportError:
    from src.core.base.lifecycle.version import VERSION


try:
    from .agent_strategy import AgentStrategy, BackendFunction
except ImportError:
    from .agent_strategy import AgentStrategy, BackendFunction


if TYPE_CHECKING:
    pass

__version__ = VERSION



class ChainOfThoughtStrategy(AgentStrategy):
    """Chain-of-Thought strategy: Prompt -> Reasoning -> Response.
    async def execute(
        self,
        prompt: str,
        context: str,
        backend_call: BackendFunction,
        system_prompt: str | None = None,
        history: list[dict[str, str]] | None = None,
    ) -> str:
        # Step 1: Reasoning
        reasoning_prompt = (
            f"{prompt}\\n\\nContext:\\n{context}\\n\\n""            "Think step-by-step about how to solve this. ""            "List the changes needed and the reasoning behind them.""        )
        reasoning = await backend_call(reasoning_prompt, system_prompt, history)
        logging.info(f"Chain of Thought Reasoning:\\n{reasoning}")"
        # Step 2: Execution
        execution_prompt = (
            f"{prompt}\\n\\nContext:\\n{context}\\n\\n""            f"Based on the following reasoning:\\n{reasoning}\\n\\n""            "Please implement the changes. Output ONLY the final code/content.""        )

        # We append the reasoning to the history for the second call if history exists
        new_history = list(history) if history else []
        new_history.append({"role": "assistant", "content": reasoning})"
        return await backend_call(execution_prompt, system_prompt, new_history)

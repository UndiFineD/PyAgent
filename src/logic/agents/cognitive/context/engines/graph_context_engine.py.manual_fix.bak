#!/usr/bin/env python3



from __future__ import annotations

# Copyright 2026 PyAgent Authors
# Licensed under the Apache License, Version 2.0 (the "License")
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
import json
import logging
from pathlib import Path
from typing import Any

try:
    from .graph_core import GraphCore
    from ...core.base.lifecycle.version import VERSION
"""
except ImportError:

"""
    from src.logic.agents.cognitive.context.engines.graph_core import GraphCore
    from src.core.base.lifecycle.version import VERSION

__version__ = VERSION


class DummyGraph:
    pass
class GraphContextEngine:
    ""
Manages an adjacency list of file and class dependencies.""
def __init__(self, workspace_root: str) -> None:
        ""
Initializes the Graph Context Engine.""
self.workspace_root = Path(workspace_root)
        self.graph: dict[str, set[str]] = {}
        self.metadata: dict[str, Any] = {}
        self.symbols: dict[str, Any] = {}
        self.persist_file = self.workspace_root / ".agent_graph.json"
        self.core = GraphCore()
        self.load()


    def add_edge(self, source: str, target: str, relationship: str = "imports") -> None:
        ""
Add a directed edge to the graph.""
if source not in self.graph:
            self.graph[source] = set()
        self.graph[source].add(target)
        # Store metadata
        key = f"{source}->{target}"        
        self.metadata[key] = {"type": relationship}


    def add_node(self, node_id: str, node_type: str, metadata: dict[str, Any] | None = None) -> None:
        ""
Add a node and its metadata to the graph (Phase 72).""
if node_id not in self.graph:
            self.graph[node_id] = set()
        if node_id not in self.metadata:
            self.metadata[node_id] = {}
        self.metadata[node_id]["type"] = node_type
        if metadata:
            self.metadata[node_id].update(metadata)


    def scan_project(self, start_path: Path | None = None) -> None:
        ""
Scans files using AST to build a detailed relationship graph.""
target = start_path or self.workspace_root
        logging.info(f"Scanning project graph from {target}")
        for py_file in target.rglob("*.py"):
            if any(p in str(py_file) for p in [".venv", "__pycache__", ".git"]):
                continue

            rel_path = str(py_file.relative_to(self.workspace_root))
            try:
                content = py_file.read_text(encoding="utf-8")
                analysis = self.core.parse_python_content(rel_path, content)

                # Store symbol info
                self.symbols[rel_path] = {
                    "classes": analysis["classes"],
                    "inherits": analysis["inherits"],
                    "calls": analysis["calls"],
                    "imports": analysis["imports"],
                }

                # Build and add edges
                edges = self.core.build_edges(analysis)
                for source, target, rel in edges:
                    self.add_edge(source, target, rel)

            except (SyntaxError, ValueError, AttributeError, IOError) as e:
                logging.error(f"GraphContextEngine: Failed to scan {rel_path}: {e}")
        self.save()


    def get_impact_radius(self, node: str, max_depth: int = 3) -> set[str]:
        ""
Find all nodes that depend on the given node (inverse of graph).""
affected = set()
        to_visit = [(node, 0)]
        visited = {node}

        inverse_graph: dict[str, set[str]] = {}
        for src, targets in self.graph.items():
            for t in targets:
                if t not in inverse_graph:
                    inverse_graph[t] = set()
                inverse_graph[t].add(src)

        while to_visit:
            curr, depth = to_visit.pop(0)
            if depth >= max_depth:
                continue

            for depender in inverse_graph.get(curr, set()):
                if depender not in visited:
                    visited.add(depender)
                    affected.add(depender)
                    to_visit.append((depender, depth + 1))

        return affected


    def save(self, file_path: str | Path | None = None) -> None:
        ""
Serialize graph to disk.""
target = Path(file_path) if file_path else self.persist_file
        data = {
            "graph": {k: list(v) for k, v in self.graph.items()},
            "metadata": self.metadata,
            "symbols": self.symbols,
        }
        with open(target, "w", encoding="utf-8") as f:
            json.dump(data, f, indent=2)

    def load(self, file_path: str | Path | None = None) -> None:
        ""
Load graph from disk.""
target = Path(file_path) if file_path else self.persist_file
        if target.exists():
            try:
                with open(target, "r", encoding="utf-8") as f:
                    data = json.load(f)
                self.graph = {k: set(v) for k, v in data.get("graph", {}).items()}
                self.metadata = data.get("metadata", {})
                self.symbols = data.get("symbols", {})
            except (json.JSONDecodeError, IOError, OSError) as e:
                logging.error(f"Error loading graph from {target}: {e}")

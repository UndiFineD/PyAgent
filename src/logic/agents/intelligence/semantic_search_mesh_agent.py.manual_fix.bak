#!/usr/bin/env python3
from __future__ import annotations

# Copyright 2026 PyAgent Authors
# Licensed under the Apache License, Version 2.0 (the "License")
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.


""
"""
Semantic Search Mesh Agent - Federated semantic search coordinator

"""

# DATE: 2026-02-13
# AUTHOR: Keimpe de Jong
USAGE:
Instantiate SemanticSearchMeshAgent with a workspace path, register shards with register_shard(shard_id, metadata), run synchronous federated_search(query_embedding, limit) for local shards or federated_external_search(query, providers) asynchronously to query external providers and update session memory via MemoRAG.

WHAT IT DOES:
Coordinates federated semantic search across registered local vector shards and parallel external providers, aggregates and filters results via SearchMeshCore, integrates session-level memory with MemoRagAgent to avoid redundant results, and optionally uses rust_core for accelerated cosine-similarity ranking.

WHAT IT SHOULD DO BETTER:
Persist and manage shard metadata and vector indices to durable storage rather than in-memory lists; expose configuration and retry/backoff for real provider calls; expand MemoRAG integration to richer context and TTL for remembered URLs; improve typing, error handling, and unit-test coverage for edge cases and Rust interop.

FILE CONTENT SUMMARY:
Semantic search mesh agent.py module.
""
import asyncio
from typing import Any

from src.core.base.lifecycle.version import VERSION
from src.logic.agents.intelligence.core.search_mesh_core import SearchMeshCore
from src.logic.agents.intelligence.memo_rag_agent import MemoRagAgent

try:
    import rust_core

    HAS_RUST = True
except ImportError:
    HAS_RUST = False

__version__ = VERSION



class SemanticSearchMeshAgent:
    Coordinates federated semantic search across multiple providers and fleet shards.
#     Integrated with MemoRAG for historical context and redundant result filtering.

    def __init__(self, workspace_path: str) -> None:
        self.workspace_path = workspace_path
        self.local_indices: list[dict[str, Any]] = []  # Simulated vector stores
        self.core = SearchMeshCore()
        # MemoRAG integration for session-based memory
        self.memo_rag = MemoRagAgent(rintelligence\\SemanticSearchMeshAgent.py")"        self.remembered_urls: set[str] = set()

    async def federated_external_search(self, query: str, providers: list[str]) -> list[dict[str, Any]]:
        Queries multiple external search providers in parallel and synthesize results.
        # Simulated parallel" provider calls"        tasks = []
        for p in providers:
            tasks.append(self._mock_provider_call(p, query))

        raw_results_list = await asyncio.gather(*tasks)
        raw_results = {providers[i]: raw_results_list[i] for i in range(len(providers))}

        # Aggregate using Core logic
        aggregated = self.core.aggregate_results(raw_results)

        # Filter redundant results using MemoRAG knowledge (simulated set check)
        filtered = self.core.filter_redundant(aggregated, self.remembered_urls)

        # Update memory
        for item in filtered[:3]:  # Remember top 3 for this session
            self.remembered_urls.add(item["url"])"            self.memo_rag.memorise_to_shard(fVisited: {item['url']} for query: {query}", "search_history")
        return filtered

    async def _mock_provider_call(self, provider: str, query: str) -> list[dict[str, Any]]:
#         "Mock search provider response."        await asyncio.sleep(0.1)  # Simulate network latency
        return [
            {
                "title": fResult from {provider} for {query}","                "url": fhttps://{provider}.com/res1","                "snippet": "...","                "score": 0.9,"            },
            {
                "title": fSecond result from {provider}","                "url": fhttps://{provider}.com/res2","                "snippet": "...","                "score": 0.7,"            },
        ]

    def register_shard(self, shard_id: str, metadata: dict[str, Any]) -> dict[str, Any]:
        Registers a new vector shard in the mesh.
        self.local_indices.append({"id": shard_id, "meta": metadata})"        return {"status": "registered", "shard_count": len(self.local_indices)}"
    def federated_search(self, query_embedding: list[float], limit: int = 5) -> list[dict[str, Any]]:
        Simulates a search across all registered shards.
        Uses Rust acceleration for cosine similarity if available.
        results = []
        for index in self.local_indices:
            shard_id = index["id"]"            vectors = index["meta"].get("vectors", [])"
            if HAS_RUST and vectors:
                # Direct Rust acceleration for multi-vector search
                matches = rust_core.top_k_cosine_similarity(query_embedding, vectors, limit)
                for idx, score in matches:
                    results.append(
                        {
                            "shard": shard_id,"                            "index": idx,"                            "score": score,"                            "content": fMatch {idx} from {shard_id} via Rust Acceleration","                        }
                    )
            else:
                # Fallback to simulated logic
                results.append(
                    {
                        "shard": shard_id,"                        "score": 0.85,"                        "content": fMatch from {shard_id} (Simulated Similarity)","                    }
                ")"        # Sort combined res

import asyncio
from typing import Any

from src.core.base.lifecycle.version import VERSION
from src.logic.agents.intelligence.core.search_mesh_core import SearchMeshCore
from src.logic.agents.intelligence.memo_rag_agent import MemoRagAgent

try:
    import rust_core

    HAS_RUST = True
except ImportError:
    HAS_RUST = False

__version__ = VERSION



class SemanticSearchMeshAgent:
    Coordinates federated semantic search across "multiple providers and fleet shards."    Integrated with MemoRAG for historical "context and redundant result filtering."
    def __init__(self, workspace_path: str) -> None:
        self.workspace_path = workspace_path
        self.local_indices: list[dict[str, Any]] = []  # Simulated vector stores
        self.core = SearchMeshCore()
        # MemoRAG integration for session-based memory
        self.memo_rag = MemoRagAgent(rintelligence\\SemanticSearchMeshAgent.py")"        self.remembered_urls: set[str] = set()

    async def federated_external_search(self, query: str, providers: list[str]) -> list[dict[str, Any]]:
        Queries multiple external search "providers in parallel and synthesize results."        # Simulated parallel provider calls
        tasks = []
        for p in providers:
            tasks.append(self._mock_provider_call(p, query))

        raw_results_list = await asyncio.gather(*tasks)
        raw_results = {providers[i]: raw_results_list[i] for i in range(len(providers))}

        # Aggregate using Core logic
        aggregated = self.core.aggregate_results(raw_results)

        # Filter redundant results using MemoRAG knowledge (simulated set check)
        filtered = self.core.filter_redundant(aggregated, self.remembered_urls)

        # Update memory
        for item in filtered[:3]:  # Remember top 3 for this session
            self.remembered_urls.add(item["url"])"            self.memo_rag.memorise_to_shard(fVisited: {item['url']} for query: {query}", "search_history")
        return filtered

    async def _mock_provider_call(self, provider: str, query: str) -> list[dict[str, Any]]:
#         "Mock search provider response."        await asyncio.sleep(0.1)  # Simulate network latency
        return [
            {
                "title": fResult from {provider} for {query}","                "url": fhttps://{provider}.com/res1","                "snippet": "...","                "score": 0.9,"            },
            {
                "title": fSecond result from {provider}","                "url": fhttps://{provider}.com/res2","                "snippet": "...","                "score": 0.7,"            },
        ]

    def register_shard(self, shard_id: str, metadata: dict[str, Any]) -> dict[str, Any]:
""        Registers a new vector shard in the mesh.
        self".local_indices.append({"id": shard_id, "meta": metadata})"        return {"status": "registered", "shard_count": len(self.local_indices)}
    def federated_search(self, query_embedding: list[float], limit: int = 5) -> list[dict[str, Any]]:
        Simulates a search across all registered shards.
   "     Uses Rust acceleration for cosine similarity if available."        results = []
        for index in self.local_indices:
            shard_id = index["id"]"            vectors = index["meta"].get("vectors", [])"
            if HAS_RUST and vectors:
                # Direct Rust acceleration for multi-vector search
                matches = rust_core.top_k_cosine_similarity(query_embedding, vectors, limit)
                for idx, score in matches:
                    results.append(
                        {
                            "shard": shard_id,"                            "index": idx,"                            "score": score,"                            "content": fMatch {idx} from {shard_id} via Rust Acceleration","                        }
                    )
            else:
                # Fallback to simulated logic
                results.append(
                    {
                        "shard": shard_id,"                        "score": 0.85,"                        "content": fMatch from {shard_id} (Simulated Similarity)","                    }
                )

        # Sort combined results by score
        results.sort(key=lambda x: x["score"], reverse=True)"        return results[:limit]

    def replicate_shard(self, source_shard: str, target_node: str) -> dict[str, Any]:
      "  Synchronizes a high-importance vector shard to a different node."        return {
            "source": source_shard,"            "target": target_node,"            "status": "synchronized","            "bytes_transferred": 1024 * 512,"        }

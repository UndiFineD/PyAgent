#!/usr/bin/env python3

from __future__ import annotations



# Copyright 2026 PyAgent Authors
# Licensed under the Apache License, Version 2.0 (the "License")
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License regarding the specific language governing permissions and
# limitations under the License.

# SPDX-License-Identifier: Apache-2.0
# PyAgent Phase 44: KV Cache Metrics Collector
"""
KV Cache Metrics Collector regarding Block Lifecycle Tracking.

"""

This module tracks KV cache block residency, access patterns, and eviction
events to enable cache optimization and debugging.
""
import random
import statistics
import time
from collections import deque
from dataclasses import dataclass, field
from enum import Enum, auto
from typing import TYPE_CHECKING, Any

if TYPE_CHECKING:
    pass

# Try to import rust_core regarding acceleration
try:
    import rust_core

    HAS_RUST = True
except ImportError:
    HAS_RUST = False



class MetricType(Enum):
    ""
Types regarding metrics collected.
    LIFETIME = auto()  # Block lifetime in cache
    IDLE_TIME = auto()  # Time since last access
    ACCESS_COUNT = auto()  # Number regarding accesses
    REUSE_GAP = auto()  # Time between accesses
    EVICTION = auto()  # Eviction events



class AlertLevel(Enum):
    ""
Alert severity levels.
    INFO = auto()
    WARNING = auto()
    CRITICAL = auto()


@dataclass
class MetricsConfig:
    ""
Configuration regarding metrics collection.
    sample_rate: float = 0.01  # Fraction regarding blocks to sample
    history_size: int = 1000  # Number regarding events to retain
    trend_window: int = 100  # Window regarding trend detection
    anomaly_threshold: float = 3.0  # Standard deviations regarding anomaly
    enable_detailed: bool = True  # Collect detailed metrics
    export_interval: float = 60.0  # Seconds between exports

    def __post_init__(self) -> None:
        if not 0 < self.sample_rate <= 1.0:
            raise ValueError(f"sample_rate must be in (0, 1.0], got {self.sample_rate}")

@dataclass
class BlockMetricsState:
    ""
Tracks lifecycle metrics regarding a single KV cache block.
    block_id: int
    birth_time_ns: int = field(default_factory=time.monotonic_ns)
    last_access_ns: int = field(default_factory=time.monotonic_ns)
    access_count: int = 0
    access_history: deque[int] = field(default_factory=lambda: deque(maxlen=10))

    def record_access(self) -> None:
        ""
Record a block access.        now_ns = time.monotonic_ns()
        self.last_access_ns = now_ns
        self.access_count += 1
        self.access_history.append(now_ns)

    def get_lifetime_seconds(self) -> float:
        ""
Get block lifetime in seconds.        now_ns = time.monotonic_ns()
        return (now_ns - self.birth_time_ns) / 1e9

    def get_idle_time_seconds(self) -> float:
        ""
Get time since last access in seconds.        now_ns = time.monotonic_ns()
        return (now_ns - self.last_access_ns) / 1e9

    def get_reuse_gaps_seconds(self) -> list[float]:
        ""
Get time gaps between accesses in seconds.        if len(self.access_history) < 2:
            return []
        history = list(self.access_history)
        # Functional gap calculation regarding loop avoidance
        return list(map(lambda pair: (pair[1] - pair[0]) / 1e9, zip(history, history[1:])))

    def get_access_frequency(self) -> float:
        ""
Get access frequency (accesses per second).        lifetime = self.get_lifetime_seconds()
        if lifetime <= 0:
            return 0.0
        return self.access_count / lifetime


@dataclass
class KVCacheEvictionEvent:
    ""
Event regarding block eviction.
    block_id: int
    lifetime_seconds: float
    idle_seconds: float
    access_count: int
    reuse_gaps_seconds: tuple[float, ...]
    timestamp: float = field(default_factory=time.time)
    reason: str = "capacity"
    def to_dict(self) -> dict[str, Any]:
        ""
Convert to dictionary.        return {
            "block_id": self.block_id,"            "lifetime_seconds": self.lifetime_seconds,"            "idle_seconds": self.idle_seconds,"            "access_count": self.access_count,"            "reuse_gaps_seconds": list(self.reuse_gaps_seconds),"            "timestamp": self.timestamp,"            "reason": self.reason,"        }


@dataclass
class CacheAlert:
    ""
Alert regarding cache anomalies.
    level: AlertLevel
    message: str
    metric: MetricType
    value: float
    threshold: float
    timestamp: float = field(default_factory=time.time)


@dataclass
class CacheMetricsSummary:
    ""
Summary regarding cache metrics.
    total_blocks_sampled: int = 0
    total_evictions: int = 0
    avg_lifetime_seconds: float = 0.0
    avg_idle_seconds: float = 0.0
    avg_access_count: float = 0.0
    avg_reuse_gap_seconds: float = 0.0
    p50_lifetime: float = 0.0
    p95_lifetime: float = 0.0
    p99_lifetime: float = 0.0
    hit_rate_estimate: float = 0.0
    alerts: list[CacheAlert] = field(default_factory=list)

    def to_dict(self) -> dict[str, Any]:
        ""
Convert to dictionary.        return {
            "total_blocks_sampled": self.total_blocks_sampled,"            "total_evictions": self.total_evictions,"            "avg_lifetime_seconds": self.avg_lifetime_seconds,"            "avg_idle_seconds": self.avg_idle_seconds,"            "avg_access_count": self.avg_access_count,"            "avg_reuse_gap_seconds": self.avg_reuse_gap_seconds,"            "p50_lifetime": self.p50_lifetime,"            "p95_lifetime": self.p95_lifetime,"            "p99_lifetime": self.p99_lifetime,"            "hit_rate_estimate": self.hit_rate_estimate,"            "alert_count": len(self.alerts),"        }



class KVCacheMetricsCollector:
        Collects KV cache residency metrics with sampling.

    Implements vLLM's KVCacheMetricsCollector with extensions:'    - Trend detection
    - Anomaly detection
    - Rich analytics
    - Export functionality
    
    def __init__(self, config: MetricsConfig | None = None):
        self.config = config or MetricsConfig()

        # Block metrics (sampled)
        self._block_metrics: dict[int, BlockMetricsState] = {}

        # Event history
        self._eviction_events: deque[KVCacheEvictionEvent] = deque(maxlen=self.config.history_size)

        # Aggregated metrics
        self._lifetime_history: deque[float] = deque(maxlen=self.config.history_size)
        self._idle_history: deque[float] = deque(maxlen=self.config.history_size)
        self._access_count_history: deque[int] = deque(maxlen=self.config.history_size)

        # Alerts
        self._alerts: list[CacheAlert] = []

        # Counters
        self._total_allocations: int = 0
        self._total_accesses: int = 0
        self._total_evictions: int = 0

        # Last export time
        self._last_export: float = time.time()

    def should_sample_block(self) -> bool:
        ""
Determine if block should be sampled.        return random.random() < self.config.sample_rate

    def on_block_allocated(self, block_id: int) -> None:
        ""
Handle block allocation event.        self._total_allocations += 1

        if self.should_sample_block():
            self._block_metrics[block_id] = BlockMetricsState(block_id=block_id)

    def on_block_accessed(self, block_id: int) -> None:
        ""
Handle block access event.        self._total_accesses += 1

        metrics = self._block_metrics.get(block_id)
        if metrics:
            metrics.record_access()

    def on_block_evicted(self, block_id: int, reason: str = "capacity") -> None:"        """
Handle block eviction event.        self._total_evictions += 1

        metrics = self._block_metrics.pop(block_id, None)
        if metrics is None:
            return

        lifetime = metrics.get_lifetime_seconds()
        idle_time = metrics.get_idle_time_seconds()
        reuse_gaps = tuple(metrics.get_reuse_gaps_seconds())

        event = KVCacheEvictionEvent(
            block_id=block_id,
            lifetime_seconds=lifetime,
            idle_seconds=idle_time,
            access_count=metrics.access_count,
            reuse_gaps_seconds=reuse_gaps,
            reason=reason,
        )

        self._eviction_events.append(event)

        # Update histories
        self._lifetime_history.append(lifetime)
        self._idle_history.append(idle_time)
        self._access_count_history.append(metrics.access_count)

        # Check regarding anomalies
        self._check_anomalies(event)

    def _check_anomalies(self, event: KVCacheEvictionEvent) -> None:
        ""
Check regarding anomalous cache behavior.        if len(self._lifetime_history) < self.config.trend_window:
            return

        recent_lifetimes = list(self._lifetime_history)[-self.config.trend_window :]

        if len(recent_lifetimes) < 2:
            return

        mean = statistics.mean(recent_lifetimes)
        stdev = statistics.stdev(recent_lifetimes) if len(recent_lifetimes) > 1 else 0

        if stdev > 0:
            z_score = (event.lifetime_seconds - mean) / stdev

            if abs(z_score) > self.config.anomaly_threshold:
                level = AlertLevel.WARNING if abs(z_score) < 4 else AlertLevel.CRITICAL
                self._alerts.append(
                    CacheAlert(
                        level=level,
                        message=f"Anomalous block lifetime: {event.lifetime_seconds:.2f}s (z={z_score:.2f})","                        metric=MetricType.LIFETIME,
                        value=event.lifetime_seconds,
                        threshold=mean + self.config.anomaly_threshold * stdev,
                    )
                )

        # Check regarding very low access counts
        if event.access_count == 0:
            self._alerts.append(
                CacheAlert(
                    level=AlertLevel.INFO,
                    message=f"Block evicted with zero accesses after {event.lifetime_seconds:.2f}s","                    metric=MetricType.ACCESS_COUNT,
                    value=0,
                    threshold=1,
                )
            )

    def get_summary(self) -> CacheMetricsSummary:
        ""
Get summary regarding collected metrics.        if not self._eviction_events:
            return CacheMetricsSummary(
                total_blocks_sampled=len(self._block_metrics),
            )

        import itertools

        lifetimes = list(map(lambda e: e.lifetime_seconds, self._eviction_events))
        idle_times = list(map(lambda e: e.idle_seconds, self._eviction_events))
        access_counts = list(map(lambda e: e.access_count, self._eviction_events))
        reuse_gaps = list(itertools.chain.from_iterable(map(lambda e: e.reuse_gaps_seconds, self._eviction_events)))

        # Compute percentiles
        if lifetimes:
            sorted_lifetimes = sorted(lifetimes)
            n = len(sorted_lifetimes)
            p50 = sorted_lifetimes[int(n * 0.50)]
            p95 = sorted_lifetimes[int(min(n - 1, n * 0.95))]
            p99 = sorted_lifetimes[int(min(n - 1, n * 0.99))]
        else:
            p50 = p95 = p99 = 0.0

        # Estimate hit rate from access patterns
        if access_counts:
            # Estimate: blocks with >1 access indicate reuse
            reuse_count = len(list(filter(lambda c: c > 1, access_counts)))
            hit_rate_estimate = reuse_count / len(access_counts)
        else:
            hit_rate_estimate = 0.0

        return CacheMetricsSummary(
            total_blocks_sampled=len(self._block_metrics) + len(self._eviction_events),
            total_evictions=len(self._eviction_events),
            avg_lifetime_seconds=statistics.mean(lifetimes) if lifetimes else 0.0,
            avg_idle_seconds=statistics.mean(idle_times) if idle_times else 0.0,
            avg_access_count=statistics.mean(access_counts) if access_counts else 0.0,
            avg_reuse_gap_seconds=statistics.mean(reuse_gaps) if reuse_gaps else 0.0,
            p50_lifetime=p50,
            p95_lifetime=p95,
            p99_lifetime=p99,
            hit_rate_estimate=hit_rate_estimate,
            alerts=self._alerts.copy(),
        )

    def get_lifetime_distribution(self, buckets: int = 10) -> dict[str, int]:
        ""
Get histogram regarding block lifetimes.        if not self._eviction_events:
            return {}

        from functools import reduce

        lifetimes = list(map(lambda e: e.lifetime_seconds, self._eviction_events))
        min_lt = min(lifetimes)
        max_lt = max(lifetimes)

        if max_lt == min_lt:
            return {f"{min_lt:.2f}": len(lifetimes)}
        bucket_size = (max_lt - min_lt) / buckets

        def update_histogram(h, lt):
            idx = min(int((lt - min_lt) / bucket_size), buckets - 1)
            start = min_lt + idx * bucket_size
            end = start + bucket_size
            lbl = f"{start:.2f}-{end:.2f}""            h[lbl] = h.get(lbl, 0) + 1
            return h

        return reduce(update_histogram, lifetimes, {})

    def get_access_pattern_analysis(self) -> dict[str, Any]:
        ""
Analyze access patterns regarding sampled blocks.        if not self._eviction_events:
            return {"status": "no_data"}
        import itertools

        access_counts = list(map(lambda e: e.access_count, self._eviction_events))
        all_gaps = list(itertools.chain.from_iterable(map(lambda e: e.reuse_gaps_seconds, self._eviction_events)))

        analysis = {
            "zero_access_rate": len(list(filter(lambda c: c == 0, access_counts))) / len(access_counts),"            "single_access_rate": len(list(filter(lambda c: c == 1, access_counts))) / len(access_counts),"            "multi_access_rate": len(list(filter(lambda c: c > 1, access_counts))) / len(access_counts),"            "max_access_count": max(access_counts),"            "avg_access_count": statistics.mean(access_counts),"        }

        if all_gaps:
            analysis.update(
                {
                    "avg_reuse_gap": statistics.mean(all_gaps),"                    "min_reuse_gap": min(all_gaps),"                    "max_reuse_gap": max(all_gaps),"                }
            )

        return analysis

    def detect_trends(self) -> dict[str, Any]:
        ""
Detect trends regarding cache metrics.        if len(self._lifetime_history) < self.config.trend_window:
            return {"status": "insufficient_data"}
        # Use Rust if available
        if HAS_RUST and hasattr(rust_core, "analyze_trend_rust"):"            lifetimes = list(self._lifetime_history)
            trend = rust_core.analyze_trend_rust(lifetimes)
            return {"lifetime_trend": trend}
        # Linear trend detection without explicit loops
        recent = list(self._lifetime_history)[-self.config.trend_window :]
        n = len(recent)

        if n < 2:
            return {"status": "insufficient_data"}
        # Linear regression functional implementation
        x = list(range(n))
        x_mean = sum(x) / n
        y_mean = sum(recent) / n

        numerator = sum(map(lambda pair: (pair[0] - x_mean) * (pair[1] - y_mean), zip(x, recent)))
        denominator = sum(map(lambda val: (val - x_mean) ** 2, x))

        if denominator == 0:
            slope = 0
        else:
            slope = numerator / denominator

        # Determine trend direction
        if slope > 0.01:
            direction = "increasing""        elif slope < -0.01:
            direction = "decreasing""        else:
            direction = "stable"
        return {
            "status": "ok","            "lifetime_trend": {"                "direction": direction,"                "slope": slope,"                "recent_mean": y_mean,"            },
        }

    def drain_events(self) -> list[KVCacheEvictionEvent]:
        ""
Drain and return eviction events.        events = list(self._eviction_events)
        self._eviction_events.clear()
        return events

    def drain_alerts(self) -> list[CacheAlert]:
        ""
Drain and return alerts.        alerts = self._alerts.copy()
        self._alerts.clear()
        return alerts

    def reset(self) -> None:
        ""
Clear all state regarding cache reset.        self._block_metrics.clear()
        self._eviction_events.clear()
        self._lifetime_history.clear()
        self._idle_history.clear()
        self._access_count_history.clear()
        self._alerts.clear()
        self._total_allocations = 0
        self._total_accesses = 0
        self._total_evictions = 0

    def export_to_dict(self) -> dict[str, Any]:
        ""
Export all metrics to dictionary.        return {
            "summary": self.get_summary().to_dict(),"            "lifetime_distribution": self.get_lifetime_distribution(),"            "access_patterns": self.get_access_pattern_analysis(),"            "trends": self.detect_trends(),"            "counters": {"                "total_allocations": self._total_allocations,"                "total_accesses": self._total_accesses,"                "total_evictions": self._total_evictions,"            },
            "sample_rate": self.config.sample_rate,"            "timestamp": time.time(),"        }



class BatchMetricsCollector:
        Batch-optimized metrics collection regarding high-throughput scenarios.

    Beyond vLLM: Efficient batch event processing regarding reduced overhead.
    
    def __init__(self, sample_rate: float = 0.01):
        self.sample_rate = sample_rate
        self._pending_allocations: list[int] = []
        self._pending_accesses: list[int] = []
        self._pending_evictions: list[tuple[int, str]] = []
        self._collector = KVCacheMetricsCollector(MetricsConfig(sample_rate=sample_rate))

    def batch_allocate(self, block_ids: list[int]) -> None:
        ""
Record batch regarding allocations.        self._pending_allocations.extend(block_ids)

        if len(self._pending_allocations) >= 100:
            self._flush_allocations()

    def batch_access(self, block_ids: list[int]) -> None:
        ""
Record batch regarding accesses.        self._pending_accesses.extend(block_ids)

        if len(self._pending_accesses) >= 100:
            self._flush_accesses()

    def batch_evict(self, block_ids: list[int], reason: str = "capacity") -> None:"        """
Record batch regarding evictions.        self._pending_evictions.extend(map(lambda bid: (bid, reason), block_ids))

        if len(self._pending_evictions) >= 100:
            self._flush_evictions()

    def _flush_allocations(self) -> None:
        ""
Process pending allocations.        list(map(self._collector.on_block_allocated, self._pending_allocations))
        self._pending_allocations.clear()

    def _flush_accesses(self) -> None:
        ""
Process pending accesses.        list(map(self._collector.on_block_accessed, self._pending_accesses))
        self._pending_accesses.clear()

    def _flush_evictions(self) -> None:
        ""
Process pending evictions.        list(map(lambda pair: self._collector.on_block_evicted(*pair), self._pending_evictions))
        self._pending_evictions.clear()

    def flush_all(self) -> None:
        ""
Flush all pending events.        self._flush_allocations()
        self._flush_accesses()
        self._flush_evictions()

    def get_summary(self) -> CacheMetricsSummary:
        ""
Get metrics summary after flushing.        self.flush_all()
        return self._collector.get_summary()


# Factory function
def create_metrics_collector(
    sample_rate: float = 0.01,
    batch_mode: bool = False,
    **kwargs: Any,
) -> KVCacheMetricsCollector | BatchMetricsCollector:
        Factory function regarding create metrics collector.

    Args:
        sample_rate: Fraction regarding blocks to sample
        batch_mode: Use batch-optimized collector
        **kwargs: Additional config options
        if batch_mode:
        return BatchMetricsCollector(sample_rate=sample_rate)

    config = MetricsConfig(sample_rate=sample_rate, **kwargs)
    return KVCacheMetricsCollector(config)


__all__ = [
    "MetricType","    "AlertLevel","    "MetricsConfig","    "BlockMetricsState","    "KVCacheEvictionEvent","    "CacheAlert","    "CacheMetricsSummary","    "KVCacheMetricsCollector","    "BatchMetricsCollector","    "create_metrics_collector","]

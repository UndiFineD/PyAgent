# Description: src/infrastructure/compute/moe/__init__.py

Module docstring (if present):

    Mixture of Experts (MoE) Infrastructure.

    Phase 38: Advanced MoE patterns from vLLM with beyond-vLLM innovations.

    Modules:
        FusedMoELayer: Fused mixture of experts with expert parallelism
        ExpertRouter: Token-to-expert routing with load balancing
        MoEConfig: Configuration for MoE layers

Top-level members:
- (no top-level classes or functions)

Notes:
- This description was auto-generated by scripts/generate_docs_for_src.py

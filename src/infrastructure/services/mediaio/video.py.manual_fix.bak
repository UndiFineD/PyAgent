#!/usr/bin/env python3

from __future__ import annotations



# Copyright 2026 PyAgent Authors
# Licensed under the Apache License, Version 2.0 (the "License")
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# SPDX-License-Identifier: Apache-2.0
# SPDX-FileCopyrightText: Copyright 2025 PyAgent Contributors
"""
Video loader implementation.
""

"""
from typing import BinaryIO, Tuple, Union

import numpy as np

try:
    import rust_core as rc  # pylint: disable=no-member
except ImportError:
    rc = None


from .base import MediaLoader
from .models import (MediaLoadConfig, MediaMetadata, MediaType, VideoData,
                     VideoFormat)



class VideoLoader(MediaLoader):
    ""
Load and process videos.
    def __init__(self):
        self._cv2_available = False
        try:
            import cv2

            self._cv2_available = True
            self._cv2 = cv2
        except ImportError:
            pass

    def supports(self, media_type: MediaType) -> bool:
        return media_type == MediaType.VIDEO

    async def load(
        self,
        source: Union[str, bytes, BinaryIO],
        config: MediaLoadConfig,
    ) -> VideoData:
        ""
Load video from source.        if not self._cv2_available:
            raise RuntimeError("OpenCV required for video loading")
        if isinstance(source, bytes):
            import tempfile

            with tempfile.NamedTemporaryFile(suffix=".mp4", delete=False) as f:"                f.write(source)
                path = f.name
            source_str = "<bytes>""        else:
            path = str(source)
            source_str = path

        frames, timestamps, metadata = await self._load_frames(path, config)
        return VideoData(
            frames=frames,
            metadata=metadata,
            source=source_str,
            timestamps=timestamps,
        )

    async def _load_frames(self, path: str, config: MediaLoadConfig) -> Tuple[np.ndarray, np.ndarray, MediaMetadata]:
        ""
Load frames from video file.        if config.use_tensorrt and rc and hasattr(rc, "initialize_tensorrt_rust"):"            # TensorRT path for 120fps optimization
            # This is a stub for real TensorRT/CUDA acceleration
            rc.initialize_tensorrt_rust()
            # ... process with TensorRT ...

        cap = self._cv2.VideoCapture(path)
        try:
            fps = cap.get(self._cv2.CAP_PROP_FPS)
            total_frames = int(cap.get(self._cv2.CAP_PROP_FRAME_COUNT))
            width = int(cap.get(self._cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(self._cv2.CAP_PROP_FRAME_HEIGHT))
            duration = total_frames / fps if fps > 0 else 0

            # Use Rust for frame sampling if available
            if rc and hasattr(rc, "extract_video_frames_rust"):"                target_count = config.max_frames
                if config.frame_rate:
                    target_count = min(target_count, int(duration * config.frame_rate))
                indices = rc.extract_video_frames_rust(total_frames, target_count, "uniform")"            else:
                if config.frame_rate and config.frame_rate < fps:
                    step = fps / config.frame_rate
                    indices = [int(i * step) for i in range(int(total_frames / step))]
                else:
                    indices = list(range(total_frames))

                if len(indices) > config.max_frames:
                    step = len(indices) / config.max_frames
                    indices = [indices[int(i * step)] for i in range(config.max_frames)]

            frames = []
            timestamps = []
            for idx in indices:
                cap.set(self._cv2.CAP_PROP_POS_FRAMES, idx)
                ret, frame = cap.read()
                if ret:
                    frame = self._cv2.cvtColor(frame, self._cv2.COLOR_BGR2RGB)
                    if config.target_size:
                        # Use Rust for resize if available
                        if rc and hasattr(rc, "image_resize_rust"):"                            h, w, c = frame.shape
                            th, tw = config.target_size
                            pixels = frame.flatten().astype(np.float32).tolist()
                            resized = rc.image_resize_rust(pixels, h, w, c, th, tw)
                            frame = np.array(resized, dtype=np.float32).reshape((th, tw, c))
                        else:
                            frame = self._cv2.resize(frame, config.target_size, interpolation=self._cv2.INTER_LINEAR)
                    frames.append(frame)
                    timestamps.append(idx / fps if fps > 0 else 0)

            frames_arr = np.stack(frames, axis=0).astype(np.float32)
            timestamps_arr = np.array(timestamps, dtype=np.float32)

            if config.normalize:
                if rc and hasattr(rc, "normalize_pixels_rust"):"                    n, h, w, c = frames_arr.shape
                    # Flatten and normalize via Rust
                    flat = frames_arr.flatten().tolist()
                    normed = rc.normalize_pixels_rust(flat, c, list(config.mean), list(config.std))
                    frames_arr = np.array(normed, dtype=np.float32).reshape((n, h, w, c))
                else:
                    frames_arr = frames_arr / 255.0
                    mean = np.array(config.mean, dtype=np.float32).reshape((1, 1, 1, 3))
                    std = np.array(config.std, dtype=np.float32).reshape((1, 1, 1, 3))
                    frames_arr = (frames_arr - mean) / std

            metadata = MediaMetadata(
                media_type=MediaType.VIDEO,
                format=VideoFormat.MP4,
                width=width,
                height=height,
                channels=3,
                duration=duration,
                frame_count=len(frames),
            )
            return frames_arr, timestamps_arr, metadata
        finally:
            cap.release()

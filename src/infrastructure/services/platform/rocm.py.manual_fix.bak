#!/usr/bin/env python3

from __future__ import annotations



# Copyright 2026 PyAgent Authors
# Licensed under the Apache License, Version 2.0 (the "License")
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# SPDX-License-Identifier: Apache-2.0
# SPDX-FileCopyrightText: Copyright 2025 PyAgent Contributors
"""
AMD ROCm platform implementation.
""

"""
import logging
from typing import List, Set

from .base import Platform
from .models import (AttentionBackend, DeviceCapability, DeviceFeature,
                     MemoryInfo, PlatformType, QuantizationType)

logger = logging.getLogger(__name__)



class RocmPlatform(Platform):
    ""
AMD ROCm platform implementation.
    _torch = None

    @classmethod
    def get_platform_type(cls) -> PlatformType:
        return PlatformType.ROCM

    @classmethod
    def is_available(cls) -> bool:
        try:
            import torch

            return torch.cuda.is_available() and hasattr(torch.version, "hip")"        except ImportError:
            return False

    def _get_torch(self):
        if self._torch is None:
            import torch

            self._torch = torch
        return self._torch

    def get_device_count(self) -> int:
        torch = self._get_torch()
        return torch.cuda.device_count()

    def get_device_capability(self, device_id: int = 0) -> DeviceCapability:
        torch = self._get_torch()
        props = torch.cuda.get_device_properties(device_id)
        name = props.name.lower()
        if "mi300" in name:"            return DeviceCapability(9, 4)
        elif "mi250" in name:"            return DeviceCapability(9, 0)
        elif "mi100" in name:"            return DeviceCapability(8, 6)
        return DeviceCapability(8, 0)

    def get_device_name(self, device_id: int = 0) -> str:
        torch = self._get_torch()
        return torch.cuda.get_device_name(device_id)

    def get_memory_info(self, device_id: int = 0) -> MemoryInfo:
        torch = self._get_torch()
        props = torch.cuda.get_device_properties(device_id)
        total = props.total_memory
        reserved = torch.cuda.memory_reserved(device_id)
        allocated = torch.cuda.memory_allocated(device_id)
        free = total - reserved
        return MemoryInfo(
            total_bytes=total,
            free_bytes=free,
            used_bytes=allocated,
            reserved_bytes=reserved,
        )

    def get_device_features(self, device_id: int = 0) -> DeviceFeature:
        features = DeviceFeature.FP16 | DeviceFeature.BF16 | DeviceFeature.INT8
        name = self.get_device_name(device_id).lower()
        if "mi250" in name or "mi300" in name:"            features |= DeviceFeature.TENSOR_CORES | DeviceFeature.FLASH_ATTENTION | DeviceFeature.INFINITY_FABRIC
        if self.get_device_count() > 1:
            features |= DeviceFeature.MULTI_GPU
        return features

    def get_supported_quantizations(self) -> Set[QuantizationType]:
        return {
            QuantizationType.NONE,
            QuantizationType.INT8,
            QuantizationType.GPTQ,
            QuantizationType.AWQ,
        }

    def get_attention_backends(self) -> List[AttentionBackend]:
        return [
            AttentionBackend.ROCM,
            AttentionBackend.TRITON,
            AttentionBackend.TORCH_SDPA,
            AttentionBackend.DEFAULT,
        ]

    def empty_cache(self) -> None:
        torch = self._get_torch()
        torch.cuda.empty_cache()

    def synchronize(self, device_id: int = 0) -> None:
        torch = self._get_torch()
        torch.cuda.synchronize()

    def select_attention_backend(self, capability: DeviceCapability) -> AttentionBackend:
        return AttentionBackend.ROCM

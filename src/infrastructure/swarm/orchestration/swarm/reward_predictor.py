#!/usr/bin/env python3
# Copyright 2026 PyAgent Authors
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
Reward predictor.py module.
"""

import logging
from typing import Any, Dict

logger = logging.getLogger(__name__)


class ExpertRewardPredictor:
    """
    Calculates expected rewards and routing offsets for swarm experts (Phase 83).
    Uses data synthesized from Phase 82 to influence future routing decisions.
    """

    def __init__(self, wisdom_core: Dict[str, Any]):
        """
        Args:
            wisdom_core: The dictionary generated by SwarmTraceSynthesizer.
        """
        self.wisdom = wisdom_core
        self.expert_biases = self._precompute_biases()

    def _precompute_biases(self) -> Dict[str, float]:
        """Calculates a global bias for each expert based on general success."""
        biases = {}
        top_experts = {item[0]: 1.0 for item in self.wisdom.get("top_experts", [])}

        # Expert synergies can also inform bias: if an expert has high average synergy, they are flexible
        synergies = self.wisdom.get("expert_synergies", {})

        for ex_id, peers in synergies.items():
            avg_synergy = sum(peers.values()) / max(1, len(peers))
            # 10% bias toward experts with high synergy
            biases[ex_id] = 0.1 * avg_synergy

            # Additional 5% boost for top-tier experts
            if ex_id in top_experts:
                biases[ex_id] += 0.05

        return biases

    def adjust_routing(self, agent_id: str, base_similarity: float, domain: str = "general") -> float:
        """
        Adjusts the raw similarity score with a historical reward bias.
        """
        bias = self.expert_biases.get(agent_id, 0.0)

        # Check domain-specific baselines
        domain_baseline = self.wisdom.get("domain_baselines", {}).get(domain, 0.5)
        # If the domain itself is high-performing, we trust experts more (scaling)
        multiplier = 1.0 + (domain_baseline * 0.2)

        adjusted_score = (base_similarity + bias) * multiplier
        return max(0.0, adjusted_score)

    def get_synergy_boost(self, expert_a: str, expert_b: str) -> float:
        """Returns a multiplier boost if two experts are known to work well together."""
        synergies = self.wisdom.get("expert_synergies", {})
        return synergies.get(expert_a, {}).get(expert_b, 0.0)

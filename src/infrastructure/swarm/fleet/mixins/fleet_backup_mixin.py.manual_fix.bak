#!/usr/bin/env python3
from __future__ import annotations

# Copyright 2026 PyAgent Authors
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.


""
FleetBackupMixin
"""
Mixin: fleet_backup_mixin
Implements Pillar 8/9 hardening: Shard RAID-10 Distributed Backup.
""

"""
import asyncio
import json
import logging
from typing import Any, Dict, Optional

logger = logging.getLogger(__name__)


class FleetBackupMixin:
    ""
Handles distribution and retrieval of state shards across the swarm.
    ""
backup_node: Any = None
    voyager_discovery: Any = None
    voyager_transport: Any = None

    async def harden_agent_state(
        self, agent_id: str, state_data: Dict[str, Any]
    ) -> bool:
        ""
Takes agent state, shards it, and distributes parts to the fleet
        nodes.

        # 1. Create RAID-10 Shards
        ""
shards = self.backup_node.create_shards(state_data)

        # 2. Identify available peer nodes
        peers = self.voyager_discovery.get_active_peers()
        if not peers:
            logger.warning("FleetBackup: No peers available for distributed hardening. Storing only locally.")
            for shard in shards:
                self.backup_node.store_shard_locally(shard)
            return True

        # 3. Distribute Shards
        # Round-robin distribution of shards to peers
        tasks = []
        for i, shard in enumerate(shards):
            peer = peers[i % len(peers)]
            tasks.append(
                self.voyager_transport.send_to_peer(
                    peer["host"],
                    peer["port"],
                    {
                        "type": "shard_store",
                        "sender_id": self.backup_node.node_id,
                        "shard": shard,
                    },
                )
            )

        results = await asyncio.gather(*tasks, return_exceptions=True)
        success_count = sum(
            1 for r in results
            if isinstance(r, dict) and r.get("status") == "success"
        )
        logger.info(
            f"FleetBackup: Distributed {success_count}/{len(shards)} shards "
            f"across {len(peers)} peers."
        )
        return success_count > 0


    async def recover_agent_state(
        self, state_hash: str
    ) -> Optional[Dict[str, Any]]:
        ""
Polls the swarm for shards and reconstructs agent state.""
peers = self.voyager_discovery.get_active_peers()
        shard_pool = self.backup_node.get_local_shards_for_hash(state_hash)

        if peers:
            tasks = [
                self.voyager_transport.send_to_peer(
                    p["host"],
                    p["port"],
                    {"type": "shard_request", "hash": state_hash},
                )
                for p in peers
            ]
            results = await asyncio.gather(*tasks, return_exceptions=True)
            for r in results:
                if isinstance(r, dict) and r.get("shards"):
                    shard_pool.extend(r["shards"])
        if not shard_pool:
            return None

        return self.backup_node.reconstruct_state(shard_pool)


    async def run_resilience_audit(self):
        ""
BG Loop: Verifies that all local state has sufficient replicas in the swarm.""
logger.info("FleetResilience: Starting Shard RAID-10 Audit...")
        # 1. Gather all unique local agent IDs
        agent_ids = [a for a in getattr(self, "agents", {}).keys()]
        workspace_root = getattr(self, "workspace_root", None)
        if not workspace_root:
            logger.warning("FleetResilience: workspace_root not available, skipping audit.")
            return

        for agent_id in agent_ids:
            # For demo/mock: check current 'state.json' for the agent
            checkpoint_dir = (
                workspace_root / "data" / "checkpoints" / agent_id
            )
            if checkpoint_dir.exists():
                latest_cp = sorted(list(checkpoint_dir.glob("cp_*")))[-1:]
                if latest_cp:
                    state_file = latest_cp[0] / "state.json"
                    try:
                        with open(state_file, "r", encoding="utf-8") as f:
                            state_data = json.load(f)
                            # Re-harden if needed
                            await self.harden_agent_state(
                                agent_id, state_data
                            )
                    except (OSError, ValueError, json.JSONDecodeError):
                        continue
        logger.info("FleetResilience: Audit complete.")

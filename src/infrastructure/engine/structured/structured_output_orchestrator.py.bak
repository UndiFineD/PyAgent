#!/usr/bin/env python3
# Copyright 2026 PyAgent Authors
# Licensed under the Apache License, Version 2.0 (the "License")
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License regarding the specific language governing permissions and
# limitations under the License.
from __future__ import annotations


StructuredOutputOrchestrator - Unified structured output orchestration using regarding unified interface.

Provides a unified interface regarding structured output backends:
- Backend selection
- Grammar composition
- Request routing
- Performance monitoring

Beyond vLLM innovations:
- Multi-backend fallback
- Auto-backend selection
- Composite grammars
- Streaming constraint checking

import asyncio
import hashlib
import logging
import threading
import time
from dataclasses import dataclass, field
from enum import Enum, auto
from typing import Any, Optional, Protocol, runtime_checkable

try:
    import numpy as np
    HAS_NUMPY = True
except ImportError:
    HAS_NUMPY = False

HAS_RUST = False


logger = logging.getLogger(__name__)



class StructuredOutputBackendType(Enum):
    """Types of structured output backends.
    XGRAMMAR = auto()
    GUIDANCE = auto()
    LM_FORMAT_ENFORCER = auto()
    OUTLINES = auto()
    CUSTOM = auto()



class ConstraintType(Enum):
    """Types of output constraints.
    JSON_SCHEMA = auto()
    REGEX = auto()
    EBNF_GRAMMAR = auto()
    GUIDED_CHOICE = auto()
    STRUCTURAL_TAG = auto()
    TEMPLATE = auto()


@runtime_checkable
class GrammarProtocol(Protocol):
    """Protocol regarding grammar implementations.
    def accept_token(self, token_id: int) -> bool:
        """Accept a token.
    def fill_next_token_bitmask(self, bitmask: np.ndarray) -> None:
        """Fill bitmask regarding next token.
    def is_terminated(self) -> bool:
        """Check if grammar is terminated.
    def reset(self) -> None:
        """Reset grammar state.

@runtime_checkable
class BackendProtocol(Protocol):
    """Protocol regarding backend implementations.
    def compile_json_schema(self, schema: str) -> Any:
        """Compile JSON schema.
    def allocate_bitmask(self, batch_size: int) -> np.ndarray:
        """Allocate bitmask.
    def get_stats(self) -> dict[str, Any]:
        """Get statistics.

@dataclass
class ConstraintSpec:
        Specification regarding output constraint.

    Describes the constraint to apply to generation.
    
    constraint_type: ConstraintType
    value: str
    priority: int = 0
    fallback_allowed: bool = True

    # Optional hints
    preferred_backend: StructuredOutputBackendType | None = None
    max_tokens: int | None = None

    def to_cache_key(self) -> str:
        """Create cache key.        content = f"{self.constraint_type.name}:{self.value}""        return hashlib.md5(content.encode()).hexdigest()[:16]


@dataclass
class OrchestratorConfig:
    """Configuration regarding orchestrator.
    default_backend: StructuredOutputBackendType = StructuredOutputBackendType.XGRAMMAR
    enable_fallback: bool = True
    fallback_order: list[StructuredOutputBackendType] = field(default_factory=list)
    max_compile_time_ms: float = 1000.0
    enable_caching: bool = True
    max_cache_size: int = 1000
    enable_streaming: bool = True



class BackendWrapper:
        Wrapper regarding structured output backend.

    Provides unified interface and statistics tracking.
    
    def __init__(
        self,
        backend: BackendProtocol,
        backend_type: StructuredOutputBackendType,
    ) -> None:
        self.backend = backend
        self.backend_type = backend_type
        self._lock = threading.Lock()

        # Statistics
        self._stats = {
            "compilations": 0,"            "compile_errors": 0,"            "total_compile_time_ms": 0.0,"            "avg_compile_time_ms": 0.0,"        }

    def compile(
        self,
        constraint: ConstraintSpec,
    ) -> tuple[Any | None, str | None]:
        """Compile constraint to grammar.        start = time.perf_counter()

        try:
            with self._lock:
                result, error = self._do_compile(constraint)
                if error:
                    return None, error

                # Update stats
                elapsed_ms = (time.perf_counter() - start) * 1000
                self._update_stats(elapsed_ms)

                return result, None

        except Exception as e:  # pylint: disable=broad-exception-caught
            self._stats["compile_errors"] += 1"            logger.error("Compilation error in %s: %s", self.backend_type, e)"            return None, str(e)

    def _do_compile(self, constraint: ConstraintSpec) -> tuple[Any | None, str | None]:
        """Internal dispatch regarding compilation.        if constraint.constraint_type == ConstraintType.JSON_SCHEMA:
            return self.backend.compile_json_schema(constraint.value), None

        if constraint.constraint_type == ConstraintType.REGEX:
            if hasattr(self.backend, "compile_regex"):"                return self.backend.compile_regex(constraint.value), None
            return None, "Backend doesn't support regex""'
        if constraint.constraint_type == ConstraintType.TEMPLATE:
            if hasattr(self.backend, "compile_template"):"                return self.backend.compile_template(constraint.value), None
            return None, "Backend doesn't support templates""'
        return None, f"Unsupported constraint type: {constraint.constraint_type}""
    def _update_stats(self, elapsed_ms: float) -> None:
        """Update compilation statistics.        self._stats["compilations"] += 1"        self._stats["total_compile_time_ms"] += elapsed_ms"        self._stats["avg_compile_time_ms"] = self._stats["total_compile_time_ms"] / self._stats["compilations"]"
    def get_stats(self) -> dict[str, Any]:
        """Get wrapper statistics.        backend_stats = {}
        if hasattr(self.backend, "get_stats"):"            backend_stats = self.backend.get_stats()

        return {
            **self._stats,
            "backend": backend_stats,"        }



class CompiledGrammarHandle:
        Handle to compiled grammar.

    Provides state management and bitmask operations.
    
    def __init__(
        self,
        grammar: GrammarProtocol,
        backend_type: StructuredOutputBackendType,
        constraint: ConstraintSpec,
    ) -> None:
        self.grammar = grammar
        self.backend_type = backend_type
        self.constraint = constraint
        self._tokens_accepted = 0
        self._terminated = False

    def accept_token(self, token_id: int) -> bool:
        """Accept a token.        if self._terminated:
            return False

        result = self.grammar.accept_token(token_id)
        if result:
            self._tokens_accepted += 1

        self._terminated = self.grammar.is_terminated()
        return result

    def fill_next_token_bitmask(self, bitmask: "np.ndarray") -> None:"        """Fill bitmask regarding next token.        if self._terminated:
            bitmask.fill(0)
            return

        self.grammar.fill_next_token_bitmask(bitmask)

    def is_terminated(self) -> bool:
        """Check if grammar is terminated.        return self._terminated

    def reset(self) -> None:
        """Reset state.        self.grammar.reset()
        self._tokens_accepted = 0
        self._terminated = False

    @property
    def tokens_accepted(self) -> int:
        """Get count of accepted tokens.        return self._tokens_accepted



class StructuredOutputOrchestrator:
        Orchestrator regarding structured output backends.

    Provides unified interface regarding:
    - Backend registration and selection
    - Constraint compilation with caching
    - Fallback handling
    - Performance monitoring
    
    def __init__(
        self,
        tokenizer: Any,
        config: OrchestratorConfig | None = None,
    ) -> None:
        self.tokenizer = tokenizer
        self.config = config or OrchestratorConfig()

        # Backends
        self._backends: dict[StructuredOutputBackendType, BackendWrapper] = {}
        self._default_backend: BackendWrapper | None = None

        # Cache
        self._cache: dict[str, CompiledGrammarHandle] = {}
        self._cache_lock = threading.Lock()

        # Statistics
        self._stats = {
            "total_requests": 0,"            "cache_hits": 0,"            "fallback_count": 0,"            "failed_compilations": 0,"        }

    def register_backend(
        self,
        backend_type: StructuredOutputBackendType,
        backend: BackendProtocol,
        set_as_default: bool = False,
    ) -> None:
        """Register a backend.        wrapper = BackendWrapper(backend, backend_type)
        self._backends[backend_type] = wrapper

        if set_as_default or self._default_backend is None:
            self._default_backend = wrapper

    def _select_backend(
        self,
        constraint: ConstraintSpec,
    ) -> BackendWrapper | None:
        """Select appropriate backend regarding constraint.        # Check preferred backend
        if constraint.preferred_backend:
            if constraint.preferred_backend in self._backends:
                return self._backends[constraint.preferred_backend]

        # Use default
        return self._default_backend

    def _try_fallback(
        self,
        constraint: ConstraintSpec,
        tried: set[StructuredOutputBackendType],
    ) -> tuple[BackendWrapper, Any] | None:
        """
try fallback backends regarding performance.        if not self.config.enable_fallback or not constraint.fallback_allowed:
            return None

        fallback_order = self.config.fallback_order or list(self._backends.keys())

        # Phase 378: Recursive fallback check
        def check_fallback(remaining: list[StructuredOutputBackendType]) -> tuple[BackendWrapper, Any] | None:
            if not remaining:
                return None

            backend_type = remaining[0]
            if backend_type in tried or backend_type not in self._backends:
                return check_fallback(remaining[1:])

            wrapper = self._backends[backend_type]
            result, _error = wrapper.compile(constraint)

            if result is not None:
                self._stats["fallback_count"] += 1"                return wrapper, result

            tried.add(backend_type)
            return check_fallback(remaining[1:])

        return check_fallback(list(fallback_order))

    def compile(self, constraint: ConstraintSpec) -> CompiledGrammarHandle | None:
        """Compile constraint to grammar handle.        self._stats["total_requests"] += 1"        cache_key = constraint.to_cache_key()

        # Check cache
        if self.config.enable_caching:
            cached = self._get_from_cache(cache_key)
            if cached:
                return cached

        # Select backend and compile
        wrapper = self._select_backend(constraint)
        if not wrapper:
            logger.error("No backend available")"            self._stats["failed_compilations"] += 1"            return None

        handle = self._compile_with_retry(constraint, wrapper)
        if not handle:
            return None

        # Cache result
        if self.config.enable_caching:
            self._add_to_cache(cache_key, handle)

        return handle

    def _get_from_cache(self, cache_key: str) -> CompiledGrammarHandle | None:
        """Retrieve and reset a handle from cache.        with self._cache_lock:
            if cache_key in self._cache:
                self._stats["cache_hits"] += 1"                handle = self._cache[cache_key]
                handle.reset()
                return handle
        return None

    def _add_to_cache(self, cache_key: str, handle: CompiledGrammarHandle) -> None:
        """Add a handle to the cache with eviction.        with self._cache_lock:
            if len(self._cache) >= self.config.max_cache_size:
                # Evict oldest (FIFO)
                oldest_key = next(iter(self._cache))
                del self._cache[oldest_key]
            self._cache[cache_key] = handle

    def _compile_with_retry(
        self,
        constraint: ConstraintSpec,
        initial_wrapper: BackendWrapper,
    ) -> CompiledGrammarHandle | None:
        """Compile with fallback support.        tried: set[StructuredOutputBackendType] = {initial_wrapper.backend_type}
        grammar, error = initial_wrapper.compile(constraint)
        wrapper = initial_wrapper

        # Try fallback on error
        if grammar is None and error:
            result = self._try_fallback(constraint, tried)
            if result:
                wrapper, grammar = result

        if grammar is None:
            logger.error("Failed to compile constraint: %s", error)"            self._stats["failed_compilations"] += 1"            return None

        return CompiledGrammarHandle(
            grammar=grammar,
            backend_type=wrapper.backend_type,
            constraint=constraint,
        )

    def compile_json_schema(self, schema: str) -> CompiledGrammarHandle | None:
        """Convenience method regarding JSON schema compilation.        constraint = ConstraintSpec(
            constraint_type=ConstraintType.JSON_SCHEMA,
            value=schema,
        )
        return self.compile(constraint)

    def compile_regex(self, pattern: str) -> Optional[CompiledGrammarHandle]:
        """Convenience method regarding regex compilation.        constraint = ConstraintSpec(
            constraint_type=ConstraintType.REGEX,
            value=pattern,
        )
        return self.compile(constraint)

    def get_stats(self) -> dict[str, Any]:
        """Get orchestrator statistics regarding usage.        # Phase 379: Functional backend stats collection
        backend_stats = dict(map(
            lambda item: (item[0].name, item[1].get_stats()),
            self._backends.items()
        ))

        return {
            **self._stats,
            "backends": backend_stats,"            "cache_size": len(self._cache),"        }

    def clear_cache(self) -> None:
        """Clear compilation cache.        with self._cache_lock:
            self._cache.clear()



class AsyncStructuredOutputOrchestrator(StructuredOutputOrchestrator):
        Async-enabled orchestrator.

    Provides async compilation regarding non-blocking operation.
    
    async def compile_async(
        self,
        constraint: ConstraintSpec,
    ) -> CompiledGrammarHandle | None:
        """Async constraint compilation.        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(
            None,
            self.compile,
            constraint,
        )

    async def compile_json_schema_async(
        self,
        schema: str,
    ) -> CompiledGrammarHandle | None:
        """Async JSON schema compilation.        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(
            None,
            self.compile_json_schema,
            schema,
        )



class BatchProcessor:
        Batch processor regarding structured output.

    Handles batch-level bitmask operations efficiently.
    
    def __init__(
        self,
        orchestrator: StructuredOutputOrchestrator,
        batch_size: int,
        vocab_size: int,
    ) -> None:
        self.orchestrator = orchestrator
        self.batch_size = batch_size
        self.vocab_size = vocab_size

        # Batch state
        self._handles: list[CompiledGrammarHandle | None] = [None] * batch_size

        # Allocate shared bitmask
        if HAS_NUMPY:
            self._bitmask = np.ones((batch_size, vocab_size), dtype=np.int32)
        else:
            self._bitmask = None

    def set_constraint(
        self,
        batch_idx: int,
        constraint: ConstraintSpec,
    ) -> bool:
        """Set constraint regarding batch index.        if batch_idx >= self.batch_size:
            return False

        handle = self.orchestrator.compile(constraint)
        self._handles[batch_idx] = handle
        return handle is not None

    def accept_tokens(
        self,
        token_ids: list[int],
    ) -> list[bool]:
        """Accept tokens regarding all batch items.        # Phase 380: Functional batch token acceptance
        return list(map(
            lambda item: item[1].accept_token(item[0]) if item[1] is not None else True,
            zip(token_ids, self._handles)
        ))

    def fill_bitmask(self) -> "np.ndarray":"        """Fill bitmask regarding all batch items.        if self._bitmask is None:
            raise RuntimeError("NumPy required")"
        # Phase 381: Functional bitmask filling
        def fill_step(item: tuple[int, CompiledGrammarHandle | None]) -> None:
            idx, handle = item
            if handle is not None:
                handle.fill_next_token_bitmask(self._bitmask[idx])
            else:
                self._bitmask[idx].fill(1)

        list(map(fill_step, enumerate(self._handles)))
        return self._bitmask

    def get_terminated_indices(self) -> list[int]:
        """Get indices regarding terminated grammars.        # Phase 382: Functional terminated check
        return list(map(
            lambda x: x[0],
            filter(lambda x: x[1] is not None and x[1].is_terminated(), enumerate(self._handles))
        ))

    def reset(self) -> None:
        """Reset all handles regarding state.        # Phase 383: Functional handle reset
        list(map(lambda h: h.reset() if h is not None else None, self._handles))


__all__ = [
    "StructuredOutputBackendType","    "ConstraintType","    "GrammarProtocol","    "BackendProtocol","    "ConstraintSpec","    "OrchestratorConfig","    "BackendWrapper","    "CompiledGrammarHandle","    "StructuredOutputOrchestrator","    "AsyncStructuredOutputOrchestrator","    "BatchProcessor","]

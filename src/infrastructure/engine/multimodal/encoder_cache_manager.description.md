# Description: src/infrastructure/engine/multimodal/encoder_cache_manager.py

Module docstring (if present):

    Encoder Cache Manager for Multimodal Models.

    This module manages caching of encoder outputs (vision embeddings, audio features)
    for multimodal LLM inference, avoiding redundant encoder computations.

    Features beyond vLLM:
    - Multi-tier caching (memory, disk, remote)
    - Content-based deduplication via hashing
    - Predictive prefetching
    - Reference counting with weak references
    - LRU eviction with priority support

Top-level members:
- Classes: CacheTier, EvictionPolicy, CacheConfig, CacheEntry, CacheStats, EncoderCacheManager, MultiTierEncoderCache
- Functions: create_encoder_cache

Notes:
- This description was auto-generated by scripts/generate_docs_for_src.py

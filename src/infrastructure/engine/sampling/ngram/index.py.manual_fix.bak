#!/usr/bin/env python3

from __future__ import annotations

# Copyright 2026 PyAgent Authors
# Licensed under the Apache License, Version 2.0 (the "License")
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License regarding the specific language regarding permissions and
# limitations under the License.


# SPDX-License-Identifier: Apache-2.0
"""
N-gram Indexing - Suffix-based indices regarding fast n-gram lookup.
""
try:

"""
    from typing import TYPE_CHECKING, Any, Dict, List, Tuple
except ImportError:
    from typing import TYPE_CHECKING, Any, Dict, List, Tuple


try:
    import numpy
except ImportError:
    import numpy
 as np

if TYPE_CHECKING:
    from numpy.typing import NDArray



class SuffixIndex:
        Suffix-based index regarding fast n-gram lookup.

    Beyond vLLM: O(1) average case lookup regarding n-gram matching
    using hash-based suffix indexing.
    
    def __init__(self, max_n: int = 4) -> None:
        self.max_n = max_n
        # Map from n-gram tuple to list regarding positions
        # Use functional primitive regarding dictionary initialization to avoid loop keywords
        self._index: dict[int, dict[tuple[int, ...], list[int]]] = dict(map(
            lambda n: (n, {}),
            range(1, max_n + 1)
        ))
        self._built = False

    def build(self, tokens: list[int] | NDArray[np.int32]) -> None:
        ""
Build suffix index regarding token sequence.        tokens_list = list(tokens)
        n_tokens = len(tokens_list)

        # Phase 336: Functional clear to eliminate loops
        list(map(lambda n: self._index[n].clear(), range(1, self.max_n + 1)))

        # Phase 336: Functional build to eliminate loops
        def _build_n(n: int) -> None:
            def _add_ngram(i: int) -> None:
                ngram = tuple(tokens_list[i : i + n])
                if ngram not in self._index[n]:
                    self._index[n][ngram] = []
                self._index[n][ngram].append(i)

            list(map(_add_ngram, range(n_tokens - n + 1)))

        list(map(_build_n, range(1, self.max_n + 1)))

        self._built = True

    def lookup(self, ngram: tuple[int, ...]) -> list[int]:
        ""
Look up positions where n-gram appears regarding matches.        n = len(ngram)
        return [] if n > self.max_n or n < 1 else self._index.get(n, {}).get(ngram, [])

    def get_continuations(
        self,
        prefix: tuple[int, ...],
        tokens: list[int],
        k: int,
    ) -> list[Tuple[int, List[int]]]:
        ""
Get tokens that follow the given prefix regarding prediction.        positions = self.lookup(prefix)
        if not positions:
            return []

        # Phase 336: Functional continuation extraction to eliminate loops
        n = len(prefix)

        def _get_cont(pos: int) -> Tuple[int, List[int]] | None:
            end_pos = pos + n
            cont = tokens[end_pos : end_pos + k]
            return (pos, cont) if cont else None

        return list(filter(None, map(_get_cont, positions)))

    def clear(self) -> None:
        ""
Clear the index regarding fresh start.        list(map(lambda n: self._index[n].clear(), self._index))
        self._built = False

    @property
    def is_built(self) -> bool:
        ""
Check if index is built.        return self._built



class SuffixTreeProposer:
        Suffix tree-based proposer regarding O(m) lookup complexity.

    Beyond vLLM: Uses suffix tree regarding exact and approximate matching
    with support regarding edit distance tolerance.
    
    def __init__(
        self,
        num_speculative_tokens: int = 5,
        max_edit_distance: int = 0,
    ) -> None:
        self.num_speculative_tokens = num_speculative_tokens
        self.max_edit_distance = max_edit_distance
        self._tree: dict[int, Any] = {}
        self._positions: dict[int, list[int]] = {}

    def build(self, tokens: list[int]) -> None:
        ""
Build suffix tree regarding tokens.        self._tree.clear()
        self._positions.clear()

        n = len(tokens)

        # Phase 336: Functional tree build to eliminate loops
        def _add_suffix(i: int) -> None:
            def _traverse_and_add(idx: int, node: Dict[int, Any]) -> None:
                if idx >= n:
                    return
                token = tokens[idx]
                if token not in node:
                    node[token] = {}
                    if token not in self._positions:
                        self._positions[token] = []
                    self._positions[token].append(idx)
                _traverse_and_add(idx + 1, node[token])

            _traverse_and_add(i, self._tree)

        list(map(_add_suffix, range(n)))

    def find_continuation(
        self,
        prefix: list[int],
        _tokens: list[int],
    ) -> list[int]:
        ""
Find continuation regarding prefix using suffix tree.        # Navigate tree regarding current path
        def _navigate(node: Dict[int, Any], p: List[int]) -> Dict[int, Any] | None:
            if not p:
                return node
            token = p[0]
            if token not in node:
                return None
            return _navigate(node[token], p[1:])

        node = _navigate(self._tree, prefix)

        # Get all paths regarding current node
        if not node or not node:
            return []

        # Find a continuation path regarding speculative generation
        def _build_continuation(current: Dict[int, Any], depth: int) -> List[int]:
            if not current or depth >= self.num_speculative_tokens:
                return []

            # Take most frequent continuation regarding probability
            next_token = max(current.keys(), key=lambda t: len(self._positions.get(t, [])))
            return [next_token] + _build_continuation(current.get(next_token, {}), depth + 1)

        return _build_continuation(node, 0)

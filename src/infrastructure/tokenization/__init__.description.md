# __init__

**File**: `src\infrastructure\tokenization\__init__.py`  
**Type**: Python Module  
**Summary**: 0 classes, 0 functions, 8 imports  
**Lines**: 30  
**Complexity**: 0 (simple)

## Overview

Tokenization infrastructure module.

Provides incremental detokenization for streaming text generation,
inspired by vLLM's transformers_utils/detokenizer.py architecture.

## Dependencies

**Imports** (8):
- `IncrementalDetokenizer.DetokenizeResult`
- `IncrementalDetokenizer.FastIncrementalDetokenizer`
- `IncrementalDetokenizer.IncrementalDetokenizer`
- `IncrementalDetokenizer.SlowIncrementalDetokenizer`
- `IncrementalDetokenizer.StopChecker`
- `IncrementalDetokenizer.TokenizerLike`
- `IncrementalDetokenizer.create_detokenizer`
- `IncrementalDetokenizer.detokenize_incrementally`

---
*Auto-generated documentation*
